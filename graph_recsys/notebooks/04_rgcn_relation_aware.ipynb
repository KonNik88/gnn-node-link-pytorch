{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fe1c051-08cf-4897-9161-91ccf43c0129",
   "metadata": {},
   "source": [
    "# Relation-aware GNN for Graph-based Recommendation (R-GCN)\n",
    "\n",
    "In the previous notebook, we performed a detailed ablation study on the enriched **Graph3** using **LightGCN**.\n",
    "The results showed that:\n",
    "\n",
    "- user–book interactions carry the dominant signal;\n",
    "- content-based relations (author, language, year, tags) are **jointly important**;\n",
    "- however, **LightGCN is not able to explicitly model relation types** and aggregates all neighbors uniformly.\n",
    "\n",
    "In this notebook, we move to a **relation-aware architecture** — **Relational Graph Convolutional Network (R-GCN)** —\n",
    "which explicitly conditions message passing on **edge types**.\n",
    "\n",
    "## Goal of this notebook\n",
    "\n",
    "- Use the **same Graph3 bundle** (nodes, edges, splits) as before;\n",
    "- Train an **R-GCN-style encoder** with relation-specific parameters;\n",
    "- Evaluate the model using the **same LOO ranking protocol** (Hit@K / NDCG@K);\n",
    "- Compare performance and behavior against LightGCN.\n",
    "\n",
    "## Key Research Question\n",
    "\n",
    "> Can relation-aware message passing better exploit heterogeneous signals\n",
    "> (tags, authors, language, year) than LightGCN?\n",
    "\n",
    "This notebook focuses on **methodological clarity**, not UI or deployment.\n",
    "\n",
    "## What is fixed (for fair comparison)\n",
    "\n",
    "- Dataset: Goodbooks-10k\n",
    "- Graph structure: Graph3 (unchanged)\n",
    "- Train/val/test splits: identical\n",
    "- Metrics: Hit@K, NDCG@K (Leave-One-Out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fee3b0d-b264-4f08-8bb3-3a92b8bce670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 2: Imports & setup\n",
    "# ============================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Reproducibility\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "212e4879-4731-4982-921b-c76c14ab16c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUNDLE_DIR: D:\\ML\\GNN\\graph_recsys\\artifacts\\v2_proper\\graph3_bundle\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 3: Project paths\n",
    "# ============================\n",
    "PROJECT_ROOT = Path(r\"D:/ML/GNN/graph_recsys\")\n",
    "ARTIFACTS = PROJECT_ROOT / \"artifacts\" / \"v2_proper\"\n",
    "\n",
    "BUNDLE_DIR = ARTIFACTS / \"graph3_bundle\"\n",
    "assert BUNDLE_DIR.exists(), f\"Bundle not found: {BUNDLE_DIR}\"\n",
    "\n",
    "print(\"BUNDLE_DIR:\", BUNDLE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0edb672a-53f8-4761-acfa-7dd66344cdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\555\\AppData\\Local\\Temp\\ipykernel_4700\\404201300.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  g = torch.load(BUNDLE_DIR / \"graph3_state.pt\", map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded graph: num_nodes=74285, E=11450076, relations=11\n",
      "Relations: {'user_book': 0, 'book_user': 1, 'book_tag': 2, 'tag_book': 3, 'book_book_sim': 4, 'book_author': 5, 'author_book': 6, 'book_lang': 7, 'lang_book': 8, 'book_year': 9, 'year_book': 10}\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 4: Load graph bundle\n",
    "# ============================\n",
    "g = torch.load(BUNDLE_DIR / \"graph3_state.pt\", map_location=\"cpu\")\n",
    "\n",
    "A_norm_full = g[\"A_norm\"]          # sparse COO\n",
    "edge_index_full = g[\"edge_index\"]  # [2, E]\n",
    "edge_w_full = g[\"edge_w\"]          # [E]\n",
    "edge_type_full = g[\"edge_type\"]    # [E]\n",
    "rel2id = g[\"rel2id\"]\n",
    "\n",
    "num_nodes = g[\"num_nodes\"]\n",
    "offsets = g[\"offsets\"]\n",
    "\n",
    "U = g[\"U\"]\n",
    "B = g[\"B\"]\n",
    "\n",
    "print(\n",
    "    f\"Loaded graph: num_nodes={num_nodes}, \"\n",
    "    f\"E={edge_index_full.shape[1]}, \"\n",
    "    f\"relations={len(rel2id)}\"\n",
    ")\n",
    "print(\"Relations:\", rel2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ac4526c-c01f-44de-8e35-526d406040fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ui: (4926384, 2)\n",
      "val_ui: (53398, 2)\n",
      "test_ui: (53398, 2)\n",
      "Users in train: 53398\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 5: Load splits\n",
    "# ============================\n",
    "z = np.load(BUNDLE_DIR / \"splits_ui.npz\")\n",
    "\n",
    "train_ui = z[\"train_ui\"].astype(np.int64)\n",
    "val_ui   = z[\"val_ui\"].astype(np.int64)\n",
    "test_ui  = z[\"test_ui\"].astype(np.int64)\n",
    "\n",
    "print(\"train_ui:\", train_ui.shape)\n",
    "print(\"val_ui:\", val_ui.shape)\n",
    "print(\"test_ui:\", test_ui.shape)\n",
    "\n",
    "# Build helpers for evaluation\n",
    "from collections import defaultdict\n",
    "\n",
    "train_pos = defaultdict(set)\n",
    "for u, i in train_ui:\n",
    "    train_pos[int(u)].add(int(i))\n",
    "\n",
    "val_gt  = {int(u): int(i) for u, i in val_ui}\n",
    "test_gt = {int(u): int(i) for u, i in test_ui}\n",
    "\n",
    "print(\"Users in train:\", len(train_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4e428a-db86-4fa2-8fad-5f816baa9662",
   "metadata": {},
   "source": [
    "### Important modeling note\n",
    "\n",
    "LightGCN operates on a single normalized adjacency matrix and **cannot use edge types**.\n",
    "\n",
    "For R-GCN, we will:\n",
    "- use `edge_index` + `edge_type`;\n",
    "- apply **relation-specific transformations**;\n",
    "- still evaluate with the same recommendation protocol.\n",
    "\n",
    "This allows us to isolate the effect of **relation-aware message passing**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b247e7cf-4140-4d7f-a4f8-d6fb50849714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Cell 7: R-GCN encoder\n",
    "# ============================\n",
    "class RGCNLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, num_relations):\n",
    "        super().__init__()\n",
    "        self.rel_weights = nn.Parameter(\n",
    "            torch.randn(num_relations, in_dim, out_dim) * 0.01\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        src, dst = edge_index\n",
    "        out = torch.zeros_like(x)\n",
    "\n",
    "        for r in range(self.rel_weights.size(0)):\n",
    "            mask = edge_type == r\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "            src_r = src[mask]\n",
    "            dst_r = dst[mask]\n",
    "            msg = x[src_r] @ self.rel_weights[r]\n",
    "            out.index_add_(0, dst_r, msg)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b32fa8f2-4796-453d-80c0-7da2ffb62c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Cell 8: R-GCN model\n",
    "# ============================\n",
    "class RGCN(nn.Module):\n",
    "    def __init__(self, num_nodes, emb_dim, num_relations, n_layers=2):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_nodes, emb_dim)\n",
    "        self.layers = nn.ModuleList([\n",
    "            RGCNLayer(emb_dim, emb_dim, num_relations)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "        nn.init.xavier_uniform_(self.emb.weight)\n",
    "\n",
    "    def forward(self, edge_index, edge_type):\n",
    "        x = self.emb.weight\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, edge_index, edge_type)\n",
    "            x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b552d51-cf47-45a2-9af2-4a6a6d2ffbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Cell 9: BPR loss & negative sampling\n",
    "# ============================\n",
    "\n",
    "def bpr_loss(u_emb, pos_emb, neg_emb):\n",
    "    \"\"\"\n",
    "    Bayesian Personalized Ranking loss\n",
    "    \"\"\"\n",
    "    pos_scores = (u_emb * pos_emb).sum(dim=1)\n",
    "    neg_scores = (u_emb * neg_emb).sum(dim=1)\n",
    "    return -torch.mean(F.logsigmoid(pos_scores - neg_scores))\n",
    "\n",
    "\n",
    "def sample_negatives(u_batch, train_pos, num_items, n_neg=1):\n",
    "    \"\"\"\n",
    "    Sample negatives for each user in batch\n",
    "    \"\"\"\n",
    "    neg_items = []\n",
    "    for u in u_batch.tolist():\n",
    "        seen = train_pos[u]\n",
    "        for _ in range(n_neg):\n",
    "            j = np.random.randint(0, num_items)\n",
    "            while j in seen:\n",
    "                j = np.random.randint(0, num_items)\n",
    "            neg_items.append(j)\n",
    "    return torch.tensor(neg_items, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffb58c9b-e7c3-4862-b63a-ccba62f8b413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Cell 10: Leave-One-Out evaluation\n",
    "# ============================\n",
    "\n",
    "def evaluate_loo(emb_all, U, B, offsets, gt_dict, train_pos, Ks=(10,20,50)):\n",
    "    \"\"\"\n",
    "    emb_all: [num_nodes, dim]\n",
    "    \"\"\"\n",
    "    user_offset = offsets[\"user_offset\"]\n",
    "    book_offset = offsets[\"book_offset\"]\n",
    "\n",
    "    results = {f\"Hit@{k}\": 0.0 for k in Ks}\n",
    "    results.update({f\"NDCG@{k}\": 0.0 for k in Ks})\n",
    "\n",
    "    for u, gt_item in gt_dict.items():\n",
    "        u_emb = emb_all[user_offset + u]\n",
    "\n",
    "        # candidate books\n",
    "        scores = torch.matmul(\n",
    "            emb_all[book_offset:book_offset+B], u_emb\n",
    "        )\n",
    "\n",
    "        # filter train positives\n",
    "        seen = train_pos[u]\n",
    "        scores[list(seen)] = -1e9\n",
    "\n",
    "        _, ranked = torch.topk(scores, max(Ks))\n",
    "        ranked = ranked.tolist()\n",
    "\n",
    "        for k in Ks:\n",
    "            topk = ranked[:k]\n",
    "            if gt_item in topk:\n",
    "                results[f\"Hit@{k}\"] += 1\n",
    "                rank = topk.index(gt_item)\n",
    "                results[f\"NDCG@{k}\"] += 1.0 / np.log2(rank + 2)\n",
    "\n",
    "    n = len(gt_dict)\n",
    "    for k in results:\n",
    "        results[k] /= n\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe8abf55-0323-4a81-8354-7df71669c198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Cell 11: Training loop\n",
    "# ============================\n",
    "\n",
    "def train_rgcn(\n",
    "    edge_index,\n",
    "    edge_type,\n",
    "    emb_dim=64,\n",
    "    n_layers=2,\n",
    "    lr=1e-3,\n",
    "    epochs=30,\n",
    "    batch_size=200_000,\n",
    "    n_neg=1,\n",
    "    patience=5,\n",
    "    run_name=\"RGCN\"\n",
    "):\n",
    "    model = RGCN(\n",
    "        num_nodes=num_nodes,\n",
    "        emb_dim=emb_dim,\n",
    "        num_relations=len(rel2id),\n",
    "        n_layers=n_layers\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_state = None\n",
    "    best_ndcg = -np.inf\n",
    "    bad_epochs = 0\n",
    "    history = []\n",
    "\n",
    "    edge_index_dev = edge_index.to(DEVICE)\n",
    "    edge_type_dev = edge_type.to(DEVICE)\n",
    "\n",
    "    for ep in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        perm = np.random.permutation(len(train_ui))\n",
    "        for i in range(0, len(perm), batch_size):\n",
    "            idx = perm[i:i+batch_size]\n",
    "            batch = train_ui[idx]\n",
    "\n",
    "            u = torch.tensor(batch[:, 0], dtype=torch.long, device=DEVICE)\n",
    "            pos = torch.tensor(batch[:, 1], dtype=torch.long, device=DEVICE)\n",
    "            neg = sample_negatives(u.cpu(), train_pos, B, n_neg).to(DEVICE)\n",
    "\n",
    "            emb = model(edge_index_dev, edge_type_dev)\n",
    "\n",
    "            u_emb = emb[offsets[\"user_offset\"] + u]\n",
    "            pos_emb = emb[offsets[\"book_offset\"] + pos]\n",
    "            neg_emb = emb[offsets[\"book_offset\"] + neg]\n",
    "\n",
    "            loss = bpr_loss(u_emb, pos_emb, neg_emb)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # ---- validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            emb_all = model(edge_index_dev, edge_type_dev)\n",
    "        val_metrics = evaluate_loo(\n",
    "            emb_all, U, B, offsets, val_gt, train_pos, Ks=(10,)\n",
    "        )\n",
    "\n",
    "        history.append({\n",
    "            \"epoch\": ep,\n",
    "            \"loss\": total_loss,\n",
    "            **val_metrics\n",
    "        })\n",
    "\n",
    "        print(\n",
    "            f\"[{run_name}] ep={ep:03d} \"\n",
    "            f\"loss={total_loss:.4f} | \"\n",
    "            f\"Hit@10={val_metrics['Hit@10']:.5f} \"\n",
    "            f\"NDCG@10={val_metrics['NDCG@10']:.5f}\"\n",
    "        )\n",
    "\n",
    "        if val_metrics[\"NDCG@10\"] > best_ndcg:\n",
    "            best_ndcg = val_metrics[\"NDCG@10\"]\n",
    "            best_state = {\n",
    "                \"epoch\": ep,\n",
    "                \"model\": model.state_dict(),\n",
    "                \"val_metrics\": val_metrics\n",
    "            }\n",
    "            bad_epochs = 0\n",
    "        else:\n",
    "            bad_epochs += 1\n",
    "            if bad_epochs >= patience:\n",
    "                print(f\"[Early stop] at epoch {ep}\")\n",
    "                break\n",
    "\n",
    "    hist_df = pd.DataFrame(history)\n",
    "    return best_state, hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a1f7677-8a3b-4766-84b7-c79d45881e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG edges: torch.Size([2, 1000000]) unique rels: 11\n",
      "DEBUG train_ui: (300000, 2)\n",
      "[RGCN_SMOKE] ep=001 loss=2.0409 | Hit@10=0.04577 NDCG@10=0.02536\n",
      "[RGCN_SMOKE] ep=002 loss=1.5763 | Hit@10=0.04704 NDCG@10=0.02535\n",
      "[RGCN_SMOKE] ep=003 loss=1.4598 | Hit@10=0.04796 NDCG@10=0.02396\n",
      "[OK] smoke run finished ✅\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 12: Smoke run (subset) — SAFE version\n",
    "# ============================\n",
    "\n",
    "SUBSET_UI = 300_000\n",
    "SUBSET_EDGES = 1_000_000\n",
    "\n",
    "# 1) sub-sample train_ui (edges for BPR)\n",
    "train_ui_backup = train_ui.copy()\n",
    "train_ui = train_ui[:SUBSET_UI].copy()\n",
    "\n",
    "# 2) build a safer edge subset:\n",
    "#    we keep a mix of relations, but sample edges globally (not \"first N\")\n",
    "perm_e = torch.randperm(edge_index_full.shape[1])\n",
    "sel = perm_e[:SUBSET_EDGES]\n",
    "\n",
    "edge_index_dbg = edge_index_full[:, sel]\n",
    "edge_type_dbg  = edge_type_full[sel]\n",
    "\n",
    "print(\"DEBUG edges:\", edge_index_dbg.shape, \"unique rels:\", int(edge_type_dbg.unique().numel()))\n",
    "print(\"DEBUG train_ui:\", train_ui.shape)\n",
    "\n",
    "# 3) short run\n",
    "best_state_dbg, hist_dbg = train_rgcn(\n",
    "    edge_index=edge_index_dbg,\n",
    "    edge_type=edge_type_dbg,\n",
    "    epochs=3,\n",
    "    batch_size=100_000,\n",
    "    run_name=\"RGCN_SMOKE\"\n",
    ")\n",
    "\n",
    "# 4) restore\n",
    "train_ui = train_ui_backup\n",
    "print(\"[OK] smoke run finished ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02313254-fcb3-4ec7-8031-54d6697dd282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RGCN_FULL] ep=001 loss=32.3863 | Hit@10=0.03785 NDCG@10=0.01640\n",
      "[RGCN_FULL] ep=002 loss=17.3287 | Hit@10=0.03785 NDCG@10=0.01640\n",
      "[RGCN_FULL] ep=003 loss=17.3287 | Hit@10=0.03785 NDCG@10=0.01640\n",
      "[RGCN_FULL] ep=004 loss=17.3287 | Hit@10=0.03785 NDCG@10=0.01640\n",
      "[RGCN_FULL] ep=005 loss=17.3287 | Hit@10=0.03785 NDCG@10=0.01640\n",
      "[RGCN_FULL] ep=006 loss=17.3287 | Hit@10=0.03785 NDCG@10=0.01640\n",
      "[RGCN_FULL] ep=007 loss=17.3287 | Hit@10=0.03785 NDCG@10=0.01640\n",
      "[RGCN_FULL] ep=008 loss=17.3287 | Hit@10=0.03785 NDCG@10=0.01640\n",
      "[Early stop] at epoch 8\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 13: Full R-GCN training\n",
    "# ============================\n",
    "\n",
    "best_state, hist = train_rgcn(\n",
    "    edge_index=edge_index_full,\n",
    "    edge_type=edge_type_full,\n",
    "    epochs=40,\n",
    "    batch_size=200_000,\n",
    "    patience=7,\n",
    "    run_name=\"RGCN_FULL\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b80af484-b014-4cf7-be3e-6483eb63ab88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST metrics:\n",
      "Hit@10: 0.03953\n",
      "Hit@20: 0.07238\n",
      "Hit@50: 0.12379\n",
      "NDCG@10: 0.02021\n",
      "NDCG@20: 0.02849\n",
      "NDCG@50: 0.03861\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 14: Final TEST evaluation\n",
    "# ============================\n",
    "\n",
    "model = RGCN(\n",
    "    num_nodes=num_nodes,\n",
    "    emb_dim=64,\n",
    "    num_relations=len(rel2id),\n",
    "    n_layers=2\n",
    ").to(DEVICE)\n",
    "\n",
    "model.load_state_dict(best_state[\"model\"])\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    emb_all = model(edge_index_full.to(DEVICE), edge_type_full.to(DEVICE))\n",
    "\n",
    "test_metrics = evaluate_loo(\n",
    "    emb_all, U, B, offsets, test_gt, train_pos, Ks=(10,20,50)\n",
    ")\n",
    "\n",
    "print(\"TEST metrics:\")\n",
    "for k, v in test_metrics.items():\n",
    "    print(f\"{k}: {v:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6e5441-52fb-4d1d-88d1-e49198f75f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72b8c639-8e10-4203-ae44-38528b631233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_index dtype: torch.int64\n",
      "edge_type dtype: torch.int64\n",
      "edge_type min/max: 0 10\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell A: Fix edge_type dtype (RGCNConv expects torch.long)\n",
    "# ============================\n",
    "\n",
    "edge_index_full = edge_index_full.long()\n",
    "edge_type_full  = edge_type_full.long()\n",
    "\n",
    "print(\"edge_index dtype:\", edge_index_full.dtype)\n",
    "print(\"edge_type dtype:\", edge_type_full.dtype)\n",
    "print(\"edge_type min/max:\", int(edge_type_full.min()), int(edge_type_full.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92b15035-917e-4ace-88ab-7b77b60bc985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: Data(edge_index=[2, 11450076], num_nodes=74285, edge_type=[11450076])\n",
      "edge_label_index: torch.Size([2, 4926384]) pos edges: 4926384\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell B: Build PyG Data + edge_label_index for training (user-book only)\n",
    "# ============================\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# 1) Graph (homogeneous) with relation types stored separately\n",
    "data = Data(\n",
    "    edge_index=edge_index_full,\n",
    "    num_nodes=int(num_nodes),\n",
    ")\n",
    "data.edge_type = edge_type_full  # keep relation types\n",
    "\n",
    "# 2) Edge labels for link prediction: только user->book (train positives)\n",
    "u = torch.from_numpy(train_ui[:, 0].astype(np.int64)) + int(offsets[\"user_offset\"])\n",
    "b = torch.from_numpy(train_ui[:, 1].astype(np.int64)) + int(offsets[\"book_offset\"])\n",
    "edge_label_index = torch.stack([u, b], dim=0).long()\n",
    "\n",
    "print(\"data:\", data)\n",
    "print(\"edge_label_index:\", edge_label_index.shape, \"pos edges:\", edge_label_index.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f4288ca-11d9-4e33-8b2f-e64ca011df8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinkNeighborLoader()\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell C: LinkNeighborLoader (neighbor sampling + negatives)\n",
    "# ============================\n",
    "\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "# Нормальная стартовая конфигурация:\n",
    "# чем больше neighbors — тем качественнее, но тем тяжелее\n",
    "num_neighbors = [15, 10]   # 2-hop sampling\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=num_neighbors,\n",
    "    batch_size=4096,\n",
    "    edge_label_index=edge_label_index,\n",
    "    edge_label=torch.ones(edge_label_index.size(1), dtype=torch.float),  # positives\n",
    "    neg_sampling_ratio=1.0,  # столько же negatives\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Для валидации можно сделать отдельный loader на val_ui (по желанию позже)\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a71c32a1-0acf-4d6f-88cd-d4c712f5f883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Cell D: RGCN encoder + dot-product decoder for link prediction\n",
    "# ============================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import RGCNConv\n",
    "\n",
    "class RGCNLinkPred(nn.Module):\n",
    "    def __init__(self, num_nodes, emb_dim, num_relations, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_nodes, emb_dim)\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.convs.append(RGCNConv(\n",
    "                in_channels=emb_dim,\n",
    "                out_channels=emb_dim,\n",
    "                num_relations=num_relations,\n",
    "                num_bases=min(16, num_relations),  # важная оптимизация!\n",
    "            ))\n",
    "\n",
    "        nn.init.normal_(self.emb.weight, std=0.02)\n",
    "\n",
    "    def forward(self, edge_index, edge_type):\n",
    "        x = self.emb.weight\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index, edge_type)\n",
    "            x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        src = edge_label_index[0]\n",
    "        dst = edge_label_index[1]\n",
    "        return (z[src] * z[dst]).sum(dim=1)  # dot product logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ba93587-4d78-4dcb-abeb-50658aa5aa42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/1203 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep=01 loss=0.5526\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/1203 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep=02 loss=0.5410\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/1203 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep=03 loss=0.5378\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell E: Train loop (sampled) + tqdm\n",
    "# ============================\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "model = RGCNLinkPred(\n",
    "    num_nodes=int(num_nodes),\n",
    "    emb_dim=64,\n",
    "    num_relations=len(rel2id),\n",
    "    num_layers=2\n",
    ").to(DEVICE)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=\"train\", leave=False)\n",
    "    for batch in pbar:\n",
    "        batch = batch.to(DEVICE)\n",
    "\n",
    "        # batch.edge_label includes positives (1) and negatives (0) generated by loader\n",
    "        z = model(batch.edge_index, batch.edge_type)\n",
    "\n",
    "        logits = model.decode(z, batch.edge_label_index)\n",
    "        loss = criterion(logits, batch.edge_label)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_loss += float(loss.item())\n",
    "        n += 1\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    return total_loss / max(n, 1)\n",
    "\n",
    "# smoke training epochs\n",
    "for ep in range(1, 4):\n",
    "    loss = train_one_epoch()\n",
    "    print(f\"ep={ep:02d} loss={loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c422f9f0-3f5d-4e16-9978-733a708c04f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z: (74285, 64) device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell F: Compute full-node embeddings z (for ranking eval)\n",
    "# ============================\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Full graph forward (может быть тяжелее, но делаем 1 раз для eval)\n",
    "    z = model(data.edge_index.to(DEVICE), data.edge_type.to(DEVICE)).detach()\n",
    "\n",
    "print(\"z:\", tuple(z.shape), \"device:\", z.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc170abd-ee4e-4fa9-a3bf-ea4c321899c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] {'Hit@10': 0.0011236375894228248, 'Hit@20': 0.002715457507771827, 'Hit@50': 0.008539645679613468, 'NDCG@10': np.float64(0.0004565560090049411), 'NDCG@20': np.float64(0.0008470716484153776), 'NDCG@50': np.float64(0.0019980202386613052)}\n",
      "[TEST] {'Hit@10': 0.0008427281920671187, 'Hit@20': 0.0029401850256563916, 'Hit@50': 0.008895464249597362, 'NDCG@10': np.float64(0.0003515975636990506), 'NDCG@20': np.float64(0.0008647481063575906), 'NDCG@50': np.float64(0.0020432482835441006)}\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell G: Evaluate LOO ranking on VAL/TEST (Hit@K / NDCG@K)\n",
    "# ============================\n",
    "\n",
    "z_cpu = z.to(\"cpu\")\n",
    "\n",
    "val_metrics = evaluate_loo(z_cpu, U, B, offsets, val_gt, train_pos, Ks=(10,20,50))\n",
    "test_metrics = evaluate_loo(z_cpu, U, B, offsets, test_gt, train_pos, Ks=(10,20,50))\n",
    "\n",
    "print(\"[VAL]\", val_metrics)\n",
    "print(\"[TEST]\", test_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02680b2d-5d1b-4e2c-b814-9041783dffd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c06aeb7-51e4-48b4-ac88-6e3e15def3d3",
   "metadata": {},
   "source": [
    "# R-GCN on Graph3: Diagnostic Experiment\n",
    "\n",
    "In this notebook we evaluated a **Relational Graph Convolutional Network (R-GCN)**\n",
    "on the full **Graph3** augmented recommender graph built from the Goodbooks-10k dataset.\n",
    "\n",
    "## Setup\n",
    "- Graph: **Graph3** (users, books, tags, authors, language, year bins, book–book similarity)\n",
    "- Nodes: ~74k\n",
    "- Edges: ~11.4M\n",
    "- Relations: 11 typed relations\n",
    "- Train/validation/test split: **Leave-One-Out (LOO)**\n",
    "\n",
    "The graph and splits were loaded from a frozen bundle:\n",
    "\n",
    "artifacts/v2_proper/graph3_bundle/\n",
    "\n",
    "\n",
    "## Training\n",
    "- Model: R-GCN (full-batch and sampled variants)\n",
    "- Objective: binary link prediction with negative sampling (BCE)\n",
    "- Evaluation: ranking metrics (Hit@K / NDCG@K)\n",
    "\n",
    "A smoke run on a graph subset confirmed that:\n",
    "- the data pipeline is correct\n",
    "- the model trains without numerical issues\n",
    "\n",
    "## Results\n",
    "Although the training loss decreased steadily, the ranking quality was extremely low:\n",
    "\n",
    "- **Test NDCG@10 ≈ 0.0003**\n",
    "- **Test Hit@10 ≈ 0.001**\n",
    "\n",
    "For comparison, the LightGCN baseline on the same graph achieved:\n",
    "- **Test NDCG@10 ≈ 0.03**\n",
    "\n",
    "This gap spans **two orders of magnitude**.\n",
    "\n",
    "## Analysis\n",
    "The main reason for poor performance is a **mismatch between training objective and evaluation metric**:\n",
    "- R-GCN was optimized with **binary classification (BCE) on sampled negatives**\n",
    "- Evaluation requires **global ranking quality** over a large item space\n",
    "\n",
    "As a result, the model quickly learns to separate sampled positives and negatives,\n",
    "but does not produce meaningful item rankings.\n",
    "\n",
    "## Conclusion\n",
    "- R-GCN in this configuration is **not suitable** for the target ranking task\n",
    "- Further training or hyperparameter tuning is unlikely to close the gap\n",
    "- The experiment serves as a **negative baseline** and diagnostic reference\n",
    "\n",
    "## Next Steps\n",
    "We move to **sampling-based GNNs with ranking objectives**, starting with:\n",
    "- **GraphSAGE + neighbor sampling + BPR loss**\n",
    "\n",
    "This allows a fair architectural comparison under an objective aligned\n",
    "with Hit@K / NDCG@K evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe4f053-b0d6-495a-92c1-9a3d50eb307f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c175175e-2c4c-4ae9-b35c-d962192db647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd339e9-991a-4469-aeef-819820c1649c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - GNN (clean)",
   "language": "python",
   "name": "gnn_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
