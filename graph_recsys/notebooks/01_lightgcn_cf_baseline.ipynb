{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3304b4f-5ae5-4188-9978-39bc4c3b3e04",
   "metadata": {},
   "source": [
    "# Graph-Based Recommender System — LightGCN Baseline\n",
    "\n",
    "In this notebook, we build and evaluate a **proper graph-based recommender system baseline**\n",
    "using the **GoodBooks-10k** dataset and a **LightGCN** architecture.\n",
    "\n",
    "The goal of this stage is **not** to achieve the best possible recommendation quality,\n",
    "but to:\n",
    "\n",
    "1. Build a **correct and scalable pipeline** for graph-based recommendation.\n",
    "2. Use **proper data splitting** suitable for recommender systems.\n",
    "3. Evaluate the model with **ranking metrics** (Hit@K, NDCG@K), not classification metrics.\n",
    "4. Understand the **performance ceiling of pure collaborative filtering** on a user–item graph.\n",
    "\n",
    "This notebook serves as a **reference baseline** for further experiments with\n",
    "graph augmentation and hybrid recommender models.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "We use the original **GoodBooks-10k** dataset and leverage the following interaction signals:\n",
    "\n",
    "- `ratings.csv` → positive user–book interactions (`rating >= threshold`)\n",
    "- `to_read.csv` → implicit positive feedback\n",
    "\n",
    "Other files (`books.csv`, `tags.csv`, `book_tags.csv`) are intentionally **not used here**\n",
    "and will be incorporated in the next stage when we move to **content-aware graphs**.\n",
    "\n",
    "## Graph Construction\n",
    "\n",
    "We construct a **bipartite graph**:\n",
    "\n",
    "- User nodes\n",
    "- Book nodes\n",
    "- Undirected edges representing positive interactions\n",
    "\n",
    "Node indices:\n",
    "- users: `[0 … n_users - 1]`\n",
    "- books: `[n_users … n_users + n_items - 1]`\n",
    "\n",
    "The adjacency matrix is **symmetrically normalized** and used by LightGCN.\n",
    "\n",
    "## Data Splitting\n",
    "\n",
    "We apply a **leave-one-out split per user**:\n",
    "\n",
    "- **Train**: all but the last interaction\n",
    "- **Validation**: 1 interaction per user\n",
    "- **Test**: 1 interaction per user\n",
    "\n",
    "This setup:\n",
    "- avoids information leakage\n",
    "- matches real-world recommendation scenarios\n",
    "- enables correct ranking-based evaluation\n",
    "\n",
    "## Model\n",
    "\n",
    "We use **LightGCN**, a simplified GCN designed specifically for collaborative filtering:\n",
    "\n",
    "- No feature transformation\n",
    "- No nonlinearities\n",
    "- Message passing only through normalized adjacency\n",
    "- Final embeddings are averaged across layers\n",
    "\n",
    "To improve training stability and ranking quality, we use:\n",
    "- **BPR loss**\n",
    "- **Popularity-biased (hard) negative sampling**\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "We evaluate the model using **ranking metrics**:\n",
    "\n",
    "- Hit@K\n",
    "- Recall@K\n",
    "- NDCG@K\n",
    "\n",
    "Metrics are computed on:\n",
    "- a validation set during training\n",
    "- the **full test set** after training\n",
    "\n",
    "All seen items from the training set are masked during evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ba0c02a-6afe-4fd8-b4ad-296941c5fc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_RAW: D:\\ML\\GNN\\graph_recsys\\data_raw\n",
      "DATA_PROCESSED: D:\\ML\\GNN\\graph_recsys\\data_processed\\v2_proper\n",
      "ARTIFACTS: D:\\ML\\GNN\\graph_recsys\\artifacts\\v2_proper\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "SEED = 42\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "PROJECT_DIR = Path(r\"D:/ML/GNN/graph_recsys\")\n",
    "DATA_RAW = PROJECT_DIR / \"data_raw\"\n",
    "DATA_PROCESSED = PROJECT_DIR / \"data_processed\" / \"v2_proper\"\n",
    "ARTIFACTS = PROJECT_DIR / \"artifacts\" / \"v2_proper\"\n",
    "\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "ARTIFACTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"DATA_RAW:\", DATA_RAW)\n",
    "print(\"DATA_PROCESSED:\", DATA_PROCESSED)\n",
    "print(\"ARTIFACTS:\", ARTIFACTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd821c6-d6ef-4320-bc37-10ac52f74bb5",
   "metadata": {},
   "source": [
    "## Build implicit positive interactions\r\n",
    "\r\n",
    "We convert the dataset into a *binary implicit-feedback* format:\r\n",
    "\r\n",
    "- **ratings.csv** → keep only strong positive feedback (`rating >= threshold`)\r\n",
    "- **to_read.csv** → treat as an additional positive signal (\"user intends to read\")\r\n",
    "\r\n",
    "Then we concatenate both sources into a single interaction table and **drop duplicates**\r\n",
    "so that each `(user_id, book_id)` pair becomes a single edge in the user–ite graph.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd44974f-8038-4a0f-aad9-f8b4af37cc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "books: (10000, 23) | columns: ['book_id', 'goodreads_book_id', 'best_book_id', 'work_id', 'books_count', 'isbn', 'isbn13', 'authors', 'original_publication_year', 'original_title', 'title', 'language_code', 'average_rating', 'ratings_count', 'work_ratings_count', 'work_text_reviews_count', 'ratings_1', 'ratings_2', 'ratings_3', 'ratings_4', 'ratings_5', 'image_url', 'small_image_url']\n",
      "ratings: (5976479, 3) | columns: ['user_id', 'book_id', 'rating']\n",
      "to_read: (912705, 2) | columns: ['user_id', 'book_id']\n",
      "tags: (34252, 2) | columns: ['tag_id', 'tag_name']\n",
      "book_tags: (999912, 3) | columns: ['goodreads_book_id', 'tag_id', 'count']\n",
      "\n",
      "ratings nunique users: 53424\n",
      "ratings nunique books: 10000\n",
      "to_read nunique users: 48871\n",
      "to_read nunique books: 9986\n"
     ]
    }
   ],
   "source": [
    "books = pd.read_csv(DATA_RAW / \"books.csv\")\n",
    "ratings = pd.read_csv(DATA_RAW / \"ratings.csv\")\n",
    "to_read = pd.read_csv(DATA_RAW / \"to_read.csv\")\n",
    "tags = pd.read_csv(DATA_RAW / \"tags.csv\")\n",
    "book_tags = pd.read_csv(DATA_RAW / \"book_tags.csv\")\n",
    "\n",
    "print(\"books:\", books.shape, \"| columns:\", list(books.columns))\n",
    "print(\"ratings:\", ratings.shape, \"| columns:\", list(ratings.columns))\n",
    "print(\"to_read:\", to_read.shape, \"| columns:\", list(to_read.columns))\n",
    "print(\"tags:\", tags.shape, \"| columns:\", list(tags.columns))\n",
    "print(\"book_tags:\", book_tags.shape, \"| columns:\", list(book_tags.columns))\n",
    "\n",
    "print(\"\\nratings nunique users:\", ratings[\"user_id\"].nunique())\n",
    "print(\"ratings nunique books:\", ratings[\"book_id\"].nunique())\n",
    "print(\"to_read nunique users:\", to_read[\"user_id\"].nunique())\n",
    "print(\"to_read nunique books:\", to_read[\"book_id\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203699ca-b1da-40bf-95ac-e96740ebcf44",
   "metadata": {},
   "source": [
    "## Build implicit positive interactions\n",
    "\n",
    "We convert raw GoodBooks data into an **implicit-feedback** interaction table.\n",
    "\n",
    "- From `ratings.csv` we keep only **strong positive** signals (`rating >= threshold`), treating them as \"user liked the book\".\n",
    "- From `to_read.csv` we treat entries as **implicit interest** signals (\"user wants to read\").\n",
    "\n",
    "Then we concatenate both sources into a single `(user_id, book_id)` table and **drop duplicates** to avoid duplicate edges and evaluation leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d4cca6-d85e-4fca-9b94-25cee3abcd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interactions: (5033236, 3)\n",
      "source\n",
      "rating_pos    4122111\n",
      "to_read        911125\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>rating_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4081</td>\n",
       "      <td>rating_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>rating_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9296</td>\n",
       "      <td>rating_pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>rating_pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id      source\n",
       "0        1      258  rating_pos\n",
       "1        2     4081  rating_pos\n",
       "2        2      260  rating_pos\n",
       "3        2     9296  rating_pos\n",
       "4        2       26  rating_pos"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RATING_POS_THRESHOLD = 4\n",
    "\n",
    "ratings_pos = ratings.loc[ratings[\"rating\"] >= RATING_POS_THRESHOLD, [\"user_id\", \"book_id\"]].copy()\n",
    "ratings_pos[\"source\"] = \"rating_pos\"\n",
    "\n",
    "to_read_pos = to_read[[\"user_id\", \"book_id\"]].copy()\n",
    "to_read_pos[\"source\"] = \"to_read\"\n",
    "\n",
    "interactions = pd.concat([ratings_pos, to_read_pos], ignore_index=True)\n",
    "\n",
    "# убираем дубли (если юзер и так поставил рейтинг, и есть to_read)\n",
    "interactions = interactions.drop_duplicates(subset=[\"user_id\", \"book_id\"], keep=\"first\")\n",
    "\n",
    "print(\"interactions:\", interactions.shape)\n",
    "print(interactions[\"source\"].value_counts())\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb04fb0-e833-4d9c-944c-66285f8b9d42",
   "metadata": {},
   "source": [
    "## Filter sparse users and items (minimum counts)\r\n",
    "\r\n",
    "Graph recommenders are sensitive to extreme sparsity.  \r\n",
    "We iteratively filter out:\r\n",
    "\r\n",
    "- users with fewer than `MIN_INTERACTIONS_PER_USER` interactions\r\n",
    "- books with fewer than `MIN_INTERACTIONS_PER_BOOK` interactions\r\n",
    "\r\n",
    "This is an *iterative* process because removing sparse items can make some users sparse again (and vice versa).  \r\n",
    "The result is a cleaner interaction graph with fewer degenerate nodes and more stable training/evluation.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7859607f-2442-4e6a-8baf-816432d0333f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered interactions: 5033236 -> 5033180\n",
      "users: 53398 books: 9999\n"
     ]
    }
   ],
   "source": [
    "MIN_INTERACTIONS_PER_USER = 5\n",
    "MIN_INTERACTIONS_PER_BOOK = 5\n",
    "\n",
    "def filter_min_counts(df, user_col=\"user_id\", item_col=\"book_id\",\n",
    "                      min_user=5, min_item=5):\n",
    "    before = len(df)\n",
    "    while True:\n",
    "        user_cnt = df[user_col].value_counts()\n",
    "        item_cnt = df[item_col].value_counts()\n",
    "\n",
    "        good_users = user_cnt[user_cnt >= min_user].index\n",
    "        good_items = item_cnt[item_cnt >= min_item].index\n",
    "\n",
    "        df2 = df[df[user_col].isin(good_users) & df[item_col].isin(good_items)]\n",
    "        if len(df2) == len(df):\n",
    "            break\n",
    "        df = df2\n",
    "    after = len(df)\n",
    "    return df, before, after\n",
    "\n",
    "interactions_f, before, after = filter_min_counts(\n",
    "    interactions,\n",
    "    min_user=MIN_INTERACTIONS_PER_USER,\n",
    "    min_item=MIN_INTERACTIONS_PER_BOOK\n",
    ")\n",
    "\n",
    "print(f\"Filtered interactions: {before} -> {after}\")\n",
    "print(\"users:\", interactions_f[\"user_id\"].nunique(), \"books:\", interactions_f[\"book_id\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f47ad95-8707-4eab-a899-c02795007b4b",
   "metadata": {},
   "source": [
    "## Build contiguous node indices and save mappings\r\n",
    "\r\n",
    "For efficient graph construction, we remap raw IDs:\r\n",
    "\r\n",
    "- `user_id` → `u` in `[0 .. n_users-1]`\r\n",
    "- `book_id` → `i` in `[0 .. n_items-1]`\r\n",
    "\r\n",
    "This makes tensors compact, speeds up training, and simplifies saving/loading.  \r\n",
    "We also save `user2idx` and `book2idx` so we can later:\r\n",
    "- reconstruct recommendations for real `user_id` / `book_id`\r\n",
    "- join predictions back to metadata (`boks.csv`)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0215157-1357-4db5-884c-a62aeb0ea29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_users: 53398 n_items: 9999 n_interactions: 5033180\n"
     ]
    }
   ],
   "source": [
    "unique_users = np.sort(interactions_f[\"user_id\"].unique())\n",
    "unique_books = np.sort(interactions_f[\"book_id\"].unique())\n",
    "\n",
    "user2idx = {u: i for i, u in enumerate(unique_users)}\n",
    "book2idx = {b: i for i, b in enumerate(unique_books)}\n",
    "\n",
    "interactions_f = interactions_f.copy()\n",
    "\n",
    "interactions_f.loc[:, \"u\"] = interactions_f[\"user_id\"].map(user2idx).astype(np.int32)\n",
    "interactions_f.loc[:, \"i\"] = interactions_f[\"book_id\"].map(book2idx).astype(np.int32)\n",
    "\n",
    "n_users = len(unique_users)\n",
    "n_items = len(unique_books)\n",
    "\n",
    "print(\"n_users:\", n_users, \"n_items:\", n_items, \"n_interactions:\", len(interactions_f))\n",
    "\n",
    "# сохраняем маппинги\n",
    "pd.Series(user2idx).to_csv(DATA_PROCESSED / \"user2idx.csv\")\n",
    "pd.Series(book2idx).to_csv(DATA_PROCESSED / \"book2idx.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286de79f-a241-4c08-a994-48495513c3b4",
   "metadata": {},
   "source": [
    "## Proper recommender split: Leave-One-Out per user\r\n",
    "\r\n",
    "We create a **recsys-style** split: for each user:\r\n",
    "\r\n",
    "- **Train**: all but 2 interactions\r\n",
    "- **Validation**: 1 held-out interaction\r\n",
    "- **Test**: 1 held-out interaction\r\n",
    "\r\n",
    "This is a realistic evaluation protocol:\r\n",
    "- avoids leakage (no future items in train)\r\n",
    "- guarantees that every user in val/test exists in train\r\n",
    "- enables ranking-based metrics (Hit@K, NDCG@K)\r\n",
    "\r\n",
    "Note: users with extremely small histories are handled safely (fallback totrain-only).\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd66178f-e93e-4f8f-938f-681d7980bae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (4926384, 5) val: (53398, 5) test: (53398, 5)\n",
      "check unique users: 53398 53398 53398\n"
     ]
    }
   ],
   "source": [
    "def leave_one_out_split(df, user_col=\"u\", item_col=\"i\", seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    train_rows, val_rows, test_rows = [], [], []\n",
    "\n",
    "    for u, g in df.groupby(user_col):\n",
    "        items = g[item_col].to_numpy()\n",
    "        if len(items) < 3:\n",
    "            # на всякий: если мало — всё в train\n",
    "            train_rows.append(g)\n",
    "            continue\n",
    "\n",
    "        perm = rng.permutation(len(items))\n",
    "        test_idx = perm[0]\n",
    "        val_idx = perm[1]\n",
    "\n",
    "        mask = np.ones(len(items), dtype=bool)\n",
    "        mask[[test_idx, val_idx]] = False\n",
    "\n",
    "        g_train = g.iloc[mask.nonzero()[0]]\n",
    "        g_val = g.iloc[[val_idx]]\n",
    "        g_test = g.iloc[[test_idx]]\n",
    "\n",
    "        train_rows.append(g_train)\n",
    "        val_rows.append(g_val)\n",
    "        test_rows.append(g_test)\n",
    "\n",
    "    train = pd.concat(train_rows, ignore_index=True)\n",
    "    val = pd.concat(val_rows, ignore_index=True)\n",
    "    test = pd.concat(test_rows, ignore_index=True)\n",
    "    return train, val, test\n",
    "\n",
    "train_df, val_df, test_df = leave_one_out_split(interactions_f, seed=SEED)\n",
    "\n",
    "print(\"train:\", train_df.shape, \"val:\", val_df.shape, \"test:\", test_df.shape)\n",
    "print(\"check unique users:\", train_df[\"u\"].nunique(), val_df[\"u\"].nunique(), test_df[\"u\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78e5af5-534d-4281-a899-f3214a7da67d",
   "metadata": {},
   "source": [
    "## Build fast lookup structures for evaluation\r\n",
    "\r\n",
    "We prepare helper structures used in ranking evaluation:\r\n",
    "\r\n",
    "- `train_user_items[u]`: set of items already seen in training (to be **masked** in ranking)\r\n",
    "- `val_pos[u]`: the single positive target item for validation\r\n",
    "- `test_pos[u]`: the single positive target item for test\r\n",
    "\r\n",
    "This matches the standard \"leave-one-out + ranking\" evaluation setup:\r\n",
    "**recommend new items excluding those the user already interacted with intrain**.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "625f4d83-f3d5-462f-9de4-425fc42359c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53398, 9999)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user_items = defaultdict(set)\n",
    "for u, i in zip(train_df[\"u\"].to_numpy(), train_df[\"i\"].to_numpy()):\n",
    "    train_user_items[u].add(i)\n",
    "\n",
    "val_pos = dict(zip(val_df[\"u\"].to_numpy(), val_df[\"i\"].to_numpy()))\n",
    "test_pos = dict(zip(test_df[\"u\"].to_numpy(), test_df[\"i\"].to_numpy()))\n",
    "\n",
    "n_users, n_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eb40be-9f40-4e70-8116-2f3ba05b60f9",
   "metadata": {},
   "source": [
    "## Define ranking metrics (Hit@K, Recall@K, NDCG@K)\r\n",
    "\r\n",
    "We evaluate recommendations with **ranking metrics**:\r\n",
    "\r\n",
    "- **Hit@K**: whether the true held-out item is in top-K\r\n",
    "- **Recall@K**: with one positive item per user, recall@K == hit@K\r\n",
    "- **NDCG@K**: position-aware metric (higher if the item is ranked earlier)\r\n",
    "\r\n",
    "These metrics reflect recommender performance better than classification metrics (AUC/AP)\r\n",
    "because recommendation is fundamentally a *ranking*problem.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d17212df-a156-4f3d-9fa3-307a78b59f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_at_k(rank, k):\n",
    "    return 1.0 if rank < k else 0.0\n",
    "\n",
    "def recall_at_k(rank, k):\n",
    "    # при одном positive это то же самое, что hit@k\n",
    "    return 1.0 if rank < k else 0.0\n",
    "\n",
    "def ndcg_at_k(rank, k):\n",
    "    if rank >= k:\n",
    "        return 0.0\n",
    "    return 1.0 / np.log2(rank + 2)  # rank 0 -> log2(2)=1\n",
    "\n",
    "def evaluate_ranking(ranks, ks=(10, 20, 50)):\n",
    "    out = {}\n",
    "    ranks = np.asarray(ranks, dtype=np.int32)\n",
    "    for k in ks:\n",
    "        out[f\"hit@{k}\"] = float(np.mean([hit_at_k(r, k) for r in ranks]))\n",
    "        out[f\"recall@{k}\"] = float(np.mean([recall_at_k(r, k) for r in ranks]))\n",
    "        out[f\"ndcg@{k}\"] = float(np.mean([ndcg_at_k(r, k) for r in ranks]))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3020ddac-be34-4cbc-a3b5-3013da3264f7",
   "metadata": {},
   "source": [
    "## Popularity baseline (sanity check)\r\n",
    "\r\n",
    "Before training any model, we compute a simple baseline:\r\n",
    "\r\n",
    "- rank items by training popularity\r\n",
    "- for each user, recommend the most popular items **excluding seen items**\r\n",
    "- compute the rank of the held-out positive item\r\n",
    "\r\n",
    "This baseline provides a reference point:\r\n",
    "- if our model cannot beat popularity, something is wrong (split/leakage/training)\r\n",
    "- it also quantifies how much of the signal is \"global ppularity\"\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b6918c5-48e5-4dd6-a2ea-5aabc8eb06e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL popularity: {'hit@10': 0.04436495748904453, 'recall@10': 0.04436495748904453, 'ndcg@10': 0.025656646790484853, 'hit@20': 0.07284917038091314, 'recall@20': 0.07284917038091314, 'ndcg@20': 0.03284832700329946, 'hit@50': 0.1260159556537698, 'recall@50': 0.1260159556537698, 'ndcg@50': 0.04338053655791091}\n",
      "TEST popularity: {'hit@10': 0.04548859507846736, 'recall@10': 0.04548859507846736, 'ndcg@10': 0.025908327415101125, 'hit@20': 0.07309262519195475, 'recall@20': 0.07309262519195475, 'ndcg@20': 0.032838528907749166, 'hit@50': 0.12687741113899398, 'recall@50': 0.12687741113899398, 'ndcg@50': 0.043492052391389875}\n"
     ]
    }
   ],
   "source": [
    "item_pop = train_df[\"i\"].value_counts().sort_values(ascending=False)\n",
    "popular_items = item_pop.index.to_numpy()\n",
    "\n",
    "def rank_for_user(u, pos_item, train_user_items, popular_items, max_k=1000):\n",
    "    # возвращаем позицию pos_item в ранжированном списке (меньше = лучше)\n",
    "    rank = 0\n",
    "    for it in popular_items[:max_k]:\n",
    "        if it in train_user_items[u]:\n",
    "            continue\n",
    "        if it == pos_item:\n",
    "            return rank\n",
    "        rank += 1\n",
    "    return max_k  # не найден в топе\n",
    "\n",
    "def evaluate_popularity(pos_dict, ks=(10, 20, 50), max_k=5000):\n",
    "    ranks = []\n",
    "    for u, pos_item in pos_dict.items():\n",
    "        r = rank_for_user(u, pos_item, train_user_items, popular_items, max_k=max_k)\n",
    "        ranks.append(r)\n",
    "    return evaluate_ranking(ranks, ks=ks)\n",
    "\n",
    "print(\"VAL popularity:\", evaluate_popularity(val_pos))\n",
    "print(\"TEST popularity:\", evaluate_popularity(test_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e593dbc-f152-4edc-aefd-da1ca9e17e28",
   "metadata": {},
   "source": [
    "## Save processed splits and artifacts\r\n",
    "\r\n",
    "We save processed arrays for reproducibility and fast iteration:\r\n",
    "\r\n",
    "- `train_ui`, `val_ui`, `test_ui` as compact NumPy arrays of `(u, i)`\r\n",
    "- `n_users`, `n_items`\r\n",
    "- `popular_items` list for baseline/evaluation\r\n",
    "\r\n",
    "We use `.npz` / `.npy` to avoid optional parquet dependencies and to keep the pipeline lighweight.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2784448-4e4a-407a-ae57-0a290b58a009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\ML\\GNN\\graph_recsys\\data_processed\\v2_proper\\splits_ui.npz\n"
     ]
    }
   ],
   "source": [
    "# сохраним пары (u,i) как numpy\n",
    "train_ui = train_df[[\"u\",\"i\"]].to_numpy(dtype=np.int32)\n",
    "val_ui   = val_df[[\"u\",\"i\"]].to_numpy(dtype=np.int32)\n",
    "test_ui  = test_df[[\"u\",\"i\"]].to_numpy(dtype=np.int32)\n",
    "\n",
    "np.savez_compressed(\n",
    "    DATA_PROCESSED / \"splits_ui.npz\",\n",
    "    train_ui=train_ui,\n",
    "    val_ui=val_ui,\n",
    "    test_ui=test_ui,\n",
    "    n_users=np.int32(n_users),\n",
    "    n_items=np.int32(n_items),\n",
    ")\n",
    "\n",
    "# популярность тоже туда же\n",
    "np.save(DATA_PROCESSED / \"popular_items.npy\", popular_items.astype(np.int32))\n",
    "\n",
    "print(\"Saved:\", DATA_PROCESSED / \"splits_ui.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609b56d2-1441-467a-8e95-ba5ad990e6c1",
   "metadata": {},
   "source": [
    "## Load processed splits (UI format)\r\n",
    "\r\n",
    "We load the processed interaction splits saved earlier:\r\n",
    "\r\n",
    "- `train_ui`, `val_ui`, `test_ui` contain `(u, i)` pairs with **contiguous indices**\r\n",
    "- `n_users`, `n_items` define the bipartite graph size\r\n",
    "\r\n",
    "This keeps the training notebook lightweight: we don’t re-run heavy preprocessing ever time.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1b7e06-f08f-4912-bc42-04ff78e47117",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.load(DATA_PROCESSED / \"splits_ui.npz\")\n",
    "train_ui = z[\"train_ui\"]\n",
    "val_ui = z[\"val_ui\"]\n",
    "test_ui = z[\"test_ui\"]\n",
    "n_users = int(z[\"n_users\"])\n",
    "n_items = int(z[\"n_items\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f300e58d-c733-4f3c-97fa-e485e6e1eb18",
   "metadata": {},
   "source": [
    "## Build normalized bipartite adjacency matrix A_norm\r\n",
    "\r\n",
    "We build a **bipartite user–item graph** from training interactions only.\r\n",
    "\r\n",
    "Node indexing:\r\n",
    "- Users: `0 .. n_users-1`\r\n",
    "- Items:  `n_users .. n_users+n_items-1`\r\n",
    "\r\n",
    "We add edges in **both directions** (undirected graph) because LightGCN performs symmetric message passing.\r\n",
    "\r\n",
    "Normalization:\r\n",
    "- compute node degree `deg`\r\n",
    "- use symmetric normalization `D^{-1/2} A D^{-1/2}`\r\n",
    "- store it as a sparse matrix `A_norm` for efficient propagation\r\n",
    "\r\n",
    "Important: we normalize using only **train edges** to avoid evalation leakage.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "572fbc3b-c7ea-430a-a58c-645ad7617a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "A_norm: torch.Size([63397, 63397]) | nnz: 9852768\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "u = torch.from_numpy(train_ui[:, 0].astype(np.int64))\n",
    "i = torch.from_numpy(train_ui[:, 1].astype(np.int64)) + n_users\n",
    "\n",
    "row = torch.cat([u, i], dim=0)\n",
    "col = torch.cat([i, u], dim=0)\n",
    "\n",
    "num_nodes = n_users + n_items\n",
    "edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "deg = torch.bincount(edge_index[0], minlength=num_nodes).float()\n",
    "deg_inv_sqrt = deg.pow(-0.5)\n",
    "deg_inv_sqrt[torch.isinf(deg_inv_sqrt)] = 0.0\n",
    "\n",
    "edge_weight = deg_inv_sqrt[edge_index[0]] * deg_inv_sqrt[edge_index[1]]\n",
    "\n",
    "edge_index = edge_index.to(device)\n",
    "edge_weight = edge_weight.to(device)\n",
    "\n",
    "A_norm = torch.sparse_coo_tensor(\n",
    "    edge_index, edge_weight,\n",
    "    size=(num_nodes, num_nodes),\n",
    "    device=device\n",
    ").coalesce()\n",
    "\n",
    "print(\"A_norm:\", A_norm.shape, \"| nnz:\", A_norm._nnz())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793a0de1-9b8e-4999-82bd-1511cf0efaf8",
   "metadata": {},
   "source": [
    "## Define LightGCN (embedding + pure graph propagation)\r\n",
    "\r\n",
    "LightGCN is a strong baseline for collaborative filtering on bipartite graphs.\r\n",
    "\r\n",
    "Key properties:\r\n",
    "- each node has a learnable embedding (users + items)\r\n",
    "- propagation is pure neighborhood aggregation: `X_{k+1} = A_norm @ X_k`\r\n",
    "- final embedding is the mean of embeddings across layers (layer-wise averaging)\r\n",
    "\r\n",
    "Unlike classic GCN:\r\n",
    "- no feature MLP / weight matrices per layer\r\n",
    "- no nonlinearities\r\n",
    "This makes LightGCN simple, fast, and often very competitive for recmmendation.\r\n",
    "ation leakage.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f94025f-c8d2-4a4d-b2ae-e4f755e669f9",
   "metadata": {},
   "source": [
    "## BPR loss (Bayesian Personalized Ranking)\r\n",
    "\r\n",
    "We optimize a **pairwise ranking** objective:\r\n",
    "\r\n",
    "- positive interaction `(u, i+)` should score higher than\r\n",
    "- negative (unobserved) item `(u, i-)`\r\n",
    "\r\n",
    "BPR encourages correct ranking directly, which aligns with recommender metrics (Hit@K / NDCG@K)\r\n",
    "better than binary classificatin loss.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa4693a7-97eb-46ed-8e83-198dc171520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_dim=64, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_nodes = num_users + num_items\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(self.num_nodes, emb_dim)\n",
    "        nn.init.xavier_uniform_(self.embedding.weight)\n",
    "\n",
    "    def propagate(self, A_norm):\n",
    "        x0 = self.embedding.weight\n",
    "        xs = [x0]\n",
    "        x = x0\n",
    "        for _ in range(self.num_layers):\n",
    "            x = torch.sparse.mm(A_norm, x)\n",
    "            xs.append(x)\n",
    "        return torch.stack(xs, dim=0).mean(dim=0)\n",
    "\n",
    "    def forward(self, A_norm, users, pos_items, neg_items):\n",
    "        all_emb = self.propagate(A_norm)\n",
    "        user_emb = all_emb[:self.num_users]\n",
    "        item_emb = all_emb[self.num_users:]\n",
    "\n",
    "        u_e = user_emb[users]\n",
    "        p_e = item_emb[pos_items]\n",
    "        n_e = item_emb[neg_items]\n",
    "\n",
    "        pos_scores = (u_e * p_e).sum(dim=1)\n",
    "        neg_scores = (u_e * n_e).sum(dim=1)\n",
    "        return pos_scores, neg_scores\n",
    "\n",
    "def bpr_loss(pos_scores, neg_scores):\n",
    "    return -torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-12).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2dc47f-041e-451d-8aac-b0b84c0bb035",
   "metadata": {},
   "source": [
    "## Sample training mini-batches (positive + negative items)\r\n",
    "\r\n",
    "We train with mini-batches:\r\n",
    "\r\n",
    "- sample random users\r\n",
    "- for each user pick a **positive** item from their train history\r\n",
    "- sample a **negative** item not seen in train for that user\r\n",
    "\r\n",
    "This is standard implicit-feedback training.\r\n",
    "Note: pure uniform negative sampling is simple but not optimal; later we can try\r\n",
    "popularity-biased negatives or hard egatives.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f091945a-44ea-4af6-9445-a46e4a61a3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_batch(train_user_items, n_users, n_items, batch_size=4096, rng=None):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(42)\n",
    "\n",
    "    users = rng.integers(0, n_users, size=batch_size, endpoint=False)\n",
    "    pos_items = np.empty(batch_size, dtype=np.int64)\n",
    "    neg_items = np.empty(batch_size, dtype=np.int64)\n",
    "\n",
    "    for idx, u in enumerate(users):\n",
    "        u = int(u)\n",
    "        seen = train_user_items[u]\n",
    "        # pos\n",
    "        pos_items[idx] = rng.choice(list(seen))\n",
    "        # neg\n",
    "        while True:\n",
    "            ni = int(rng.integers(0, n_items, endpoint=False))\n",
    "            if ni not in seen:\n",
    "                neg_items[idx] = ni\n",
    "                break\n",
    "\n",
    "    return users.astype(np.int64), pos_items, neg_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f656b415-c966-4bed-9772-8977be7eb000",
   "metadata": {},
   "source": [
    "## Ranking evaluation via \"rank of the true held-out item\"\r\n",
    "\r\n",
    "For each user we have exactly **one positive target** in val/test (leave-one-out protocol).\r\n",
    "\r\n",
    "We compute:\r\n",
    "- score for all candidate items\r\n",
    "- mask items already seen in train (`train_user_items[u]`)\r\n",
    "- rank = number of items with score higher than the positive item\r\n",
    "\r\n",
    "Then we convert ranks into Hit@K / NDCG@K metrics.\r\n",
    "\r\n",
    "This is a direct, transparent evaluation approach:\r\n",
    "we measure if the model places the true item in the top-K recomendations.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c17e11e3-416b-4d7c-87f2-415fd0e68f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_all_user_item_emb(model, edge_index, edge_weight):\n",
    "    model.eval()\n",
    "    all_emb = model.propagate(edge_index, edge_weight)\n",
    "    user_emb = all_emb[:model.num_users]\n",
    "    item_emb = all_emb[model.num_users:]\n",
    "    return user_emb, item_emb\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_ranks_for_users(user_emb, item_emb, pos_dict, train_user_items, k_max=50, user_subset=None):\n",
    "    \"\"\"\n",
    "    Возвращает rank (0..inf) для positive item среди всех items (исключая seen).\n",
    "    Мы не строим полный sort — считаем rank через сравнение со score(pos).\n",
    "    \"\"\"\n",
    "    if user_subset is None:\n",
    "        users = list(pos_dict.keys())\n",
    "    else:\n",
    "        users = list(user_subset)\n",
    "\n",
    "    ranks = []\n",
    "    item_emb_T = item_emb.t()  # [d, n_items]\n",
    "\n",
    "    for u in users:\n",
    "        u = int(u)\n",
    "        pos_item = int(pos_dict[u])\n",
    "\n",
    "        # scores for all items\n",
    "        scores = (user_emb[u] @ item_emb_T).detach().cpu().numpy()  # [n_items]\n",
    "\n",
    "        # exclude seen (train items)\n",
    "        seen = train_user_items[u]\n",
    "        scores[list(seen)] = -1e9  # чтобы не попадали в top\n",
    "        pos_score = scores[pos_item]\n",
    "\n",
    "        # rank = сколько items имеют score > pos_score\n",
    "        rank = int(np.sum(scores > pos_score))\n",
    "        ranks.append(rank)\n",
    "\n",
    "    return ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c72b0c9-3a1c-4463-a9ad-b406a3d5312d",
   "metadata": {},
   "source": [
    "## Train LightGCN with BPR + evaluate on validation users\r\n",
    "\r\n",
    "Training setup:\r\n",
    "- LightGCN embeddings (dimension `EMB_DIM`)\r\n",
    "- `NUM_LAYERS` propagation steps\r\n",
    "- Adam optimizer (small weight decay for stability)\r\n",
    "\r\n",
    "Each epoch:\r\n",
    "1) run `STEPS` mini-batches of BPR updates\r\n",
    "2) compute validation ranks for a subset of users (`EVAL_USERS`) to keep evaluation fast\r\n",
    "3) track best model by **val NDCG@10**\r\n",
    "\r\n",
    "Notes:\r\n",
    "- evaluation subset speeds up iteration; final reporting should run on full val/test\r\n",
    "- epoch time depends mostly on sparse propagation + atch sampling\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5754f6fd-6721-4ee2-b184-0010ab06e0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 001] loss=0.4723 | val {'hit@10': 0.0504, 'recall@10': 0.0504, 'ndcg@10': 0.02793142752854441, 'hit@20': 0.0816, 'recall@20': 0.0816, 'ndcg@20': 0.035806972737550596, 'hit@50': 0.1414, 'recall@50': 0.1414, 'ndcg@50': 0.047699980305317885} | time=104.2s\n",
      "[Epoch 002] loss=0.3851 | val {'hit@10': 0.0566, 'recall@10': 0.0566, 'ndcg@10': 0.029975346021028623, 'hit@20': 0.0912, 'recall@20': 0.0912, 'ndcg@20': 0.03867671333302165, 'hit@50': 0.1534, 'recall@50': 0.1534, 'ndcg@50': 0.0509281504193389} | time=105.5s\n",
      "[Epoch 003] loss=0.3535 | val {'hit@10': 0.0598, 'recall@10': 0.0598, 'ndcg@10': 0.03138965625545384, 'hit@20': 0.0924, 'recall@20': 0.0924, 'ndcg@20': 0.039586826956874224, 'hit@50': 0.1616, 'recall@50': 0.1616, 'ndcg@50': 0.05324169363819383} | time=104.5s\n",
      "[Epoch 004] loss=0.3393 | val {'hit@10': 0.0614, 'recall@10': 0.0614, 'ndcg@10': 0.03273073024259129, 'hit@20': 0.0968, 'recall@20': 0.0968, 'ndcg@20': 0.041675894311533054, 'hit@50': 0.1614, 'recall@50': 0.1614, 'ndcg@50': 0.05440010963022043} | time=103.7s\n",
      "[Epoch 005] loss=0.3293 | val {'hit@10': 0.0658, 'recall@10': 0.0658, 'ndcg@10': 0.03469419489839685, 'hit@20': 0.1004, 'recall@20': 0.1004, 'ndcg@20': 0.04335884821454024, 'hit@50': 0.167, 'recall@50': 0.167, 'ndcg@50': 0.05646596823526892} | time=103.6s\n",
      "[Epoch 006] loss=0.3184 | val {'hit@10': 0.0694, 'recall@10': 0.0694, 'ndcg@10': 0.036538302995450994, 'hit@20': 0.1042, 'recall@20': 0.1042, 'ndcg@20': 0.04527489646969083, 'hit@50': 0.175, 'recall@50': 0.175, 'ndcg@50': 0.05916299550174235} | time=103.8s\n",
      "[Epoch 007] loss=0.3031 | val {'hit@10': 0.0742, 'recall@10': 0.0742, 'ndcg@10': 0.03956758758306267, 'hit@20': 0.1104, 'recall@20': 0.1104, 'ndcg@20': 0.04861246974759384, 'hit@50': 0.1824, 'recall@50': 0.1824, 'ndcg@50': 0.06270619944997347} | time=103.6s\n",
      "[Epoch 008] loss=0.2900 | val {'hit@10': 0.0754, 'recall@10': 0.0754, 'ndcg@10': 0.04099419056340193, 'hit@20': 0.1152, 'recall@20': 0.1152, 'ndcg@20': 0.05090961157660271, 'hit@50': 0.1882, 'recall@50': 0.1882, 'ndcg@50': 0.06523754422082896} | time=103.8s\n",
      "[Epoch 009] loss=0.2815 | val {'hit@10': 0.0772, 'recall@10': 0.0772, 'ndcg@10': 0.04179555584271518, 'hit@20': 0.1158, 'recall@20': 0.1158, 'ndcg@20': 0.0514300829126944, 'hit@50': 0.1914, 'recall@50': 0.1914, 'ndcg@50': 0.0663408743287976} | time=103.9s\n",
      "[Epoch 010] loss=0.2768 | val {'hit@10': 0.0792, 'recall@10': 0.0792, 'ndcg@10': 0.04221118957860664, 'hit@20': 0.1176, 'recall@20': 0.1176, 'ndcg@20': 0.05180244340337992, 'hit@50': 0.1944, 'recall@50': 0.1944, 'ndcg@50': 0.06695105015706988} | time=103.9s\n",
      "[Epoch 011] loss=0.2722 | val {'hit@10': 0.0772, 'recall@10': 0.0772, 'ndcg@10': 0.04177698277573768, 'hit@20': 0.1172, 'recall@20': 0.1172, 'ndcg@20': 0.05180299993077813, 'hit@50': 0.1946, 'recall@50': 0.1946, 'ndcg@50': 0.06710974367267675} | time=104.0s\n",
      "[Epoch 012] loss=0.2709 | val {'hit@10': 0.078, 'recall@10': 0.078, 'ndcg@10': 0.04224632710187862, 'hit@20': 0.1182, 'recall@20': 0.1182, 'ndcg@20': 0.05234580331502873, 'hit@50': 0.1954, 'recall@50': 0.1954, 'ndcg@50': 0.06758821236402614} | time=104.7s\n",
      "[Epoch 013] loss=0.2688 | val {'hit@10': 0.0786, 'recall@10': 0.0786, 'ndcg@10': 0.04310177180786684, 'hit@20': 0.1176, 'recall@20': 0.1176, 'ndcg@20': 0.05292838994666929, 'hit@50': 0.1962, 'recall@50': 0.1962, 'ndcg@50': 0.06844781860201778} | time=104.7s\n",
      "[Epoch 014] loss=0.2676 | val {'hit@10': 0.08, 'recall@10': 0.08, 'ndcg@10': 0.0431190085571127, 'hit@20': 0.1182, 'recall@20': 0.1182, 'ndcg@20': 0.052709850584332245, 'hit@50': 0.1968, 'recall@50': 0.1968, 'ndcg@50': 0.06823246753491885} | time=104.7s\n",
      "[Epoch 015] loss=0.2655 | val {'hit@10': 0.0792, 'recall@10': 0.0792, 'ndcg@10': 0.04266835691067183, 'hit@20': 0.1174, 'recall@20': 0.1174, 'ndcg@20': 0.05225736710251479, 'hit@50': 0.196, 'recall@50': 0.196, 'ndcg@50': 0.06786497300621161} | time=104.5s\n",
      "[Epoch 016] loss=0.2661 | val {'hit@10': 0.0792, 'recall@10': 0.0792, 'ndcg@10': 0.043180784118038766, 'hit@20': 0.1178, 'recall@20': 0.1178, 'ndcg@20': 0.05288510507166027, 'hit@50': 0.1956, 'recall@50': 0.1956, 'ndcg@50': 0.06832222619990638} | time=104.4s\n",
      "[Epoch 017] loss=0.2650 | val {'hit@10': 0.079, 'recall@10': 0.079, 'ndcg@10': 0.043582457935911464, 'hit@20': 0.1188, 'recall@20': 0.1188, 'ndcg@20': 0.05355126804691439, 'hit@50': 0.196, 'recall@50': 0.196, 'ndcg@50': 0.06883304776616116} | time=104.5s\n",
      "[Epoch 018] loss=0.2633 | val {'hit@10': 0.081, 'recall@10': 0.081, 'ndcg@10': 0.04387916393327597, 'hit@20': 0.119, 'recall@20': 0.119, 'ndcg@20': 0.053378994342622194, 'hit@50': 0.1978, 'recall@50': 0.1978, 'ndcg@50': 0.06892960751888585} | time=104.9s\n",
      "[Epoch 019] loss=0.2621 | val {'hit@10': 0.0812, 'recall@10': 0.0812, 'ndcg@10': 0.04376742457517084, 'hit@20': 0.121, 'recall@20': 0.121, 'ndcg@20': 0.05368227952022416, 'hit@50': 0.198, 'recall@50': 0.198, 'ndcg@50': 0.06889975768959132} | time=104.5s\n",
      "[Epoch 020] loss=0.2616 | val {'hit@10': 0.0814, 'recall@10': 0.0814, 'ndcg@10': 0.0439672951327678, 'hit@20': 0.1214, 'recall@20': 0.1214, 'ndcg@20': 0.05395444255862092, 'hit@50': 0.199, 'recall@50': 0.199, 'ndcg@50': 0.06933168726329678} | time=104.4s\n",
      "Best val ndcg@10: 0.0439672951327678\n"
     ]
    }
   ],
   "source": [
    "EMB_DIM = 64\n",
    "NUM_LAYERS = 3\n",
    "LR = 2e-3\n",
    "BATCH_SIZE = 4096\n",
    "EPOCHS = 20\n",
    "STEPS = 300\n",
    "EVAL_USERS = 5000\n",
    "KS = (10, 20, 50)\n",
    "\n",
    "model = LightGCN(n_users, n_items, emb_dim=EMB_DIM, num_layers=NUM_LAYERS).to(device)\n",
    "\n",
    "# вместо l2_reg — безопасный weight_decay\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-6)\n",
    "\n",
    "all_val_users = np.array(list(val_pos.keys()), dtype=np.int64)\n",
    "val_users_subset = rng.choice(all_val_users, size=min(EVAL_USERS, len(all_val_users)), replace=False)\n",
    "\n",
    "best_val_ndcg10 = -1.0\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for _ in range(STEPS):\n",
    "        users, pos_items, neg_items = sample_batch(train_user_items, n_users, n_items, BATCH_SIZE, rng=rng)\n",
    "\n",
    "        users = torch.from_numpy(users).to(device)\n",
    "        pos_items = torch.from_numpy(pos_items).to(device)\n",
    "        neg_items = torch.from_numpy(neg_items).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pos_scores, neg_scores = model(A_norm, users, pos_items, neg_items)\n",
    "        loss = bpr_loss(pos_scores, neg_scores)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_emb = model.propagate(A_norm)\n",
    "        user_emb = all_emb[:n_users]\n",
    "        item_emb = all_emb[n_users:]\n",
    "        ranks = compute_ranks_for_users(user_emb, item_emb, val_pos, train_user_items, user_subset=val_users_subset)\n",
    "        val_metrics = evaluate_ranking(ranks, ks=KS)\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    print(f\"[Epoch {epoch:03d}] loss={np.mean(losses):.4f} | val {val_metrics} | time={dt:.1f}s\")\n",
    "\n",
    "    if val_metrics[\"ndcg@10\"] > best_val_ndcg10:\n",
    "        best_val_ndcg10 = val_metrics[\"ndcg@10\"]\n",
    "        best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n",
    "\n",
    "print(\"Best val ndcg@10:\", best_val_ndcg10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c59dda-9e47-4f38-a8aa-d572539f363f",
   "metadata": {},
   "source": [
    "## Save best model checkpoint and experiment config\n",
    "\n",
    "We save the best model (by validation NDCG@10) into a timestamped run folder:\n",
    "\n",
    "- `lightgcn_best_state.pt`: model weights\n",
    "- `config.json`: all hyperparameters and best validation metrics\n",
    "\n",
    "This makes experiments reproducible and keeps results organized in `artifacts/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca062cca-4b24-45e2-9fc6-b7a4d243cad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: D:\\ML\\GNN\\graph_recsys\\artifacts\\v2_proper\\lightgcn_20251213_145944\n"
     ]
    }
   ],
   "source": [
    "ARTIFACTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_dir = ARTIFACTS / f\"lightgcn_{run_id}\"\n",
    "run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# сохраняем best веса\n",
    "torch.save(best_state, run_dir / \"lightgcn_best_state.pt\")\n",
    "\n",
    "# сохраняем конфиг\n",
    "config = {\n",
    "    \"emb_dim\": EMB_DIM,\n",
    "    \"num_layers\": NUM_LAYERS,\n",
    "    \"lr\": LR,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"steps_per_epoch\": STEPS,\n",
    "    \"eval_users\": EVAL_USERS,\n",
    "    \"best_val_ndcg10\": float(best_val_ndcg10),\n",
    "    \"best_val_metrics\": {k: float(v) for k, v in val_metrics.items()},\n",
    "}\n",
    "with open(run_dir / \"config.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(config, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Saved to:\", run_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7297a78-b662-4d10-80b1-65eac3b3affc",
   "metadata": {},
   "source": [
    "## Second model: alternative graph-based recommender (same pipeline, different architecture)\r\n",
    "\r\n",
    "After restarting the kernel, we reuse **exactly the same data pipeline and evaluation protocol**:\r\n",
    "\r\n",
    "- identical interaction construction (ratings ≥ threshold + to-read)\r\n",
    "- identical user/item filtering and indexing\r\n",
    "- the same leave-one-out split (train / validation / test)\r\n",
    "- the same ranking metrics (Hit@K, NDCG@K)\r\n",
    "- the same popularity baseline for reference\r\n",
    "\r\n",
    "This is intentional:  \r\n",
    "**the goal is to compare models under identical conditions**, not to re-optimize the pipeline each time.\r\n",
    "\r\n",
    "### What changes compared to the previous model\r\n",
    "\r\n",
    "Only the **model architecture and training objective** differ:\r\n",
    "\r\n",
    "- a different graph-based recommender is used\r\n",
    "- embeddings are learned and propagated through the same user–item graph\r\n",
    "- optimization may use a different loss (e.g. BPR / contrastive / pairwise)\r\n",
    "- training dynamics (loss scale, convergence speed) differ accordingly\r\n",
    "\r\n",
    "All other components — data splits, negative sampling logic, ranking evaluation — remain unchanged.\r\n",
    "\r\n",
    "### Why we do not repeat all code explanations here\r\n",
    "\r\n",
    "The following blocks reuse:\r\n",
    "- the same graph construction logic\r\n",
    "- the same batching and negative sampling ideas\r\n",
    "- the same evaluation functions\r\n",
    "\r\n",
    "Therefore, detailed explanations are provided **once** (in the first model section)  \r\n",
    "to avoid redundancy and keep the notebook readable.\r\n",
    "\r\n",
    "### Purpose of this section\r\n",
    "\r\n",
    "This section serves to:\r\n",
    "- verify that the pipeline is **model-agnostic**\r\n",
    "- compare architectures fairly on the same data\r\n",
    "- observe how different graph models behave under identical conditions\r\n",
    "\r\n",
    "Further improvements (graph enrichment, heterogeneity, edge weighing) are addressed in the next notebook.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "980a4e9d-b6b1-4503-b440-b2c342f5cde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "\n",
    "DATA_PROCESSED = Path(r\"D:\\ML\\GNN\\graph_recsys\\data_processed\\v2_proper\")\n",
    "ARTIFACTS = Path(r\"D:\\ML\\GNN\\graph_recsys\\artifacts\\v2_proper\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "rng = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d618ca96-9d0b-49f9-9d80-c592af839b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:\n",
      " train: (4926384, 2) val: (53398, 2) test: (53398, 2)\n",
      " n_users: 53398 n_items: 9999\n",
      " popular_items: (9999,) unique: 9999\n"
     ]
    }
   ],
   "source": [
    "z = np.load(DATA_PROCESSED / \"splits_ui.npz\")\n",
    "train_ui = z[\"train_ui\"].astype(np.int32)\n",
    "val_ui   = z[\"val_ui\"].astype(np.int32)\n",
    "test_ui  = z[\"test_ui\"].astype(np.int32)\n",
    "n_users = int(z[\"n_users\"])\n",
    "n_items = int(z[\"n_items\"])\n",
    "\n",
    "popular_items = np.load(DATA_PROCESSED / \"popular_items.npy\").astype(np.int32)\n",
    "\n",
    "train_user_items = defaultdict(set)\n",
    "for u, i in train_ui:\n",
    "    train_user_items[int(u)].add(int(i))\n",
    "\n",
    "val_pos  = {int(u): int(i) for u, i in val_ui}\n",
    "test_pos = {int(u): int(i) for u, i in test_ui}\n",
    "\n",
    "print(\"Loaded:\")\n",
    "print(\" train:\", train_ui.shape, \"val:\", val_ui.shape, \"test:\", test_ui.shape)\n",
    "print(\" n_users:\", n_users, \"n_items:\", n_items)\n",
    "print(\" popular_items:\", popular_items.shape, \"unique:\", len(np.unique(popular_items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc7cc719-e2d8-4778-963a-482a85d1adf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_norm: torch.Size([63397, 63397]) | nnz: 9852768\n"
     ]
    }
   ],
   "source": [
    "u = torch.from_numpy(train_ui[:, 0].astype(np.int64))\n",
    "i = torch.from_numpy(train_ui[:, 1].astype(np.int64)) + n_users\n",
    "\n",
    "row = torch.cat([u, i], dim=0)\n",
    "col = torch.cat([i, u], dim=0)\n",
    "\n",
    "num_nodes = n_users + n_items\n",
    "edge_index = torch.stack([row, col], dim=0)  # [2, 2E]\n",
    "\n",
    "deg = torch.bincount(edge_index[0], minlength=num_nodes).float()\n",
    "deg_inv_sqrt = deg.pow(-0.5)\n",
    "deg_inv_sqrt[torch.isinf(deg_inv_sqrt)] = 0.0\n",
    "\n",
    "edge_weight = deg_inv_sqrt[edge_index[0]] * deg_inv_sqrt[edge_index[1]]\n",
    "\n",
    "edge_index = edge_index.to(device)\n",
    "edge_weight = edge_weight.to(device)\n",
    "\n",
    "A_norm = torch.sparse_coo_tensor(\n",
    "    edge_index, edge_weight,\n",
    "    size=(num_nodes, num_nodes),\n",
    "    device=device\n",
    ").coalesce()\n",
    "\n",
    "print(\"A_norm:\", A_norm.shape, \"| nnz:\", A_norm._nnz())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cbf13e3-b0ed-45e8-bfe0-75def95190f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ranking(ranks, ks=(10, 20, 50)):\n",
    "    # ranks: list[int], where rank=0 means best item, etc.\n",
    "    ranks = np.asarray(ranks, dtype=np.int64)\n",
    "    out = {}\n",
    "    for k in ks:\n",
    "        hit = (ranks < k).mean()\n",
    "        out[f\"hit@{k}\"] = float(hit)\n",
    "        out[f\"recall@{k}\"] = float(hit)  # single positive per user => recall==hit\n",
    "        # ndcg for single positive\n",
    "        ndcg = np.where(ranks < k, 1.0 / np.log2(ranks + 2.0), 0.0).mean()\n",
    "        out[f\"ndcg@{k}\"] = float(ndcg)\n",
    "    return out\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_ranks_for_users(user_emb, item_emb, pos_dict, train_user_items, user_subset=None):\n",
    "    if user_subset is None:\n",
    "        users = list(pos_dict.keys())\n",
    "    else:\n",
    "        users = list(user_subset)\n",
    "\n",
    "    item_emb_T = item_emb.t()  # [d, n_items]\n",
    "    ranks = []\n",
    "\n",
    "    for u in users:\n",
    "        u = int(u)\n",
    "        pos_item = int(pos_dict[u])\n",
    "\n",
    "        scores = (user_emb[u] @ item_emb_T).detach().cpu().numpy()  # [n_items]\n",
    "        seen = train_user_items[u]\n",
    "        if seen:\n",
    "            scores[list(seen)] = -1e9\n",
    "        pos_score = scores[pos_item]\n",
    "        rank = int(np.sum(scores > pos_score))\n",
    "        ranks.append(rank)\n",
    "\n",
    "    return ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "394c6c4f-da6f-415e-b687-559a81e9908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_dim=64, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_nodes = num_users + num_items\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(self.num_nodes, emb_dim)\n",
    "        nn.init.xavier_uniform_(self.embedding.weight)\n",
    "\n",
    "    def propagate(self, A_norm):\n",
    "        x0 = self.embedding.weight\n",
    "        xs = [x0]\n",
    "        x = x0\n",
    "        for _ in range(self.num_layers):\n",
    "            x = torch.sparse.mm(A_norm, x)\n",
    "            xs.append(x)\n",
    "        return torch.stack(xs, dim=0).mean(dim=0)\n",
    "\n",
    "    def forward(self, A_norm, users, pos_items, neg_items):\n",
    "        all_emb = self.propagate(A_norm)\n",
    "        user_emb = all_emb[:self.num_users]\n",
    "        item_emb = all_emb[self.num_users:]\n",
    "\n",
    "        u_e = user_emb[users]\n",
    "        p_e = item_emb[pos_items]\n",
    "        n_e = item_emb[neg_items]\n",
    "\n",
    "        pos_scores = (u_e * p_e).sum(dim=1)\n",
    "        neg_scores = (u_e * n_e).sum(dim=1)\n",
    "        return pos_scores, neg_scores\n",
    "\n",
    "def bpr_loss(pos_scores, neg_scores):\n",
    "    return -torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-12).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc40c504-d48a-48e6-8bde-3fcda803bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# настройки hard negatives\n",
    "TOPK_NEG = 2000          # пул популярных для negatives\n",
    "P_POP_NEG = 0.7          # вероятность взять neg из popular pool\n",
    "\n",
    "popular_pool = popular_items[:min(TOPK_NEG, len(popular_items))].astype(np.int64)\n",
    "\n",
    "def sample_batch_hard(train_user_items, n_users, n_items, batch_size=4096, rng=None):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(42)\n",
    "\n",
    "    users = rng.integers(0, n_users, size=batch_size, endpoint=False)\n",
    "    pos_items = np.empty(batch_size, dtype=np.int64)\n",
    "    neg_items = np.empty(batch_size, dtype=np.int64)\n",
    "\n",
    "    for idx, u in enumerate(users):\n",
    "        u = int(u)\n",
    "        seen = train_user_items[u]\n",
    "\n",
    "        # positive\n",
    "        pos_items[idx] = rng.choice(list(seen))\n",
    "\n",
    "        # negative (hard)\n",
    "        while True:\n",
    "            if rng.random() < P_POP_NEG:\n",
    "                ni = int(rng.choice(popular_pool))\n",
    "            else:\n",
    "                ni = int(rng.integers(0, n_items, endpoint=False))\n",
    "            if ni not in seen:\n",
    "                neg_items[idx] = ni\n",
    "                break\n",
    "\n",
    "    return users.astype(np.int64), pos_items, neg_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "311d07fd-d24a-4283-bea0-e0e00e12a5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 001] loss=0.5759 | val {'hit@10': 0.0546, 'recall@10': 0.0546, 'ndcg@10': 0.028216020367364956, 'hit@20': 0.0864, 'recall@20': 0.0864, 'ndcg@20': 0.036172434707701685, 'hit@50': 0.157, 'recall@50': 0.157, 'ndcg@50': 0.050158361440504215} | time=107.4s\n",
      "[Epoch 002] loss=0.4706 | val {'hit@10': 0.0666, 'recall@10': 0.0666, 'ndcg@10': 0.03628392834314441, 'hit@20': 0.105, 'recall@20': 0.105, 'ndcg@20': 0.04590641587142754, 'hit@50': 0.1814, 'recall@50': 0.1814, 'ndcg@50': 0.06101243575589649} | time=108.6s\n",
      "[Epoch 003] loss=0.4253 | val {'hit@10': 0.0694, 'recall@10': 0.0694, 'ndcg@10': 0.038178567919614076, 'hit@20': 0.1136, 'recall@20': 0.1136, 'ndcg@20': 0.04929299762774982, 'hit@50': 0.1912, 'recall@50': 0.1912, 'ndcg@50': 0.06460546630653431} | time=107.5s\n",
      "[Epoch 004] loss=0.4051 | val {'hit@10': 0.0734, 'recall@10': 0.0734, 'ndcg@10': 0.039736806478453755, 'hit@20': 0.1194, 'recall@20': 0.1194, 'ndcg@20': 0.05131958004273017, 'hit@50': 0.1986, 'recall@50': 0.1986, 'ndcg@50': 0.06687344212537338} | time=107.6s\n",
      "[Epoch 005] loss=0.3921 | val {'hit@10': 0.077, 'recall@10': 0.077, 'ndcg@10': 0.04126172988921379, 'hit@20': 0.1206, 'recall@20': 0.1206, 'ndcg@20': 0.05225454106566957, 'hit@50': 0.2014, 'recall@50': 0.2014, 'ndcg@50': 0.06820190459291202} | time=107.5s\n",
      "[Epoch 006] loss=0.3821 | val {'hit@10': 0.08, 'recall@10': 0.08, 'ndcg@10': 0.0427304752572123, 'hit@20': 0.1232, 'recall@20': 0.1232, 'ndcg@20': 0.053631695292516546, 'hit@50': 0.2076, 'recall@50': 0.2076, 'ndcg@50': 0.07033627629506517} | time=107.6s\n",
      "[Epoch 007] loss=0.3733 | val {'hit@10': 0.0812, 'recall@10': 0.0812, 'ndcg@10': 0.043438079498614585, 'hit@20': 0.1258, 'recall@20': 0.1258, 'ndcg@20': 0.05469049317660778, 'hit@50': 0.2114, 'recall@50': 0.2114, 'ndcg@50': 0.07163167971627013} | time=108.0s\n",
      "[Epoch 008] loss=0.3662 | val {'hit@10': 0.0834, 'recall@10': 0.0834, 'ndcg@10': 0.04406916534794309, 'hit@20': 0.1302, 'recall@20': 0.1302, 'ndcg@20': 0.05575462025430743, 'hit@50': 0.2182, 'recall@50': 0.2182, 'ndcg@50': 0.07323703152947304} | time=106.2s\n",
      "[Epoch 009] loss=0.3602 | val {'hit@10': 0.0886, 'recall@10': 0.0886, 'ndcg@10': 0.045899768901234164, 'hit@20': 0.1354, 'recall@20': 0.1354, 'ndcg@20': 0.0576002353072377, 'hit@50': 0.222, 'recall@50': 0.222, 'ndcg@50': 0.07474541591890065} | time=106.3s\n",
      "[Epoch 010] loss=0.3550 | val {'hit@10': 0.0874, 'recall@10': 0.0874, 'ndcg@10': 0.047242429201535104, 'hit@20': 0.1374, 'recall@20': 0.1374, 'ndcg@20': 0.05980526122410247, 'hit@50': 0.2288, 'recall@50': 0.2288, 'ndcg@50': 0.07782496124812951} | time=106.3s\n",
      "[Epoch 011] loss=0.3518 | val {'hit@10': 0.0872, 'recall@10': 0.0872, 'ndcg@10': 0.04817748225162353, 'hit@20': 0.137, 'recall@20': 0.137, 'ndcg@20': 0.06066596549020065, 'hit@50': 0.2286, 'recall@50': 0.2286, 'ndcg@50': 0.07870678799902649} | time=106.3s\n",
      "[Epoch 012] loss=0.3492 | val {'hit@10': 0.0906, 'recall@10': 0.0906, 'ndcg@10': 0.048817041034111365, 'hit@20': 0.1384, 'recall@20': 0.1384, 'ndcg@20': 0.060818841363540606, 'hit@50': 0.2298, 'recall@50': 0.2298, 'ndcg@50': 0.07888374639001147} | time=106.3s\n",
      "[Epoch 013] loss=0.3473 | val {'hit@10': 0.0898, 'recall@10': 0.0898, 'ndcg@10': 0.04886539604550195, 'hit@20': 0.1386, 'recall@20': 0.1386, 'ndcg@20': 0.061076993013974075, 'hit@50': 0.2306, 'recall@50': 0.2306, 'ndcg@50': 0.0792761118267877} | time=106.5s\n",
      "[Epoch 014] loss=0.3456 | val {'hit@10': 0.0902, 'recall@10': 0.0902, 'ndcg@10': 0.04942086678665905, 'hit@20': 0.1384, 'recall@20': 0.1384, 'ndcg@20': 0.06151688845410681, 'hit@50': 0.234, 'recall@50': 0.234, 'ndcg@50': 0.08040057690614189} | time=106.5s\n",
      "[Epoch 015] loss=0.3447 | val {'hit@10': 0.0896, 'recall@10': 0.0896, 'ndcg@10': 0.04899997136693234, 'hit@20': 0.1396, 'recall@20': 0.1396, 'ndcg@20': 0.061458172000637704, 'hit@50': 0.234, 'recall@50': 0.234, 'ndcg@50': 0.08009728915636379} | time=106.4s\n",
      "[Epoch 016] loss=0.3437 | val {'hit@10': 0.0908, 'recall@10': 0.0908, 'ndcg@10': 0.048959994235306954, 'hit@20': 0.1414, 'recall@20': 0.1414, 'ndcg@20': 0.06160665572536381, 'hit@50': 0.2328, 'recall@50': 0.2328, 'ndcg@50': 0.07973241252089067} | time=106.2s\n",
      "[Epoch 017] loss=0.3431 | val {'hit@10': 0.0898, 'recall@10': 0.0898, 'ndcg@10': 0.0483622055775877, 'hit@20': 0.1396, 'recall@20': 0.1396, 'ndcg@20': 0.060854096403930066, 'hit@50': 0.2328, 'recall@50': 0.2328, 'ndcg@50': 0.07939163976753352} | time=106.3s\n",
      "[Epoch 018] loss=0.3424 | val {'hit@10': 0.0908, 'recall@10': 0.0908, 'ndcg@10': 0.048837883426715474, 'hit@20': 0.141, 'recall@20': 0.141, 'ndcg@20': 0.061384882250013234, 'hit@50': 0.235, 'recall@50': 0.235, 'ndcg@50': 0.07998988762075417} | time=106.4s\n",
      "[Epoch 019] loss=0.3417 | val {'hit@10': 0.0932, 'recall@10': 0.0932, 'ndcg@10': 0.04981368696605072, 'hit@20': 0.1416, 'recall@20': 0.1416, 'ndcg@20': 0.06186535922085339, 'hit@50': 0.2318, 'recall@50': 0.2318, 'ndcg@50': 0.0797562654920275} | time=106.4s\n",
      "[Epoch 020] loss=0.3415 | val {'hit@10': 0.0896, 'recall@10': 0.0896, 'ndcg@10': 0.04889269585169746, 'hit@20': 0.1406, 'recall@20': 0.1406, 'ndcg@20': 0.06170090356957392, 'hit@50': 0.2342, 'recall@50': 0.2342, 'ndcg@50': 0.08022404395773922} | time=106.3s\n",
      "Best val ndcg@10: 0.04981368696605072 | best metrics: {'hit@10': 0.0932, 'recall@10': 0.0932, 'ndcg@10': 0.04981368696605072, 'hit@20': 0.1416, 'recall@20': 0.1416, 'ndcg@20': 0.06186535922085339, 'hit@50': 0.2318, 'recall@50': 0.2318, 'ndcg@50': 0.0797562654920275}\n"
     ]
    }
   ],
   "source": [
    "EMB_DIM = 64\n",
    "NUM_LAYERS = 3\n",
    "LR = 2e-3\n",
    "WEIGHT_DECAY = 1e-6\n",
    "\n",
    "BATCH_SIZE = 4096\n",
    "EPOCHS = 20\n",
    "STEPS = 300\n",
    "EVAL_USERS = 5000\n",
    "KS = (10, 20, 50)\n",
    "\n",
    "model = LightGCN(n_users, n_items, emb_dim=EMB_DIM, num_layers=NUM_LAYERS).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "all_val_users = np.array(list(val_pos.keys()), dtype=np.int64)\n",
    "val_users_subset = rng.choice(all_val_users, size=min(EVAL_USERS, len(all_val_users)), replace=False)\n",
    "\n",
    "best_val_ndcg10 = -1.0\n",
    "best_state = None\n",
    "best_metrics = None\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for _ in range(STEPS):\n",
    "        users, pos_items, neg_items = sample_batch_hard(\n",
    "            train_user_items, n_users, n_items,\n",
    "            batch_size=BATCH_SIZE, rng=rng\n",
    "        )\n",
    "        users = torch.from_numpy(users).to(device)\n",
    "        pos_items = torch.from_numpy(pos_items).to(device)\n",
    "        neg_items = torch.from_numpy(neg_items).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pos_scores, neg_scores = model(A_norm, users, pos_items, neg_items)\n",
    "        loss = bpr_loss(pos_scores, neg_scores)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_emb = model.propagate(A_norm)\n",
    "        user_emb = all_emb[:n_users]\n",
    "        item_emb = all_emb[n_users:]\n",
    "        ranks = compute_ranks_for_users(user_emb, item_emb, val_pos, train_user_items, user_subset=val_users_subset)\n",
    "        val_metrics = evaluate_ranking(ranks, ks=KS)\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    print(f\"[Epoch {epoch:03d}] loss={np.mean(losses):.4f} | val {val_metrics} | time={dt:.1f}s\")\n",
    "\n",
    "    if val_metrics[\"ndcg@10\"] > best_val_ndcg10:\n",
    "        best_val_ndcg10 = val_metrics[\"ndcg@10\"]\n",
    "        best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n",
    "        best_metrics = val_metrics.copy()\n",
    "\n",
    "print(\"Best val ndcg@10:\", best_val_ndcg10, \"| best metrics:\", best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23987ed3-5831-4ae5-bb6d-da750cf6bfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a8d36f578a4d94885b39ca81abab53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Full TEST ranks:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL TEST metrics: {'hit@10': 0.08421663732724072, 'recall@10': 0.08421663732724072, 'ndcg@10': 0.04552879810597425, 'hit@20': 0.12886250421364095, 'recall@20': 0.12886250421364095, 'ndcg@20': 0.056736608678710554, 'hit@50': 0.22058878609685756, 'recall@50': 0.22058878609685756, 'ndcg@50': 0.07481866735724439}\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def compute_ranks_for_users_batched(user_emb, item_emb, pos_dict, train_user_items, users, batch_size=512):\n",
    "    \"\"\"\n",
    "    users: np.array of user ids (int)\n",
    "    pos_dict: dict u -> pos_item\n",
    "    train_user_items: dict u -> set(seen_items)  (только train!)\n",
    "    \"\"\"\n",
    "    user_emb = user_emb.to(device)\n",
    "    item_emb = item_emb.to(device)\n",
    "    item_emb_T = item_emb.t().contiguous()  # [d, n_items]\n",
    "\n",
    "    ranks = np.empty(len(users), dtype=np.int64)\n",
    "\n",
    "    for start in tqdm(range(0, len(users), batch_size), desc=\"Full TEST ranks\"):\n",
    "        end = min(start + batch_size, len(users))\n",
    "        batch_users = users[start:end]\n",
    "        bu = torch.from_numpy(batch_users).to(device)  # [B]\n",
    "\n",
    "        # scores: [B, n_items]\n",
    "        scores = (user_emb[bu] @ item_emb_T)  # GPU matmul\n",
    "\n",
    "        # переносим на CPU для удобного маскинга питоном по sets\n",
    "        scores_cpu = scores.detach().cpu().numpy()\n",
    "\n",
    "        for j, u in enumerate(batch_users):\n",
    "            u = int(u)\n",
    "            pos_item = int(pos_dict[u])\n",
    "\n",
    "            # mask seen items from TRAIN\n",
    "            seen = train_user_items[u]\n",
    "            if seen:\n",
    "                scores_cpu[j, list(seen)] = -1e9\n",
    "\n",
    "            pos_score = scores_cpu[j, pos_item]\n",
    "            rank = int(np.sum(scores_cpu[j] > pos_score))\n",
    "            ranks[start + j] = rank\n",
    "\n",
    "    return ranks\n",
    "\n",
    "# --- FULL TEST evaluation (all users) ---\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    all_emb = model.propagate(A_norm)\n",
    "    user_emb = all_emb[:n_users]\n",
    "    item_emb = all_emb[n_users:]\n",
    "\n",
    "full_test_users = np.array(list(test_pos.keys()), dtype=np.int64)\n",
    "\n",
    "ranks_full_test = compute_ranks_for_users_batched(\n",
    "    user_emb=user_emb,\n",
    "    item_emb=item_emb,\n",
    "    pos_dict=test_pos,\n",
    "    train_user_items=train_user_items,\n",
    "    users=full_test_users,\n",
    "    batch_size=512  # можно 256 если память/скорость будут капризничать\n",
    ")\n",
    "\n",
    "full_test_metrics = evaluate_ranking(ranks_full_test, ks=(10,20,50))\n",
    "print(\"FULL TEST metrics:\", full_test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00f0ea26-2583-42ba-abf9-27dcf7242780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: D:\\ML\\GNN\\graph_recsys\\artifacts\\v2_proper\\lightgcn_hardneg_20251213_160028\n"
     ]
    }
   ],
   "source": [
    "ARTIFACTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_dir = ARTIFACTS / f\"lightgcn_hardneg_{run_id}\"\n",
    "run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "torch.save(best_state, run_dir / \"lightgcn_best_state.pt\")\n",
    "\n",
    "config = {\n",
    "    \"model\": \"LightGCN\",\n",
    "    \"variant\": \"hardneg_popularity\",\n",
    "    \"emb_dim\": EMB_DIM,\n",
    "    \"num_layers\": NUM_LAYERS,\n",
    "    \"lr\": LR,\n",
    "    \"weight_decay\": WEIGHT_DECAY,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"steps_per_epoch\": STEPS,\n",
    "    \"topk_neg_pool\": int(TOPK_NEG),\n",
    "    \"p_pop_neg\": float(P_POP_NEG),\n",
    "    \"eval_users_val\": int(EVAL_USERS),\n",
    "    \"eval_users_test\": int(EVAL_TEST_USERS),\n",
    "    \"best_val_ndcg10\": float(best_val_ndcg10),\n",
    "    \"best_val_metrics\": {k: float(v) for k, v in (best_metrics or {}).items()},\n",
    "    \"test_subset_metrics\": {k: float(v) for k, v in test_metrics.items()},\n",
    "}\n",
    "\n",
    "with open(run_dir / \"config.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(config, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Saved to:\", run_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8b5e2f-3f22-4bf5-a113-2c5de82a828a",
   "metadata": {},
   "source": [
    "# Results and Conclusions\n",
    "\n",
    "## Quantitative Results (Full Test Set)\n",
    "\n",
    "The final evaluation on the **full test set** (≈53k users, ≈10k items) yields:\n",
    "\n",
    "- **Hit@10** ≈ 0.084  \n",
    "- **NDCG@10** ≈ 0.045  \n",
    "- **Hit@20** ≈ 0.129  \n",
    "- **NDCG@20** ≈ 0.057  \n",
    "- **Hit@50** ≈ 0.221  \n",
    "- **NDCG@50** ≈ 0.075  \n",
    "\n",
    "Compared to a popularity-based baseline, this represents a **1.5–2× improvement**\n",
    "across ranking metrics.\n",
    "\n",
    "## Interpretation\n",
    "\n",
    "These results confirm several important points:\n",
    "\n",
    "1. **The training and evaluation pipeline is correct**\n",
    "   - Proper split\n",
    "   - Proper metrics\n",
    "   - No data leakage\n",
    "\n",
    "2. **LightGCN effectively captures collaborative signals**\n",
    "   from the user–item interaction graph.\n",
    "\n",
    "3. At the same time, the model reaches a **clear performance plateau**.\n",
    "\n",
    "This plateau is **not caused by model capacity or optimization issues**, but by\n",
    "the **limited information content of the pure user–item graph**.\n",
    "\n",
    "## Key Insight\n",
    "\n",
    "> Pure collaborative filtering on GoodBooks-10k saturates around  \n",
    "> **NDCG@10 ≈ 0.04–0.05**.\n",
    "\n",
    "Further architectural complexity (e.g. GAT, Graph Transformers) **will not lead to\n",
    "significant gains** without introducing additional signals.\n",
    "\n",
    "## Why This Notebook Matters\n",
    "\n",
    "This notebook is intentionally positioned as:\n",
    "\n",
    "- a **baseline**\n",
    "- a **pipeline validation**\n",
    "- a **reference point**\n",
    "\n",
    "It is **not** meant to be the final recommender system, but rather a solid foundation\n",
    "for further work.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "In the next notebook, we move beyond pure collaborative filtering and **augment the graph**\n",
    "with additional information:\n",
    "\n",
    "- Book–tag relationships\n",
    "- Content-aware connections\n",
    "- Hybrid graph structures\n",
    "\n",
    "The goal is to inject **new semantic signals** into the graph and push recommendation\n",
    "quality beyond the collaborative filtering ceiling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - GNN (clean)",
   "language": "python",
   "name": "gnn_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
