{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9cef4c4-3a5d-468e-9683-66074d38d41e",
   "metadata": {},
   "source": [
    "# 03 — Ablation study on Graph3 (Goodbooks-10k GNN Recsys)\n",
    "\n",
    "This notebook answers a simple but crucial question:\n",
    "\n",
    "> **Which relation groups in Graph3 actually improve recommendation quality?**\n",
    "\n",
    "We already have a strong **Graph3** constructed in a unified node-id space:\n",
    "- **Users**, **Books**, and content/context nodes (**Tags**, **Authors**, **Language**, **Year bins**)\n",
    "- Weighted edges:\n",
    "  - user ↔ book (TRAIN only)\n",
    "  - book ↔ tag (weight = log1p(tag_count))\n",
    "  - book ↔ book (TF-IDF cosine similarity, top-K neighbors, pruned by min similarity)\n",
    "  - book ↔ author (1.0)\n",
    "  - book ↔ language (1.0)\n",
    "  - book ↔ year_bin (1.0)\n",
    "\n",
    "The goal is **not** to redesign the graph anymore (we consider it maxed out with available Goodbooks signals),\n",
    "but to **quantify the contribution** of each relation group via systematic ablations.\n",
    "\n",
    "## Task setup\n",
    "\n",
    "- **Model:** LightGCN (3 layers, embedding dim = 64)  \n",
    "- **Loss:** BPR with negative sampling (negatives exclude seen TRAIN positives)\n",
    "- **Split:** leave-one-out (LOO)\n",
    "  - for each user: 1 validation item, 1 test item\n",
    "- **Metrics:** Hit@K / NDCG@K (K ∈ {10, 20, 50})\n",
    "\n",
    "## What “ablation” means here\n",
    "\n",
    "We start from the FULL Graph3 and create variants by removing a relation group:\n",
    "\n",
    "- **−book_sim**: remove book↔book similarity edges  \n",
    "- **−book_tag**: remove book↔tag edges  \n",
    "- **−book_author**: remove book↔author edges  \n",
    "- **−book_lang**: remove book↔language edges  \n",
    "- **−book_year**: remove book↔year_bin edges  \n",
    "\n",
    "We also run useful baselines:\n",
    "- **ONLY_user_book**: only the user↔book bipartite graph\n",
    "- **user_book+tag**: bipartite + tag relations\n",
    "\n",
    "Each variant rebuilds the normalized adjacency and trains LightGCN with **the same training loop and eval**.\n",
    "\n",
    "## Expected outcome\n",
    "\n",
    "A final table ranking variants by **TEST NDCG@10**, plus deltas relative to FULL.\n",
    "\n",
    "This tells us:\n",
    "1) which relations are true “signal” vs “noise”,  \n",
    "2) what to emphasize in the next notebooks (HeteroGNN / HGT / sampling / attention),  \n",
    "3) which components are safe to drop for faster training without losing quality.\n",
    "\n",
    "## Loaded bundle (already prepared)\n",
    "\n",
    "We load a saved Graph3 bundle from:\n",
    "\n",
    "`D:/ML/GNN/graph_recsys/artifacts/v2_proper/graph3_bundle`\n",
    "\n",
    "It contains:\n",
    "- sparse normalized adjacency `A_norm`\n",
    "- raw edges `edge_index`, weights `edge_w`\n",
    "- typed relations `edge_type` and mapping `rel2id`\n",
    "- fixed LOO splits `train_ui / val_ui / test_ui`\n",
    "- offsets and vocabularies for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e8cea90-cc7f-4746-a6d1-87e7569d7067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Cell 1: Imports + seed\n",
    "# ============================\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32853b05-8e3f-4397-8caf-2631a58f0b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 1b: Reproducibility\n",
    "# ============================\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c723456b-6585-4448-96fe-8f67a2113a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUNDLE_DIR: D:\\ML\\GNN\\graph_recsys\\artifacts\\v2_proper\\graph3_bundle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\555\\AppData\\Local\\Temp\\ipykernel_15212\\2403994732.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  g = torch.load(BUNDLE_DIR / \"graph3_state.pt\", map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: num_nodes=74285, E=11450076, U=53398, B=9999, rels=11\n",
      "Relations: {'user_book': 0, 'book_user': 1, 'book_tag': 2, 'tag_book': 3, 'book_book_sim': 4, 'book_author': 5, 'author_book': 6, 'book_lang': 7, 'lang_book': 8, 'book_year': 9, 'year_book': 10}\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 2: Paths + load bundle\n",
    "# ============================\n",
    "PROJECT_ROOT = Path(r\"D:/ML/GNN/graph_recsys\")\n",
    "ARTIFACTS = PROJECT_ROOT / \"artifacts\" / \"v2_proper\"\n",
    "BUNDLE_DIR = ARTIFACTS / \"graph3_bundle\"\n",
    "\n",
    "assert BUNDLE_DIR.exists(), f\"Missing bundle dir: {BUNDLE_DIR}\"\n",
    "print(\"BUNDLE_DIR:\", BUNDLE_DIR)\n",
    "\n",
    "g = torch.load(BUNDLE_DIR / \"graph3_state.pt\", map_location=\"cpu\")\n",
    "z = np.load(BUNDLE_DIR / \"splits_ui.npz\", allow_pickle=True)\n",
    "\n",
    "A_norm_full = g[\"A_norm\"]                 # sparse normalized adjacency (full Graph3)\n",
    "edge_index_full = g[\"edge_index\"]         # [2, E]\n",
    "edge_w_full = g[\"edge_w\"]                 # [E]\n",
    "edge_type_full = g[\"edge_type\"]           # [E]\n",
    "rel2id = g[\"rel2id\"]                      # dict[str,int]\n",
    "offsets = g[\"offsets\"]\n",
    "num_nodes = int(g[\"num_nodes\"])\n",
    "\n",
    "train_ui = z[\"train_ui\"].astype(np.int64) # [N_train, 2] (user_idx, book_idx)\n",
    "val_ui   = z[\"val_ui\"].astype(np.int64)   # [U, 2] LOO\n",
    "test_ui  = z[\"test_ui\"].astype(np.int64)  # [U, 2] LOO\n",
    "U = int(z[\"U\"]); B = int(z[\"B\"])\n",
    "\n",
    "print(f\"Loaded: num_nodes={num_nodes}, E={edge_index_full.shape[1]}, U={U}, B={B}, rels={len(rel2id)}\")\n",
    "print(\"Relations:\", rel2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e4fdf98-bf05-486f-bbb7-1880385a91f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_check: (74285, 74285) nnz: 11260518\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 3: Helpers (filter edges + rebuild normalized adjacency)\n",
    "# ============================\n",
    "def filter_edges_by_rel(edge_index, edge_w, edge_type, keep_rel_ids):\n",
    "    \"\"\"\n",
    "    Возвращает подграф, содержащий только ребра с типами из keep_rel_ids.\n",
    "    \"\"\"\n",
    "    keep_rel_ids = set(int(x) for x in keep_rel_ids)\n",
    "    mask = torch.zeros_like(edge_type, dtype=torch.bool)\n",
    "    for rid in keep_rel_ids:\n",
    "        mask |= (edge_type == rid)\n",
    "\n",
    "    ei = edge_index[:, mask]\n",
    "    ew = edge_w[mask]\n",
    "    et = edge_type[mask]\n",
    "    return ei, ew, et\n",
    "\n",
    "def build_sparse_norm(edge_index, edge_w, num_nodes):\n",
    "    \"\"\"\n",
    "    Symmetric norm: D^{-1/2} A D^{-1/2}\n",
    "    where degree is weighted sum over outgoing edges (row).\n",
    "    Assumes graph is already undirected by construction (we stored both directions).\n",
    "    \"\"\"\n",
    "    row = edge_index[0]\n",
    "    col = edge_index[1]\n",
    "    val = edge_w.float()\n",
    "\n",
    "    deg = torch.zeros(num_nodes, dtype=torch.float32)\n",
    "    deg.scatter_add_(0, row, val)\n",
    "    deg = torch.clamp(deg, min=1e-12)\n",
    "\n",
    "    inv_sqrt = deg.pow(-0.5)\n",
    "    norm_val = inv_sqrt[row] * val * inv_sqrt[col]\n",
    "\n",
    "    A = torch.sparse_coo_tensor(edge_index, norm_val, (num_nodes, num_nodes), dtype=torch.float32).coalesce()\n",
    "    return A\n",
    "\n",
    "# sanity check: rebuild should match shape\n",
    "A_check = build_sparse_norm(edge_index_full, edge_w_full, num_nodes)\n",
    "print(\"A_check:\", tuple(A_check.shape), \"nnz:\", int(A_check._nnz()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "284bbd7e-ff78-4c1e-b361-cb8eb0d3fcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Cell 4: LightGCN model\n",
    "# ============================\n",
    "class LightGCN(torch.nn.Module):\n",
    "    def __init__(self, num_nodes, emb_dim=64, n_layers=3):\n",
    "        super().__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.emb_dim = emb_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.emb = torch.nn.Embedding(num_nodes, emb_dim)\n",
    "        torch.nn.init.normal_(self.emb.weight, std=0.1)\n",
    "\n",
    "    def propagate(self, A_norm):\n",
    "        \"\"\"\n",
    "        A_norm: torch sparse COO [N, N] on DEVICE\n",
    "        returns: final embeddings [N, D]\n",
    "        \"\"\"\n",
    "        x0 = self.emb.weight\n",
    "        xs = [x0]\n",
    "        x = x0\n",
    "        for _ in range(self.n_layers):\n",
    "            x = torch.sparse.mm(A_norm, x)\n",
    "            xs.append(x)\n",
    "        x_out = torch.stack(xs, dim=0).mean(dim=0)\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "978e7099-d5e2-4013-9b0b-7bbec118900c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_pos users: 53398 val_gt: 53398 test_gt: 53398\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 5: Train positives + negative sampling\n",
    "# ============================\n",
    "from collections import defaultdict\n",
    "\n",
    "train_pos = defaultdict(set)\n",
    "for u, i in train_ui:\n",
    "    train_pos[int(u)].add(int(i))\n",
    "\n",
    "val_gt  = {int(u): int(i) for u, i in val_ui}\n",
    "test_gt = {int(u): int(i) for u, i in test_ui}\n",
    "\n",
    "print(\"train_pos users:\", len(train_pos), \"val_gt:\", len(val_gt), \"test_gt:\", len(test_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b4bef32-cb38-4b79-8c73-ce233f0acdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Cell 5b: vectorized negative sampling (per batch)\n",
    "# ============================\n",
    "def sample_negatives(users_np, B, train_pos, n_neg=1, max_tries=50):\n",
    "    \"\"\"\n",
    "    Для каждого user выбираем n_neg отрицательных items, избегая train positives.\n",
    "    Возвращает shape [len(users), n_neg]\n",
    "    \"\"\"\n",
    "    users_np = users_np.astype(np.int64)\n",
    "    out = np.empty((len(users_np), n_neg), dtype=np.int64)\n",
    "\n",
    "    for idx, u in enumerate(users_np):\n",
    "        s = train_pos[int(u)]\n",
    "        for k in range(n_neg):\n",
    "            # rejection sampling\n",
    "            for _ in range(max_tries):\n",
    "                j = np.random.randint(0, B)\n",
    "                if j not in s:\n",
    "                    out[idx, k] = j\n",
    "                    break\n",
    "            else:\n",
    "                # fallback if user почти всё видел\n",
    "                j = np.random.randint(0, B)\n",
    "                out[idx, k] = j\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e6a491f-f021-427e-a76a-40615309a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Cell 6: Ranking metrics for LOO (Hit@K, NDCG@K)\n",
    "# ============================\n",
    "def hit_ndcg_at_k(scores, gt_item, k):\n",
    "    \"\"\"\n",
    "    scores: 1D torch tensor [B] (bigger = better)\n",
    "    gt_item: int\n",
    "    \"\"\"\n",
    "    topk = torch.topk(scores, k=k).indices.cpu().numpy()\n",
    "    if gt_item in topk:\n",
    "        rank = int(np.where(topk == gt_item)[0][0]) + 1  # 1-based\n",
    "        hit = 1.0\n",
    "        ndcg = 1.0 / np.log2(rank + 1)\n",
    "    else:\n",
    "        hit = 0.0\n",
    "        ndcg = 0.0\n",
    "    return hit, ndcg\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_loo(emb_all, U, B, offsets, gt_dict, train_pos, Ks=(10,20,50), batch_users=1024):\n",
    "    \"\"\"\n",
    "    emb_all: [num_nodes, D] on DEVICE\n",
    "    gt_dict: {user_idx: true_item_idx}\n",
    "    Excludes train positives from ranking by setting -inf.\n",
    "    \"\"\"\n",
    "    user_off = int(offsets[\"user_offset\"])\n",
    "    book_off = int(offsets[\"book_offset\"])\n",
    "\n",
    "    # item embeddings for dot-product scoring\n",
    "    item_emb = emb_all[book_off:book_off+B]  # [B, D]\n",
    "\n",
    "    hits = {k: 0.0 for k in Ks}\n",
    "    ndcgs = {k: 0.0 for k in Ks}\n",
    "    users = np.array(sorted(gt_dict.keys()), dtype=np.int64)\n",
    "\n",
    "    for start in range(0, len(users), batch_users):\n",
    "        u_batch = users[start:start+batch_users]\n",
    "        u_emb = emb_all[user_off + torch.from_numpy(u_batch).to(DEVICE)]  # [bs, D]\n",
    "        scores = u_emb @ item_emb.T  # [bs, B]\n",
    "\n",
    "        # mask train positives\n",
    "        for row_idx, u in enumerate(u_batch):\n",
    "            seen = list(train_pos[int(u)])\n",
    "            if seen:\n",
    "                scores[row_idx, torch.tensor(seen, device=DEVICE)] = -1e9\n",
    "\n",
    "        # compute metrics\n",
    "        for row_idx, u in enumerate(u_batch):\n",
    "            gt = int(gt_dict[int(u)])\n",
    "            s = scores[row_idx]\n",
    "            for k in Ks:\n",
    "                h, n = hit_ndcg_at_k(s, gt, k)\n",
    "                hits[k] += h\n",
    "                ndcgs[k] += n\n",
    "\n",
    "    n = len(users)\n",
    "    out = {}\n",
    "    for k in Ks:\n",
    "        out[f\"Hit@{k}\"] = hits[k] / n\n",
    "        out[f\"NDCG@{k}\"] = ndcgs[k] / n\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca207589-f099-4d36-b5c3-79ba155fc382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Cell 7: Train loop (BPR) - STABLE MODE\n",
    "# - propagate is recomputed per batch to avoid \"backward second time\" error\n",
    "# ============================\n",
    "def bpr_loss(u_emb, pos_emb, neg_emb):\n",
    "    pos_scores = (u_emb * pos_emb).sum(dim=1)\n",
    "    neg_scores = (u_emb * neg_emb).sum(dim=1)\n",
    "    return -torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-12).mean()\n",
    "\n",
    "def train_one_run(\n",
    "    A_norm_cpu,\n",
    "    run_name,\n",
    "    emb_dim=64,\n",
    "    n_layers=3,\n",
    "    lr=1e-3,\n",
    "    epochs=20,\n",
    "    batch_size=200_000,\n",
    "    n_neg=1,\n",
    "    eval_every=1,\n",
    "    patience=8,\n",
    "):\n",
    "    \"\"\"\n",
    "    STABLE training:\n",
    "    - A_norm moved to DEVICE once\n",
    "    - for each batch: propagate -> loss -> backward -> step\n",
    "    This avoids the autograd error from reusing the same graph across multiple backward passes.\n",
    "    \"\"\"\n",
    "    A_norm = A_norm_cpu.to(DEVICE)\n",
    "\n",
    "    model = LightGCN(num_nodes=num_nodes, emb_dim=emb_dim, n_layers=n_layers).to(DEVICE)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val = -1.0\n",
    "    best_state = None\n",
    "    bad = 0\n",
    "\n",
    "    n_train = train_ui.shape[0]\n",
    "    idx_all = np.arange(n_train)\n",
    "\n",
    "    history = []\n",
    "\n",
    "    user_off = int(offsets[\"user_offset\"])\n",
    "    book_off = int(offsets[\"book_offset\"])\n",
    "\n",
    "    for ep in range(1, epochs + 1):\n",
    "        np.random.shuffle(idx_all)\n",
    "\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        steps = 0\n",
    "\n",
    "        for s in range(0, n_train, batch_size):\n",
    "            batch_idx = idx_all[s:s + batch_size]\n",
    "            batch = train_ui[batch_idx]  # [bs, 2]\n",
    "\n",
    "            users_np = batch[:, 0]\n",
    "            pos_np   = batch[:, 1]\n",
    "            neg_np   = sample_negatives(users_np, B, train_pos, n_neg=n_neg)[:, 0]\n",
    "\n",
    "            u = torch.from_numpy(users_np).to(DEVICE)\n",
    "            i_pos = torch.from_numpy(pos_np).to(DEVICE)\n",
    "            i_neg = torch.from_numpy(neg_np).to(DEVICE)\n",
    "\n",
    "            # --- STABLE: recompute propagate per batch (fresh autograd graph) ---\n",
    "            emb_all = model.propagate(A_norm)\n",
    "\n",
    "            u_emb = emb_all[user_off + u]\n",
    "            pos_emb = emb_all[book_off + i_pos]\n",
    "            neg_emb = emb_all[book_off + i_neg]\n",
    "\n",
    "            loss = bpr_loss(u_emb, pos_emb, neg_emb)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            total_loss += float(loss.item())\n",
    "            steps += 1\n",
    "\n",
    "        avg_loss = total_loss / max(1, steps)\n",
    "\n",
    "        # ---- eval ----\n",
    "        if ep % eval_every == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                emb_all_eval = model.propagate(A_norm)\n",
    "\n",
    "            val_metrics = evaluate_loo(emb_all_eval, U, B, offsets, val_gt, train_pos, Ks=(10, 20, 50))\n",
    "            score = val_metrics[\"NDCG@10\"]\n",
    "\n",
    "            row = {\"run\": run_name, \"epoch\": ep, \"loss\": avg_loss, **val_metrics}\n",
    "            history.append(row)\n",
    "\n",
    "            print(f\"[{run_name}] ep={ep:03d} loss={avg_loss:.4f} | \"\n",
    "                  f\"Hit@10={val_metrics['Hit@10']:.5f} NDCG@10={val_metrics['NDCG@10']:.5f}\")\n",
    "\n",
    "            # early stopping\n",
    "            if score > best_val + 1e-6:\n",
    "                best_val = score\n",
    "                best_state = {\"model\": model.state_dict(), \"epoch\": ep, \"val_metrics\": val_metrics}\n",
    "                bad = 0\n",
    "            else:\n",
    "                bad += 1\n",
    "                if bad >= patience:\n",
    "                    print(f\"[{run_name}] Early stop at epoch {ep} (best val NDCG@10={best_val:.5f})\")\n",
    "                    break\n",
    "\n",
    "    return best_state, pd.DataFrame(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cc9fea8-fd00-41e5-9ff5-6b70d4e063fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: filtered E = 10852488\n",
      "DEBUG: used E = 1500000\n",
      "DEBUG: A_dbg nnz = 1500000\n",
      "DEBUG: train_ui = (500000, 2)\n",
      "[SMOKE_user_book+tag] ep=001 loss=7.4679 | Hit@10=0.00097 NDCG@10=0.00043\n",
      "[SMOKE_user_book+tag] ep=002 loss=7.4290 | Hit@10=0.00105 NDCG@10=0.00046\n",
      "[SMOKE_user_book+tag] ep=003 loss=7.4022 | Hit@10=0.00105 NDCG@10=0.00046\n",
      "\n",
      "[SMOKE DONE] last hist row:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>Hit@10</th>\n",
       "      <th>NDCG@10</th>\n",
       "      <th>Hit@20</th>\n",
       "      <th>NDCG@20</th>\n",
       "      <th>Hit@50</th>\n",
       "      <th>NDCG@50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOKE_user_book+tag</td>\n",
       "      <td>3</td>\n",
       "      <td>7.402205</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>0.001351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   run  epoch      loss    Hit@10   NDCG@10    Hit@20  \\\n",
       "2  SMOKE_user_book+tag      3  7.402205  0.001049  0.000459  0.001966   \n",
       "\n",
       "    NDCG@20    Hit@50   NDCG@50  \n",
       "2  0.000687  0.005356  0.001351  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] train_ui restored: (500000, 2)\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 7.5: SMOKE TEST (fast debug run)\n",
    "# - цель: проверить, что filter -> rebuild A_norm -> train loop -> eval работает\n",
    "# - режем граф и train edges, делаем 2-3 эпохи\n",
    "# ============================\n",
    "\n",
    "FAST_DEBUG = True \n",
    "\n",
    "if FAST_DEBUG:\n",
    "    # 1) берём более лёгкую конфигурацию: только user-book + book-tag\n",
    "    keep_rel_ids = (\n",
    "        [rel2id[\"user_book\"], rel2id[\"book_user\"]] +\n",
    "        [rel2id[\"book_tag\"], rel2id[\"tag_book\"]]\n",
    "    )\n",
    "\n",
    "    # 2) фильтруем edges\n",
    "    ei_dbg, ew_dbg, et_dbg = filter_edges_by_rel(\n",
    "        edge_index_full, edge_w_full, edge_type_full, keep_rel_ids\n",
    "    )\n",
    "    print(\"DEBUG: filtered E =\", int(ei_dbg.shape[1]))\n",
    "\n",
    "    # 3) дополнительно режем число рёбер (чтобы быстро)\n",
    "    # ВАЖНО: берём первые N рёбер — этого достаточно для smoke теста\n",
    "    MAX_E = 1_500_000\n",
    "    if ei_dbg.shape[1] > MAX_E:\n",
    "        ei_dbg = ei_dbg[:, :MAX_E]\n",
    "        ew_dbg = ew_dbg[:MAX_E]\n",
    "        et_dbg = et_dbg[:MAX_E]\n",
    "    print(\"DEBUG: used E =\", int(ei_dbg.shape[1]))\n",
    "\n",
    "    # 4) rebuild A_norm\n",
    "    A_dbg = build_sparse_norm(ei_dbg, ew_dbg, num_nodes)\n",
    "    print(\"DEBUG: A_dbg nnz =\", int(A_dbg._nnz()))\n",
    "\n",
    "    # 5) режем train edges (чтобы одна эпоха быстро)\n",
    "    # сохраним оригинал и временно заменим train_ui\n",
    "    _train_ui_orig = train_ui.copy()\n",
    "\n",
    "    MAX_TRAIN_EDGES = 500_000\n",
    "    if train_ui.shape[0] > MAX_TRAIN_EDGES:\n",
    "        train_ui = train_ui[:MAX_TRAIN_EDGES].copy()\n",
    "    print(\"DEBUG: train_ui =\", train_ui.shape)\n",
    "\n",
    "    # 6) короткий прогон (2-3 эпохи)\n",
    "    best_state_dbg, hist_dbg = train_one_run(\n",
    "        A_norm_cpu=A_dbg,\n",
    "        run_name=\"SMOKE_user_book+tag\",\n",
    "        emb_dim=64,\n",
    "        n_layers=2,        \n",
    "        lr=1e-3,\n",
    "        epochs=3,            \n",
    "        batch_size=100_000,  \n",
    "        n_neg=1,\n",
    "        patience=10         \n",
    "    )\n",
    "\n",
    "    print(\"\\n[SMOKE DONE] last hist row:\")\n",
    "    display(hist_dbg.tail(1))\n",
    "\n",
    "    # 7) возвращаем train_ui на место\n",
    "    train_ui = _train_ui_orig\n",
    "    print(\"[OK] train_ui restored:\", train_ui.shape)\n",
    "\n",
    "else:\n",
    "    print(\"FAST_DEBUG=False -> skip smoke test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "368b98a6-84a9-4d2b-b6fc-5d59d77b694a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_norm_full: (74285, 74285) nnz: 11260518\n",
      "edge_index_full: (2, 11450076)\n",
      "edge_w_full: (11450076,) finite: True\n",
      "edge_type_full: (11450076,) n_rels: 11\n",
      "train_ui: (500000, 2) val_ui: (53398, 2) test_ui: (53398, 2)\n",
      "U,B: 53398 9999 | num_nodes: 74285\n",
      "\n",
      "[OK] Ready for full ablations ✅\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 7.6: Final checklist before full ablations\n",
    "# ============================\n",
    "\n",
    "print(\"A_norm_full:\", tuple(A_norm_full.shape), \"nnz:\", int(A_norm_full._nnz()))\n",
    "print(\"edge_index_full:\", tuple(edge_index_full.shape))\n",
    "print(\"edge_w_full:\", tuple(edge_w_full.shape), \"finite:\", bool(torch.isfinite(edge_w_full).all().item()))\n",
    "print(\"edge_type_full:\", tuple(edge_type_full.shape), \"n_rels:\", len(rel2id))\n",
    "print(\"train_ui:\", train_ui.shape, \"val_ui:\", val_ui.shape, \"test_ui:\", test_ui.shape)\n",
    "print(\"U,B:\", U, B, \"| num_nodes:\", num_nodes)\n",
    "\n",
    "# базовые sanity\n",
    "assert edge_index_full.shape[1] == edge_w_full.numel() == edge_type_full.numel()\n",
    "assert int(edge_index_full.max()) < int(num_nodes)\n",
    "assert int(edge_index_full.min()) >= 0\n",
    "assert train_ui.shape[1] == 2 and val_ui.shape[1] == 2 and test_ui.shape[1] == 2\n",
    "\n",
    "print(\"\\n[OK] Ready for full ablations ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f34a165e-6206-4988-9c74-b2d57e529b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded splits:\n",
      "train_ui: (4926384, 2)\n",
      "val_ui: (53398, 2)\n",
      "test_ui: (53398, 2)\n",
      "U,B: 53398 9999\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 7.7: FIX - reload FULL splits from bundle\n",
    "# ============================\n",
    "z = np.load(BUNDLE_DIR / \"splits_ui.npz\", allow_pickle=True)\n",
    "\n",
    "train_ui = z[\"train_ui\"].astype(np.int64)\n",
    "val_ui   = z[\"val_ui\"].astype(np.int64)\n",
    "test_ui  = z[\"test_ui\"].astype(np.int64)\n",
    "\n",
    "U = int(z[\"U\"]); B = int(z[\"B\"])\n",
    "\n",
    "print(\"Reloaded splits:\")\n",
    "print(\"train_ui:\", train_ui.shape)\n",
    "print(\"val_ui:\", val_ui.shape)\n",
    "print(\"test_ui:\", test_ui.shape)\n",
    "print(\"U,B:\", U, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d91fac4-758a-4d71-a6ff-c5102c16523b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>n_rel_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FULL</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ONLY_user_book</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_book+tag</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-book_sim</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          variant  n_rel_ids\n",
       "0            FULL         11\n",
       "1  ONLY_user_book          2\n",
       "2   user_book+tag          4\n",
       "3       -book_sim         10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 8: Define ablations (night run)\n",
    "# ============================\n",
    "groups = {\n",
    "    \"user_book\":   [rel2id[\"user_book\"], rel2id[\"book_user\"]],\n",
    "    \"book_tag\":    [rel2id[\"book_tag\"], rel2id[\"tag_book\"]],\n",
    "    \"book_sim\":    [rel2id[\"book_book_sim\"]],\n",
    "    \"book_author\": [rel2id[\"book_author\"], rel2id[\"author_book\"]],\n",
    "    \"book_lang\":   [rel2id[\"book_lang\"], rel2id[\"lang_book\"]],\n",
    "    \"book_year\":   [rel2id[\"book_year\"], rel2id[\"year_book\"]],\n",
    "}\n",
    "\n",
    "all_rel_ids = sorted(set(int(v) for v in rel2id.values()))\n",
    "\n",
    "ablations = [\n",
    "    (\"FULL\", all_rel_ids),\n",
    "    (\"ONLY_user_book\", groups[\"user_book\"]),\n",
    "    (\"user_book+tag\",  groups[\"user_book\"] + groups[\"book_tag\"]),\n",
    "    (\"-book_sim\",      [rid for rid in all_rel_ids if rid not in groups[\"book_sim\"]]),\n",
    "]\n",
    "\n",
    "pd.DataFrame({\"variant\":[a[0] for a in ablations], \"n_rel_ids\":[len(a[1]) for a in ablations]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2caaeaf8-2633-49f6-b2d4-c9d1edaa4ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "Variant: FULL | keep_rel_ids: 11\n",
      "Filtered E: 11450076\n",
      "A_var nnz: 11260518\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FULL | ep 001:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FULL] ep=001 loss=0.6927 | Hit@10=0.01157 NDCG@10=0.00593\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FULL | ep 002:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FULL] ep=002 loss=0.6883 | Hit@10=0.04674 NDCG@10=0.02416\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FULL | ep 003:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FULL] ep=003 loss=0.6693 | Hit@10=0.04805 NDCG@10=0.02598\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FULL | ep 004:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FULL] ep=004 loss=0.6282 | Hit@10=0.04749 NDCG@10=0.02618\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FULL | ep 005:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FULL] ep=005 loss=0.5718 | Hit@10=0.04701 NDCG@10=0.02622\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FULL | ep 006:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FULL] ep=006 loss=0.5165 | Hit@10=0.04714 NDCG@10=0.02626\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FULL | ep 007:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FULL] ep=007 loss=0.4744 | Hit@10=0.04747 NDCG@10=0.02636\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FULL | ep 008:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FULL] ep=008 loss=0.4461 | Hit@10=0.04772 NDCG@10=0.02645\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FULL | ep 009:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FULL] ep=009 loss=0.4285 | Hit@10=0.04822 NDCG@10=0.02674\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FULL | ep 010:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FULL] ep=010 loss=0.4161 | Hit@10=0.04862 NDCG@10=0.02692\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FULL | ep 011:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FULL] ep=011 loss=0.4073 | Hit@10=0.04912 NDCG@10=0.02721\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FULL | ep 012:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FULL] ep=012 loss=0.3998 | Hit@10=0.04959 NDCG@10=0.02742\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FULL | ep 013:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FULL] ep=013 loss=0.3939 | Hit@10=0.05010 NDCG@10=0.02760\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FULL | ep 014:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FULL] ep=014 loss=0.3880 | Hit@10=0.05053 NDCG@10=0.02787\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FULL | ep 015:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FULL] ep=015 loss=0.3814 | Hit@10=0.05167 NDCG@10=0.02828\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FULL | ep 016:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FULL] ep=016 loss=0.3756 | Hit@10=0.05232 NDCG@10=0.02855\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FULL | ep 017:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FULL] ep=017 loss=0.3699 | Hit@10=0.05285 NDCG@10=0.02877\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FULL | ep 018:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FULL] ep=018 loss=0.3640 | Hit@10=0.05365 NDCG@10=0.02916\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FULL | ep 019:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FULL] ep=019 loss=0.3585 | Hit@10=0.05457 NDCG@10=0.02959\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FULL | ep 020:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FULL] ep=020 loss=0.3526 | Hit@10=0.05481 NDCG@10=0.02977\n",
      "[DONE] FULL | TEST Hit@10=0.05515 NDCG@10=0.02982\n",
      "\n",
      "==========================================================================================\n",
      "Variant: ONLY_user_book | keep_rel_ids: 2\n",
      "Filtered E: 9852768\n",
      "A_var nnz: 9852768\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ONLY_user_book | ep 001:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ONLY_user_book] ep=001 loss=0.6924 | Hit@10=0.02279 NDCG@10=0.01158\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ONLY_user_book | ep 002:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ONLY_user_book] ep=002 loss=0.6847 | Hit@10=0.04680 NDCG@10=0.02545\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ONLY_user_book | ep 003:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ONLY_user_book] ep=003 loss=0.6560 | Hit@10=0.04584 NDCG@10=0.02605\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ONLY_user_book | ep 004:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ONLY_user_book] ep=004 loss=0.6021 | Hit@10=0.04566 NDCG@10=0.02603\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ONLY_user_book | ep 005:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ONLY_user_book] ep=005 loss=0.5392 | Hit@10=0.04603 NDCG@10=0.02608\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f409496af9d4b9ea582d234ebae6bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ONLY_user_book | ep 006:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ONLY_user_book] ep=006 loss=0.4876 | Hit@10=0.04635 NDCG@10=0.02621\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e02ea06474430e856411d992c36279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ONLY_user_book | ep 007:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ONLY_user_book] ep=007 loss=0.4537 | Hit@10=0.04642 NDCG@10=0.02625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a1d4c14a4e49879db7bb1be08afc7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ONLY_user_book | ep 008:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ONLY_user_book] ep=008 loss=0.4334 | Hit@10=0.04659 NDCG@10=0.02628\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501faa63282241a3955ffafde48e2e83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ONLY_user_book | ep 009:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ONLY_user_book] ep=009 loss=0.4207 | Hit@10=0.04702 NDCG@10=0.02643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d70fd61ef1544de859ff29e8cc9dd16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ONLY_user_book | ep 010:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ONLY_user_book] ep=010 loss=0.4123 | Hit@10=0.04725 NDCG@10=0.02657\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc419c6187e4fc89c96c904b240b858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ONLY_user_book | ep 011:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ONLY_user_book] ep=011 loss=0.4052 | Hit@10=0.04766 NDCG@10=0.02677\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c60ab05c8d479ea4e400d16fe52ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ONLY_user_book | ep 012:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ONLY_user_book] ep=012 loss=0.3989 | Hit@10=0.04830 NDCG@10=0.02703\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60292f98361e4705b1da64cbbb5bf03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ONLY_user_book | ep 013:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ONLY_user_book] ep=013 loss=0.3927 | Hit@10=0.04903 NDCG@10=0.02732\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe668c0c84e7412bb1543fde77bc1dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ONLY_user_book | ep 014:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ONLY_user_book] ep=014 loss=0.3871 | Hit@10=0.05010 NDCG@10=0.02768\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b29e6cea1f54e049211aedcb845f3b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ONLY_user_book | ep 015:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ONLY_user_book] ep=015 loss=0.3814 | Hit@10=0.05060 NDCG@10=0.02804\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182711950d52434ba516272eb555a30a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ONLY_user_book | ep 016:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ONLY_user_book] ep=016 loss=0.3762 | Hit@10=0.05146 NDCG@10=0.02841\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55da6758ff444369a1ada7aabb648c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ONLY_user_book | ep 017:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ONLY_user_book] ep=017 loss=0.3709 | Hit@10=0.05219 NDCG@10=0.02872\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645ff568d5b843c68fe11e05c9183c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ONLY_user_book | ep 018:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ONLY_user_book] ep=018 loss=0.3652 | Hit@10=0.05296 NDCG@10=0.02894\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6e4882813345e9bdc6ee8c43562fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ONLY_user_book | ep 019:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ONLY_user_book] ep=019 loss=0.3599 | Hit@10=0.05375 NDCG@10=0.02927\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1af0446a18849efa608b3128723d682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ONLY_user_book | ep 020:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ONLY_user_book] ep=020 loss=0.3552 | Hit@10=0.05452 NDCG@10=0.02957\n",
      "[DONE] ONLY_user_book | TEST Hit@10=0.05498 NDCG@10=0.02973\n",
      "\n",
      "==========================================================================================\n",
      "Variant: user_book+tag | keep_rel_ids: 4\n",
      "Filtered E: 10852488\n",
      "A_var nnz: 10852482\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38ac225f98a48b480dc83dd8f0fea2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "user_book+tag | ep 001:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user_book+tag] ep=001 loss=0.6927 | Hit@10=0.01230 NDCG@10=0.00619\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff814d181f84d2094452b8ca2286bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "user_book+tag | ep 002:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user_book+tag] ep=002 loss=0.6881 | Hit@10=0.04618 NDCG@10=0.02428\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9bcb5b9901a499baa01d2a69590d8e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "user_book+tag | ep 003:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user_book+tag] ep=003 loss=0.6680 | Hit@10=0.04699 NDCG@10=0.02582\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194aecefcac649bd9c3a003ff313dd1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "user_book+tag | ep 004:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user_book+tag] ep=004 loss=0.6254 | Hit@10=0.04663 NDCG@10=0.02606\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "321379cbc15f40e8ae45704c87ae5982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "user_book+tag | ep 005:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user_book+tag] ep=005 loss=0.5682 | Hit@10=0.04650 NDCG@10=0.02618\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba875e640dee4717a98e9fad783cc625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "user_book+tag | ep 006:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user_book+tag] ep=006 loss=0.5136 | Hit@10=0.04637 NDCG@10=0.02620\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28897d63f7c0475193099166cbec30b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "user_book+tag | ep 007:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user_book+tag] ep=007 loss=0.4730 | Hit@10=0.04631 NDCG@10=0.02607\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786c48fc4fbd44339c7ca390b8242c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "user_book+tag | ep 008:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user_book+tag] ep=008 loss=0.4461 | Hit@10=0.04672 NDCG@10=0.02619\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c42ab5825bb34c09b6f6df1e41770cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "user_book+tag | ep 009:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user_book+tag] ep=009 loss=0.4295 | Hit@10=0.04712 NDCG@10=0.02632\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "500c18eeb5534b0d85f8ccd62839e701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "user_book+tag | ep 010:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user_book+tag] ep=010 loss=0.4182 | Hit@10=0.04766 NDCG@10=0.02662\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "user_book+tag | ep 011:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user_book+tag] ep=011 loss=0.4104 | Hit@10=0.04811 NDCG@10=0.02693\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "user_book+tag | ep 012:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user_book+tag] ep=012 loss=0.4040 | Hit@10=0.04854 NDCG@10=0.02724\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "user_book+tag | ep 013:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user_book+tag] ep=013 loss=0.3981 | Hit@10=0.04888 NDCG@10=0.02747\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "user_book+tag | ep 014:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user_book+tag] ep=014 loss=0.3930 | Hit@10=0.04950 NDCG@10=0.02779\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "user_book+tag | ep 015:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user_book+tag] ep=015 loss=0.3874 | Hit@10=0.05008 NDCG@10=0.02797\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "user_book+tag | ep 016:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user_book+tag] ep=016 loss=0.3822 | Hit@10=0.05088 NDCG@10=0.02830\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "user_book+tag | ep 017:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user_book+tag] ep=017 loss=0.3762 | Hit@10=0.05139 NDCG@10=0.02855\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "user_book+tag | ep 018:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user_book+tag] ep=018 loss=0.3710 | Hit@10=0.05189 NDCG@10=0.02875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "user_book+tag | ep 019:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user_book+tag] ep=019 loss=0.3657 | Hit@10=0.05264 NDCG@10=0.02905\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "user_book+tag | ep 020:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user_book+tag] ep=020 loss=0.3603 | Hit@10=0.05360 NDCG@10=0.02940\n",
      "[DONE] user_book+tag | TEST Hit@10=0.05388 NDCG@10=0.02950\n",
      "\n",
      "==========================================================================================\n",
      "Variant: -book_sim | keep_rel_ids: 10\n",
      "Filtered E: 10918914\n",
      "A_var nnz: 10918894\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_sim | ep 001:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_sim] ep=001 loss=0.6927 | Hit@10=0.01081 NDCG@10=0.00547\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_sim | ep 002:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_sim] ep=002 loss=0.6883 | Hit@10=0.04534 NDCG@10=0.02437\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_sim | ep 003:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_sim] ep=003 loss=0.6685 | Hit@10=0.04656 NDCG@10=0.02588\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_sim | ep 004:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_sim] ep=004 loss=0.6258 | Hit@10=0.04596 NDCG@10=0.02591\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_sim | ep 005:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_sim] ep=005 loss=0.5684 | Hit@10=0.04596 NDCG@10=0.02595\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_sim | ep 006:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_sim] ep=006 loss=0.5135 | Hit@10=0.04598 NDCG@10=0.02594\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_sim | ep 007:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_sim] ep=007 loss=0.4728 | Hit@10=0.04609 NDCG@10=0.02595\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_sim | ep 008:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_sim] ep=008 loss=0.4465 | Hit@10=0.04609 NDCG@10=0.02598\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_sim | ep 009:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_sim] ep=009 loss=0.4300 | Hit@10=0.04613 NDCG@10=0.02605\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_sim | ep 010:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_sim] ep=010 loss=0.4192 | Hit@10=0.04639 NDCG@10=0.02617\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_sim | ep 011:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_sim] ep=011 loss=0.4114 | Hit@10=0.04672 NDCG@10=0.02637\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_sim | ep 012:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_sim] ep=012 loss=0.4057 | Hit@10=0.04727 NDCG@10=0.02655\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_sim | ep 013:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_sim] ep=013 loss=0.4000 | Hit@10=0.04790 NDCG@10=0.02682\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_sim | ep 014:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_sim] ep=014 loss=0.3949 | Hit@10=0.04848 NDCG@10=0.02710\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_sim | ep 015:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_sim] ep=015 loss=0.3896 | Hit@10=0.04923 NDCG@10=0.02735\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_sim | ep 016:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_sim] ep=016 loss=0.3845 | Hit@10=0.04993 NDCG@10=0.02770\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_sim | ep 017:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_sim] ep=017 loss=0.3789 | Hit@10=0.05066 NDCG@10=0.02812\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_sim | ep 018:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_sim] ep=018 loss=0.3736 | Hit@10=0.05154 NDCG@10=0.02844\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_sim | ep 019:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_sim] ep=019 loss=0.3678 | Hit@10=0.05206 NDCG@10=0.02872\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_sim | ep 020:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_sim] ep=020 loss=0.3627 | Hit@10=0.05309 NDCG@10=0.02905\n",
      "[DONE] -book_sim | TEST Hit@10=0.05328 NDCG@10=0.02902\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>E</th>\n",
       "      <th>nnz</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>val_Hit@10</th>\n",
       "      <th>val_NDCG@10</th>\n",
       "      <th>test_Hit@10</th>\n",
       "      <th>test_NDCG@10</th>\n",
       "      <th>test_Hit@20</th>\n",
       "      <th>test_NDCG@20</th>\n",
       "      <th>test_Hit@50</th>\n",
       "      <th>test_NDCG@50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FULL</td>\n",
       "      <td>11450076</td>\n",
       "      <td>11260518</td>\n",
       "      <td>20</td>\n",
       "      <td>0.054815</td>\n",
       "      <td>0.029770</td>\n",
       "      <td>0.055152</td>\n",
       "      <td>0.029817</td>\n",
       "      <td>0.082887</td>\n",
       "      <td>0.036756</td>\n",
       "      <td>0.142945</td>\n",
       "      <td>0.048596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ONLY_user_book</td>\n",
       "      <td>9852768</td>\n",
       "      <td>9852768</td>\n",
       "      <td>20</td>\n",
       "      <td>0.054515</td>\n",
       "      <td>0.029567</td>\n",
       "      <td>0.054983</td>\n",
       "      <td>0.029727</td>\n",
       "      <td>0.082924</td>\n",
       "      <td>0.036715</td>\n",
       "      <td>0.142833</td>\n",
       "      <td>0.048543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_book+tag</td>\n",
       "      <td>10852488</td>\n",
       "      <td>10852482</td>\n",
       "      <td>20</td>\n",
       "      <td>0.053598</td>\n",
       "      <td>0.029399</td>\n",
       "      <td>0.053878</td>\n",
       "      <td>0.029497</td>\n",
       "      <td>0.082194</td>\n",
       "      <td>0.036590</td>\n",
       "      <td>0.141110</td>\n",
       "      <td>0.048221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-book_sim</td>\n",
       "      <td>10918914</td>\n",
       "      <td>10918894</td>\n",
       "      <td>20</td>\n",
       "      <td>0.053092</td>\n",
       "      <td>0.029047</td>\n",
       "      <td>0.053279</td>\n",
       "      <td>0.029020</td>\n",
       "      <td>0.080958</td>\n",
       "      <td>0.035954</td>\n",
       "      <td>0.140473</td>\n",
       "      <td>0.047699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          variant         E       nnz  best_epoch  val_Hit@10  val_NDCG@10  \\\n",
       "0            FULL  11450076  11260518          20    0.054815     0.029770   \n",
       "1  ONLY_user_book   9852768   9852768          20    0.054515     0.029567   \n",
       "2   user_book+tag  10852488  10852482          20    0.053598     0.029399   \n",
       "3       -book_sim  10918914  10918894          20    0.053092     0.029047   \n",
       "\n",
       "   test_Hit@10  test_NDCG@10  test_Hit@20  test_NDCG@20  test_Hit@50  \\\n",
       "0     0.055152      0.029817     0.082887      0.036756     0.142945   \n",
       "1     0.054983      0.029727     0.082924      0.036715     0.142833   \n",
       "2     0.053878      0.029497     0.082194      0.036590     0.141110   \n",
       "3     0.053279      0.029020     0.080958      0.035954     0.140473   \n",
       "\n",
       "   test_NDCG@50  \n",
       "0      0.048596  \n",
       "1      0.048543  \n",
       "2      0.048221  \n",
       "3      0.047699  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved: D:\\ML\\GNN\\graph_recsys\\artifacts\\v2_proper\\ablation_runs\\ablation_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 9: Run ablations (tqdm progress + skip + save)\n",
    "# ============================\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "RESULTS_DIR = ARTIFACTS / \"ablation_runs\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- Overwrite train_one_run with tqdm-enabled STABLE loop ----\n",
    "def train_one_run(\n",
    "    A_norm_cpu,\n",
    "    run_name,\n",
    "    emb_dim=64,\n",
    "    n_layers=3,\n",
    "    lr=1e-3,\n",
    "    epochs=20,\n",
    "    batch_size=300_000,\n",
    "    n_neg=1,\n",
    "    eval_every=1,\n",
    "    patience=5,\n",
    "):\n",
    "    \"\"\"\n",
    "    STABLE training (propagate per batch) + tqdm progress bar over batches.\n",
    "    This is slower but robust and won't crash with autograd 'backward second time'.\n",
    "    \"\"\"\n",
    "    A_norm = A_norm_cpu.to(DEVICE)\n",
    "\n",
    "    model = LightGCN(num_nodes=num_nodes, emb_dim=emb_dim, n_layers=n_layers).to(DEVICE)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val = -1.0\n",
    "    best_state = None\n",
    "    bad = 0\n",
    "    history = []\n",
    "\n",
    "    n_train = train_ui.shape[0]\n",
    "    idx_all = np.arange(n_train)\n",
    "\n",
    "    user_off = int(offsets[\"user_offset\"])\n",
    "    book_off = int(offsets[\"book_offset\"])\n",
    "\n",
    "    for ep in range(1, epochs + 1):\n",
    "        np.random.shuffle(idx_all)\n",
    "\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        steps = 0\n",
    "\n",
    "        n_batches = math.ceil(n_train / batch_size)\n",
    "        pbar = tqdm(range(0, n_train, batch_size), total=n_batches,\n",
    "                    desc=f\"{run_name} | ep {ep:03d}\", leave=False)\n",
    "\n",
    "        for s in pbar:\n",
    "            batch_idx = idx_all[s:s + batch_size]\n",
    "            batch = train_ui[batch_idx]  # [bs, 2]\n",
    "\n",
    "            users_np = batch[:, 0]\n",
    "            pos_np   = batch[:, 1]\n",
    "            neg_np   = sample_negatives(users_np, B, train_pos, n_neg=n_neg)[:, 0]\n",
    "\n",
    "            u = torch.from_numpy(users_np).to(DEVICE)\n",
    "            i_pos = torch.from_numpy(pos_np).to(DEVICE)\n",
    "            i_neg = torch.from_numpy(neg_np).to(DEVICE)\n",
    "\n",
    "            # STABLE: fresh autograd graph each batch\n",
    "            emb_all = model.propagate(A_norm)\n",
    "\n",
    "            u_emb = emb_all[user_off + u]\n",
    "            pos_emb = emb_all[book_off + i_pos]\n",
    "            neg_emb = emb_all[book_off + i_neg]\n",
    "\n",
    "            loss = bpr_loss(u_emb, pos_emb, neg_emb)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            total_loss += float(loss.item())\n",
    "            steps += 1\n",
    "            pbar.set_postfix(loss=total_loss / max(1, steps))\n",
    "\n",
    "        avg_loss = total_loss / max(1, steps)\n",
    "\n",
    "        # ---- eval ----\n",
    "        if ep % eval_every == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                emb_all_eval = model.propagate(A_norm)\n",
    "\n",
    "            val_metrics = evaluate_loo(emb_all_eval, U, B, offsets, val_gt, train_pos, Ks=(10, 20, 50))\n",
    "            score = val_metrics[\"NDCG@10\"]\n",
    "\n",
    "            row = {\"run\": run_name, \"epoch\": ep, \"loss\": avg_loss, **val_metrics}\n",
    "            history.append(row)\n",
    "\n",
    "            print(f\"[{run_name}] ep={ep:03d} loss={avg_loss:.4f} | \"\n",
    "                  f\"Hit@10={val_metrics['Hit@10']:.5f} NDCG@10={val_metrics['NDCG@10']:.5f}\")\n",
    "\n",
    "            if score > best_val + 1e-6:\n",
    "                best_val = score\n",
    "                best_state = {\"model\": model.state_dict(), \"epoch\": ep, \"val_metrics\": val_metrics}\n",
    "                bad = 0\n",
    "            else:\n",
    "                bad += 1\n",
    "                if bad >= patience:\n",
    "                    print(f\"[{run_name}] Early stop at epoch {ep} (best val NDCG@10={best_val:.5f})\")\n",
    "                    break\n",
    "\n",
    "    return best_state, pd.DataFrame(history)\n",
    "\n",
    "\n",
    "# ---- Run variants ----\n",
    "all_results = []\n",
    "all_hist = []\n",
    "\n",
    "for variant, keep_rel_ids in ablations:\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"Variant:\", variant, \"| keep_rel_ids:\", len(keep_rel_ids))\n",
    "\n",
    "    # SKIP if already computed\n",
    "    sum_path = RESULTS_DIR / f\"summary_{variant}.json\"\n",
    "    hist_path = RESULTS_DIR / f\"hist_{variant}.csv\"\n",
    "    if sum_path.exists() and hist_path.exists():\n",
    "        print(f\"[SKIP] {variant} already computed\")\n",
    "        # optionally load existing summary for the final table\n",
    "        with open(sum_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            all_results.append(json.load(f))\n",
    "        continue\n",
    "\n",
    "    # 1) filter edges\n",
    "    ei, ew, et = filter_edges_by_rel(edge_index_full, edge_w_full, edge_type_full, keep_rel_ids)\n",
    "    print(\"Filtered E:\", int(ei.shape[1]))\n",
    "\n",
    "    # 2) rebuild A_norm\n",
    "    A_var = build_sparse_norm(ei, ew, num_nodes)\n",
    "    print(\"A_var nnz:\", int(A_var._nnz()))\n",
    "\n",
    "    # 3) train\n",
    "    best_state, hist_df = train_one_run(\n",
    "        A_norm_cpu=A_var,\n",
    "        run_name=variant,\n",
    "        emb_dim=64,\n",
    "        n_layers=3,\n",
    "        lr=1e-3,\n",
    "        epochs=20,\n",
    "        batch_size=300_000,   \n",
    "        n_neg=1,\n",
    "        patience=5\n",
    "    )\n",
    "\n",
    "    # 4) evaluate on TEST at best epoch\n",
    "    model = LightGCN(num_nodes=num_nodes, emb_dim=64, n_layers=3).to(DEVICE)\n",
    "    model.load_state_dict(best_state[\"model\"])\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        emb_all = model.propagate(A_var.to(DEVICE))\n",
    "\n",
    "    test_metrics = evaluate_loo(emb_all, U, B, offsets, test_gt, train_pos, Ks=(10, 20, 50))\n",
    "\n",
    "    row = {\n",
    "        \"variant\": variant,\n",
    "        \"best_epoch\": int(best_state[\"epoch\"]),\n",
    "        **{f\"val_{k}\": float(v) for k, v in best_state[\"val_metrics\"].items()},\n",
    "        **{f\"test_{k}\": float(v) for k, v in test_metrics.items()},\n",
    "        \"E\": int(ei.shape[1]),\n",
    "        \"nnz\": int(A_var._nnz()),\n",
    "    }\n",
    "\n",
    "    all_results.append(row)\n",
    "    all_hist.append(hist_df)\n",
    "\n",
    "    # save\n",
    "    hist_df.to_csv(hist_path, index=False)\n",
    "    with open(sum_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(row, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"[DONE] {variant} | TEST Hit@10={test_metrics['Hit@10']:.5f} NDCG@10={test_metrics['NDCG@10']:.5f}\")\n",
    "\n",
    "\n",
    "# ---- Final summary table ----\n",
    "res = pd.DataFrame(all_results)\n",
    "if len(res) > 0:\n",
    "    res = res.sort_values(\"test_NDCG@10\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "cols = [\n",
    "    \"variant\", \"E\", \"nnz\", \"best_epoch\",\n",
    "    \"val_Hit@10\", \"val_NDCG@10\",\n",
    "    \"test_Hit@10\", \"test_NDCG@10\",\n",
    "    \"test_Hit@20\", \"test_NDCG@20\",\n",
    "    \"test_Hit@50\", \"test_NDCG@50\",\n",
    "]\n",
    "display(res[cols])\n",
    "\n",
    "out_path = RESULTS_DIR / \"ablation_summary.csv\"\n",
    "res.to_csv(out_path, index=False)\n",
    "print(\"[OK] saved:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2223752-19c1-4045-abf8-fb56ee4737b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>E</th>\n",
       "      <th>nnz</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>val_Hit@10</th>\n",
       "      <th>val_NDCG@10</th>\n",
       "      <th>test_Hit@10</th>\n",
       "      <th>test_NDCG@10</th>\n",
       "      <th>test_Hit@20</th>\n",
       "      <th>test_NDCG@20</th>\n",
       "      <th>test_Hit@50</th>\n",
       "      <th>test_NDCG@50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FULL</td>\n",
       "      <td>11450076</td>\n",
       "      <td>11260518</td>\n",
       "      <td>20</td>\n",
       "      <td>0.054815</td>\n",
       "      <td>0.029770</td>\n",
       "      <td>0.055152</td>\n",
       "      <td>0.029817</td>\n",
       "      <td>0.082887</td>\n",
       "      <td>0.036756</td>\n",
       "      <td>0.142945</td>\n",
       "      <td>0.048596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ONLY_user_book</td>\n",
       "      <td>9852768</td>\n",
       "      <td>9852768</td>\n",
       "      <td>20</td>\n",
       "      <td>0.054515</td>\n",
       "      <td>0.029567</td>\n",
       "      <td>0.054983</td>\n",
       "      <td>0.029727</td>\n",
       "      <td>0.082924</td>\n",
       "      <td>0.036715</td>\n",
       "      <td>0.142833</td>\n",
       "      <td>0.048543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_book+tag</td>\n",
       "      <td>10852488</td>\n",
       "      <td>10852482</td>\n",
       "      <td>20</td>\n",
       "      <td>0.053598</td>\n",
       "      <td>0.029399</td>\n",
       "      <td>0.053878</td>\n",
       "      <td>0.029497</td>\n",
       "      <td>0.082194</td>\n",
       "      <td>0.036590</td>\n",
       "      <td>0.141110</td>\n",
       "      <td>0.048221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-book_sim</td>\n",
       "      <td>10918914</td>\n",
       "      <td>10918894</td>\n",
       "      <td>20</td>\n",
       "      <td>0.053092</td>\n",
       "      <td>0.029047</td>\n",
       "      <td>0.053279</td>\n",
       "      <td>0.029020</td>\n",
       "      <td>0.080958</td>\n",
       "      <td>0.035954</td>\n",
       "      <td>0.140473</td>\n",
       "      <td>0.047699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          variant         E       nnz  best_epoch  val_Hit@10  val_NDCG@10  \\\n",
       "0            FULL  11450076  11260518          20    0.054815     0.029770   \n",
       "1  ONLY_user_book   9852768   9852768          20    0.054515     0.029567   \n",
       "2   user_book+tag  10852488  10852482          20    0.053598     0.029399   \n",
       "3       -book_sim  10918914  10918894          20    0.053092     0.029047   \n",
       "\n",
       "   test_Hit@10  test_NDCG@10  test_Hit@20  test_NDCG@20  test_Hit@50  \\\n",
       "0     0.055152      0.029817     0.082887      0.036756     0.142945   \n",
       "1     0.054983      0.029727     0.082924      0.036715     0.142833   \n",
       "2     0.053878      0.029497     0.082194      0.036590     0.141110   \n",
       "3     0.053279      0.029020     0.080958      0.035954     0.140473   \n",
       "\n",
       "   test_NDCG@50  \n",
       "0      0.048596  \n",
       "1      0.048543  \n",
       "2      0.048221  \n",
       "3      0.047699  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 10: Summarize ablations\n",
    "# ============================\n",
    "res = pd.DataFrame(all_results)\n",
    "\n",
    "# сортируем по test NDCG@10\n",
    "res = res.sort_values(\"test_NDCG@10\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "cols = [\n",
    "    \"variant\", \"E\", \"nnz\", \"best_epoch\",\n",
    "    \"val_Hit@10\", \"val_NDCG@10\", \"test_Hit@10\", \"test_NDCG@10\",\n",
    "    \"test_Hit@20\", \"test_NDCG@20\", \"test_Hit@50\", \"test_NDCG@50\"\n",
    "]\n",
    "display(res[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52993856-01d1-4145-bd81-361b865f15f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved: D:\\ML\\GNN\\graph_recsys\\artifacts\\v2_proper\\ablation_runs\\ablation_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 11: Save final results table\n",
    "# ============================\n",
    "out_path = RESULTS_DIR / \"ablation_summary.csv\"\n",
    "res.to_csv(out_path, index=False)\n",
    "print(\"[OK] saved:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee225f0-9ba6-4972-a1b9-66bf37b4f0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d80d45a-d4c1-4c89-bc0e-c35e0e4f9f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>n_rel_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FULL</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-book_sim</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-book_tag</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-book_author</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-book_lang</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-book_year</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ONLY_user_book</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>user_book+tag</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          variant  n_rel_ids\n",
       "0            FULL         11\n",
       "1       -book_sim         10\n",
       "2       -book_tag          9\n",
       "3    -book_author          9\n",
       "4      -book_lang          9\n",
       "5      -book_year          9\n",
       "6  ONLY_user_book          2\n",
       "7   user_book+tag          4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================\n",
    "# Define BIG ablations (full list)\n",
    "# ============================\n",
    "\n",
    "import json, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "groups = {\n",
    "    \"user_book\":    [rel2id[\"user_book\"], rel2id[\"book_user\"]],\n",
    "    \"book_tag\":     [rel2id[\"book_tag\"], rel2id[\"tag_book\"]],\n",
    "    \"book_sim\":     [rel2id[\"book_book_sim\"]],\n",
    "    \"book_author\":  [rel2id[\"book_author\"], rel2id[\"author_book\"]],\n",
    "    \"book_lang\":    [rel2id[\"book_lang\"], rel2id[\"lang_book\"]],\n",
    "    \"book_year\":    [rel2id[\"book_year\"], rel2id[\"year_book\"]],\n",
    "}\n",
    "\n",
    "all_rel_ids = sorted(set(int(v) for v in rel2id.values()))\n",
    "\n",
    "# Большая абляция: удаляем по одному \"блоку\" отношений\n",
    "ablations_big = [\n",
    "    (\"FULL\", all_rel_ids),\n",
    "\n",
    "    (\"-book_sim\",   [rid for rid in all_rel_ids if rid not in groups[\"book_sim\"]]),\n",
    "    (\"-book_tag\",   [rid for rid in all_rel_ids if rid not in groups[\"book_tag\"]]),\n",
    "    (\"-book_author\",[rid for rid in all_rel_ids if rid not in groups[\"book_author\"]]),\n",
    "    (\"-book_lang\",  [rid for rid in all_rel_ids if rid not in groups[\"book_lang\"]]),\n",
    "    (\"-book_year\",  [rid for rid in all_rel_ids if rid not in groups[\"book_year\"]]),\n",
    "\n",
    "    # полезные sanity / минималки:\n",
    "    (\"ONLY_user_book\", groups[\"user_book\"]),\n",
    "    (\"user_book+tag\",  groups[\"user_book\"] + groups[\"book_tag\"]),\n",
    "]\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\"variant\":[a[0] for a in ablations_big],\n",
    "     \"n_rel_ids\":[len(a[1]) for a in ablations_big]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ceaa3f7-1e93-4f21-800e-62099c7389ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "Variant: FULL | keep_rel_ids: 11\n",
      "[SKIP] FULL already computed\n",
      "\n",
      "==========================================================================================\n",
      "Variant: -book_sim | keep_rel_ids: 10\n",
      "[SKIP] -book_sim already computed\n",
      "\n",
      "==========================================================================================\n",
      "Variant: -book_tag | keep_rel_ids: 9\n",
      "Filtered E: 10450356\n",
      "A_var nnz: 10260804\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_tag | ep 001:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_tag] ep=001 loss=0.6926 | Hit@10=0.01710 NDCG@10=0.00845\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_tag | ep 002:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_tag] ep=002 loss=0.6863 | Hit@10=0.04738 NDCG@10=0.02541\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_tag | ep 003:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_tag] ep=003 loss=0.6607 | Hit@10=0.04676 NDCG@10=0.02622\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_tag | ep 004:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_tag] ep=004 loss=0.6097 | Hit@10=0.04626 NDCG@10=0.02630\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_tag | ep 005:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_tag] ep=005 loss=0.5467 | Hit@10=0.04642 NDCG@10=0.02638\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_tag | ep 006:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_tag] ep=006 loss=0.4927 | Hit@10=0.04656 NDCG@10=0.02642\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_tag | ep 007:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_tag] ep=007 loss=0.4563 | Hit@10=0.04671 NDCG@10=0.02642\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_tag | ep 008:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_tag] ep=008 loss=0.4337 | Hit@10=0.04716 NDCG@10=0.02656\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_tag | ep 009:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_tag] ep=009 loss=0.4194 | Hit@10=0.04760 NDCG@10=0.02675\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_tag | ep 010:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_tag] ep=010 loss=0.4096 | Hit@10=0.04804 NDCG@10=0.02690\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_tag | ep 011:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_tag] ep=011 loss=0.4020 | Hit@10=0.04841 NDCG@10=0.02711\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_tag | ep 012:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_tag] ep=012 loss=0.3944 | Hit@10=0.04927 NDCG@10=0.02749\n",
      "[DONE] -book_tag | TEST Hit@10=0.04950 NDCG@10=0.02748\n",
      "\n",
      "==========================================================================================\n",
      "Variant: -book_author | keep_rel_ids: 9\n",
      "Filtered E: 11423646\n",
      "A_var nnz: 11234102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_author | ep 001:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_author] ep=001 loss=0.6927 | Hit@10=0.01129 NDCG@10=0.00561\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_author | ep 002:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_author] ep=002 loss=0.6882 | Hit@10=0.04586 NDCG@10=0.02470\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_author | ep 003:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_author] ep=003 loss=0.6685 | Hit@10=0.04564 NDCG@10=0.02584\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_author | ep 004:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_author] ep=004 loss=0.6260 | Hit@10=0.04536 NDCG@10=0.02593\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_author | ep 005:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_author] ep=005 loss=0.5686 | Hit@10=0.04566 NDCG@10=0.02598\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_author | ep 006:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_author] ep=006 loss=0.5140 | Hit@10=0.04569 NDCG@10=0.02599\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_author | ep 007:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_author] ep=007 loss=0.4735 | Hit@10=0.04577 NDCG@10=0.02601\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_author | ep 008:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_author] ep=008 loss=0.4475 | Hit@10=0.04577 NDCG@10=0.02600\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_author | ep 009:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_author] ep=009 loss=0.4306 | Hit@10=0.04594 NDCG@10=0.02605\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_author | ep 010:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_author] ep=010 loss=0.4205 | Hit@10=0.04635 NDCG@10=0.02616\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_author | ep 011:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_author] ep=011 loss=0.4128 | Hit@10=0.04663 NDCG@10=0.02631\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_author | ep 012:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_author] ep=012 loss=0.4072 | Hit@10=0.04710 NDCG@10=0.02650\n",
      "[DONE] -book_author | TEST Hit@10=0.04704 NDCG@10=0.02638\n",
      "\n",
      "==========================================================================================\n",
      "Variant: -book_lang | keep_rel_ids: 9\n",
      "Filtered E: 11430078\n",
      "A_var nnz: 11240520\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_lang | ep 001:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_lang] ep=001 loss=0.6928 | Hit@10=0.01103 NDCG@10=0.00536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1392bdc5013f431d9b2d626d21c7d574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_lang | ep 002:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_lang] ep=002 loss=0.6885 | Hit@10=0.04599 NDCG@10=0.02410\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871e6de5d989402e8c6ad46e3cc67c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_lang | ep 003:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_lang] ep=003 loss=0.6696 | Hit@10=0.04620 NDCG@10=0.02577\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d532281ab78345daacdbc5d3f22c3ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_lang | ep 004:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_lang] ep=004 loss=0.6284 | Hit@10=0.04605 NDCG@10=0.02609\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a83abc340b14333ae4fb8d0bf739683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_lang | ep 005:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_lang] ep=005 loss=0.5715 | Hit@10=0.04611 NDCG@10=0.02611\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73d9a97ac0943f8ae422334f4d24661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_lang | ep 006:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_lang] ep=006 loss=0.5163 | Hit@10=0.04601 NDCG@10=0.02604\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b4c3c2d48b49ec9559b5e2b1253904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_lang | ep 007:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_lang] ep=007 loss=0.4746 | Hit@10=0.04599 NDCG@10=0.02603\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "007d250285d0497a9b45036538cb0323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_lang | ep 008:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_lang] ep=008 loss=0.4475 | Hit@10=0.04631 NDCG@10=0.02612\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82605e35c13e493b8098f0862154c82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_lang | ep 009:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_lang] ep=009 loss=0.4305 | Hit@10=0.04657 NDCG@10=0.02622\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6464e9d1ca8d4cb585d151197a6fdd46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_lang | ep 010:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_lang] ep=010 loss=0.4196 | Hit@10=0.04712 NDCG@10=0.02641\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3433f02827d4d0e8e303ba12380e716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_lang | ep 011:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_lang] ep=011 loss=0.4114 | Hit@10=0.04729 NDCG@10=0.02651\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51259bdcd6dd46fda6114673a549a306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_lang | ep 012:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_lang] ep=012 loss=0.4052 | Hit@10=0.04757 NDCG@10=0.02667\n",
      "[DONE] -book_lang | TEST Hit@10=0.04794 NDCG@10=0.02651\n",
      "\n",
      "==========================================================================================\n",
      "Variant: -book_year | keep_rel_ids: 9\n",
      "Filtered E: 11430078\n",
      "A_var nnz: 11240520\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288ce5d24a794ce9a021f11818d40fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_year | ep 001:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_year] ep=001 loss=0.6928 | Hit@10=0.00966 NDCG@10=0.00470\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b1bf6ba5db41f68ec610d2e834c6cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_year | ep 002:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_year] ep=002 loss=0.6886 | Hit@10=0.04674 NDCG@10=0.02453\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3db8fabf43c4912938d0ef661d8cf1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_year | ep 003:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_year] ep=003 loss=0.6699 | Hit@10=0.04727 NDCG@10=0.02617\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63ecb57f09748b2ade76eb0f0b7365a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_year | ep 004:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_year] ep=004 loss=0.6285 | Hit@10=0.04676 NDCG@10=0.02641\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7517b3971db485993950c6b76f5aa67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_year | ep 005:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_year] ep=005 loss=0.5712 | Hit@10=0.04657 NDCG@10=0.02623\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a700a656cdb043d7bfc1f5efa1a0257a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_year | ep 006:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_year] ep=006 loss=0.5156 | Hit@10=0.04656 NDCG@10=0.02615\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753047baa46a4b94ae448a54fab684ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "-book_year | ep 007:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-book_year] ep=007 loss=0.4739 | Hit@10=0.04676 NDCG@10=0.02619\n",
      "[-book_year] Early stop at epoch 7 (best val NDCG@10=0.02641)\n",
      "[DONE] -book_year | TEST Hit@10=0.04742 NDCG@10=0.02630\n",
      "\n",
      "==========================================================================================\n",
      "Variant: ONLY_user_book | keep_rel_ids: 2\n",
      "[SKIP] ONLY_user_book already computed\n",
      "\n",
      "==========================================================================================\n",
      "Variant: user_book+tag | keep_rel_ids: 4\n",
      "[SKIP] user_book+tag already computed\n",
      "\n",
      "[OK] BIG ablation run finished ✅\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Run BIG ablations (tqdm + skip + save) [FIXED]\n",
    "# ============================\n",
    "\n",
    "RESULTS_DIR = ARTIFACTS / \"ablation_runs\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ----------------------------\n",
    "# Train loop: STABLE + tqdm\n",
    "# ----------------------------\n",
    "def train_one_run(\n",
    "    A_norm_cpu,\n",
    "    run_name,\n",
    "    emb_dim=64,\n",
    "    n_layers=3,\n",
    "    lr=1e-3,\n",
    "    epochs=12,             # FAST for big ablations\n",
    "    batch_size=300_000,    # your sweet spot\n",
    "    n_neg=1,\n",
    "    eval_every=1,\n",
    "    patience=3,            # FAST early stop\n",
    "):\n",
    "    \"\"\"\n",
    "    STABLE training:\n",
    "    - propagate per batch (robust)\n",
    "    - tqdm shows per-batch progress\n",
    "    \"\"\"\n",
    "    A_norm = A_norm_cpu.to(DEVICE)\n",
    "\n",
    "    model = LightGCN(num_nodes=num_nodes, emb_dim=emb_dim, n_layers=n_layers).to(DEVICE)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val = -1.0\n",
    "    best_state = None\n",
    "    bad = 0\n",
    "    history = []\n",
    "\n",
    "    n_train = train_ui.shape[0]\n",
    "    idx_all = np.arange(n_train)\n",
    "\n",
    "    user_off = int(offsets[\"user_offset\"])\n",
    "    book_off = int(offsets[\"book_offset\"])\n",
    "\n",
    "    for ep in range(1, epochs + 1):\n",
    "        np.random.shuffle(idx_all)\n",
    "\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        steps = 0\n",
    "\n",
    "        n_batches = math.ceil(n_train / batch_size)\n",
    "        pbar = tqdm(\n",
    "            range(0, n_train, batch_size),\n",
    "            total=n_batches,\n",
    "            desc=f\"{run_name} | ep {ep:03d}\",\n",
    "            leave=False\n",
    "        )\n",
    "\n",
    "        for s in pbar:\n",
    "            batch_idx = idx_all[s:s + batch_size]\n",
    "            batch = train_ui[batch_idx]  # [bs, 2]\n",
    "\n",
    "            users_np = batch[:, 0]\n",
    "            pos_np   = batch[:, 1]\n",
    "            neg_np   = sample_negatives(users_np, B, train_pos, n_neg=n_neg)[:, 0]\n",
    "\n",
    "            u = torch.from_numpy(users_np).to(DEVICE)\n",
    "            i_pos = torch.from_numpy(pos_np).to(DEVICE)\n",
    "            i_neg = torch.from_numpy(neg_np).to(DEVICE)\n",
    "\n",
    "            # STABLE: fresh autograd graph per batch\n",
    "            emb_all = model.propagate(A_norm)\n",
    "\n",
    "            u_emb   = emb_all[user_off + u]\n",
    "            pos_emb = emb_all[book_off + i_pos]\n",
    "            neg_emb = emb_all[book_off + i_neg]\n",
    "\n",
    "            loss = bpr_loss(u_emb, pos_emb, neg_emb)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            total_loss += float(loss.item())\n",
    "            steps += 1\n",
    "            pbar.set_postfix(loss=total_loss / max(1, steps))\n",
    "\n",
    "        avg_loss = total_loss / max(1, steps)\n",
    "\n",
    "        # ---- eval ----\n",
    "        if ep % eval_every == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                emb_all_eval = model.propagate(A_norm)\n",
    "\n",
    "            val_metrics = evaluate_loo(emb_all_eval, U, B, offsets, val_gt, train_pos, Ks=(10,20,50))\n",
    "            score = float(val_metrics[\"NDCG@10\"])\n",
    "\n",
    "            row = {\"run\": run_name, \"epoch\": ep, \"loss\": avg_loss, **val_metrics}\n",
    "            history.append(row)\n",
    "\n",
    "            print(f\"[{run_name}] ep={ep:03d} loss={avg_loss:.4f} | \"\n",
    "                  f\"Hit@10={val_metrics['Hit@10']:.5f} NDCG@10={val_metrics['NDCG@10']:.5f}\")\n",
    "\n",
    "            if score > best_val + 1e-6:\n",
    "                best_val = score\n",
    "                best_state = {\"model\": model.state_dict(), \"epoch\": ep, \"val_metrics\": val_metrics}\n",
    "                bad = 0\n",
    "            else:\n",
    "                bad += 1\n",
    "                if bad >= patience:\n",
    "                    print(f\"[{run_name}] Early stop at epoch {ep} (best val NDCG@10={best_val:.5f})\")\n",
    "                    break\n",
    "\n",
    "    return best_state, pd.DataFrame(history)\n",
    "\n",
    "# ----------------------------\n",
    "# Run variants\n",
    "# ----------------------------\n",
    "all_results = []\n",
    "all_hist = []\n",
    "\n",
    "for variant, keep_rel_ids in ablations_big:\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"Variant:\", variant, \"| keep_rel_ids:\", len(keep_rel_ids))\n",
    "\n",
    "    sum_path  = RESULTS_DIR / f\"summary_{variant}.json\"\n",
    "    hist_path = RESULTS_DIR / f\"hist_{variant}.csv\"\n",
    "\n",
    "    # SKIP if already done\n",
    "    if sum_path.exists() and hist_path.exists():\n",
    "        print(f\"[SKIP] {variant} already computed\")\n",
    "        with open(sum_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            all_results.append(json.load(f))\n",
    "        continue\n",
    "\n",
    "    # 1) filter edges\n",
    "    ei, ew, et = filter_edges_by_rel(edge_index_full, edge_w_full, edge_type_full, keep_rel_ids)\n",
    "    print(\"Filtered E:\", int(ei.shape[1]))\n",
    "\n",
    "    # 2) rebuild A_norm\n",
    "    A_var = build_sparse_norm(ei, ew, num_nodes)\n",
    "    print(\"A_var nnz:\", int(A_var._nnz()))\n",
    "\n",
    "    # 3) train\n",
    "    best_state, hist_df = train_one_run(\n",
    "        A_norm_cpu=A_var,\n",
    "        run_name=variant,\n",
    "        emb_dim=64,\n",
    "        n_layers=3,\n",
    "        lr=1e-3,\n",
    "        epochs=12,\n",
    "        batch_size=300_000,\n",
    "        n_neg=1,\n",
    "        patience=3\n",
    "    )\n",
    "\n",
    "    # 4) evaluate TEST\n",
    "    model = LightGCN(num_nodes=num_nodes, emb_dim=64, n_layers=3).to(DEVICE)\n",
    "    model.load_state_dict(best_state[\"model\"])\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        emb_all = model.propagate(A_var.to(DEVICE))\n",
    "\n",
    "    test_metrics = evaluate_loo(emb_all, U, B, offsets, test_gt, train_pos, Ks=(10,20,50))\n",
    "\n",
    "    row = {\n",
    "        \"variant\": variant,\n",
    "        \"best_epoch\": int(best_state[\"epoch\"]),\n",
    "        **{f\"val_{k}\": float(v) for k, v in best_state[\"val_metrics\"].items()},\n",
    "        **{f\"test_{k}\": float(v) for k, v in test_metrics.items()},\n",
    "        \"E\": int(ei.shape[1]),\n",
    "        \"nnz\": int(A_var._nnz()),\n",
    "        \"n_rel_ids\": int(len(keep_rel_ids)),\n",
    "    }\n",
    "\n",
    "    all_results.append(row)\n",
    "    all_hist.append(hist_df)\n",
    "\n",
    "    # save per-variant\n",
    "    hist_df.to_csv(hist_path, index=False)\n",
    "    with open(sum_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(row, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"[DONE] {variant} | TEST Hit@10={test_metrics['Hit@10']:.5f} NDCG@10={test_metrics['NDCG@10']:.5f}\")\n",
    "\n",
    "print(\"\\n[OK] BIG ablation run finished ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a076b7e-2a9f-4dc7-bc9a-6e2225803c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>n_rel_ids</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>E</th>\n",
       "      <th>nnz</th>\n",
       "      <th>test_Hit@10</th>\n",
       "      <th>test_NDCG@10</th>\n",
       "      <th>delta_test_NDCG@10</th>\n",
       "      <th>test_Hit@20</th>\n",
       "      <th>test_NDCG@20</th>\n",
       "      <th>delta_test_NDCG@20</th>\n",
       "      <th>test_Hit@50</th>\n",
       "      <th>test_NDCG@50</th>\n",
       "      <th>delta_test_NDCG@50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>11450076</td>\n",
       "      <td>11260518</td>\n",
       "      <td>0.055152</td>\n",
       "      <td>0.029817</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082887</td>\n",
       "      <td>0.036756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142945</td>\n",
       "      <td>0.048596</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ONLY_user_book</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>9852768</td>\n",
       "      <td>9852768</td>\n",
       "      <td>0.054983</td>\n",
       "      <td>0.029727</td>\n",
       "      <td>-0.000090</td>\n",
       "      <td>0.082924</td>\n",
       "      <td>0.036715</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>0.142833</td>\n",
       "      <td>0.048543</td>\n",
       "      <td>-0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_book+tag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>10852488</td>\n",
       "      <td>10852482</td>\n",
       "      <td>0.053878</td>\n",
       "      <td>0.029497</td>\n",
       "      <td>-0.000320</td>\n",
       "      <td>0.082194</td>\n",
       "      <td>0.036590</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>0.141110</td>\n",
       "      <td>0.048221</td>\n",
       "      <td>-0.000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-book_sim</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>10918914</td>\n",
       "      <td>10918894</td>\n",
       "      <td>0.053279</td>\n",
       "      <td>0.029020</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>0.080958</td>\n",
       "      <td>0.035954</td>\n",
       "      <td>-0.000802</td>\n",
       "      <td>0.140473</td>\n",
       "      <td>0.047699</td>\n",
       "      <td>-0.000897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-book_tag</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12</td>\n",
       "      <td>10450356</td>\n",
       "      <td>10260804</td>\n",
       "      <td>0.049496</td>\n",
       "      <td>0.027478</td>\n",
       "      <td>-0.002339</td>\n",
       "      <td>0.078392</td>\n",
       "      <td>0.034728</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>0.135361</td>\n",
       "      <td>0.045984</td>\n",
       "      <td>-0.002613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-book_lang</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12</td>\n",
       "      <td>11430078</td>\n",
       "      <td>11240520</td>\n",
       "      <td>0.047942</td>\n",
       "      <td>0.026509</td>\n",
       "      <td>-0.003308</td>\n",
       "      <td>0.076145</td>\n",
       "      <td>0.033570</td>\n",
       "      <td>-0.003186</td>\n",
       "      <td>0.132140</td>\n",
       "      <td>0.044649</td>\n",
       "      <td>-0.003948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-book_author</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12</td>\n",
       "      <td>11423646</td>\n",
       "      <td>11234102</td>\n",
       "      <td>0.047043</td>\n",
       "      <td>0.026382</td>\n",
       "      <td>-0.003434</td>\n",
       "      <td>0.075883</td>\n",
       "      <td>0.033607</td>\n",
       "      <td>-0.003148</td>\n",
       "      <td>0.131597</td>\n",
       "      <td>0.044615</td>\n",
       "      <td>-0.003981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-book_year</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>11430078</td>\n",
       "      <td>11240520</td>\n",
       "      <td>0.047418</td>\n",
       "      <td>0.026299</td>\n",
       "      <td>-0.003518</td>\n",
       "      <td>0.074778</td>\n",
       "      <td>0.033137</td>\n",
       "      <td>-0.003619</td>\n",
       "      <td>0.129668</td>\n",
       "      <td>0.043999</td>\n",
       "      <td>-0.004598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          variant  n_rel_ids  best_epoch         E       nnz  test_Hit@10  \\\n",
       "0            FULL        NaN          20  11450076  11260518     0.055152   \n",
       "1  ONLY_user_book        NaN          20   9852768   9852768     0.054983   \n",
       "2   user_book+tag        NaN          20  10852488  10852482     0.053878   \n",
       "3       -book_sim        NaN          20  10918914  10918894     0.053279   \n",
       "4       -book_tag        9.0          12  10450356  10260804     0.049496   \n",
       "5      -book_lang        9.0          12  11430078  11240520     0.047942   \n",
       "6    -book_author        9.0          12  11423646  11234102     0.047043   \n",
       "7      -book_year        9.0           4  11430078  11240520     0.047418   \n",
       "\n",
       "   test_NDCG@10  delta_test_NDCG@10  test_Hit@20  test_NDCG@20  \\\n",
       "0      0.029817            0.000000     0.082887      0.036756   \n",
       "1      0.029727           -0.000090     0.082924      0.036715   \n",
       "2      0.029497           -0.000320     0.082194      0.036590   \n",
       "3      0.029020           -0.000797     0.080958      0.035954   \n",
       "4      0.027478           -0.002339     0.078392      0.034728   \n",
       "5      0.026509           -0.003308     0.076145      0.033570   \n",
       "6      0.026382           -0.003434     0.075883      0.033607   \n",
       "7      0.026299           -0.003518     0.074778      0.033137   \n",
       "\n",
       "   delta_test_NDCG@20  test_Hit@50  test_NDCG@50  delta_test_NDCG@50  \n",
       "0            0.000000     0.142945      0.048596            0.000000  \n",
       "1           -0.000041     0.142833      0.048543           -0.000053  \n",
       "2           -0.000166     0.141110      0.048221           -0.000375  \n",
       "3           -0.000802     0.140473      0.047699           -0.000897  \n",
       "4           -0.002028     0.135361      0.045984           -0.002613  \n",
       "5           -0.003186     0.132140      0.044649           -0.003948  \n",
       "6           -0.003148     0.131597      0.044615           -0.003981  \n",
       "7           -0.003619     0.129668      0.043999           -0.004598  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline FULL:\n",
      "  FULL test_NDCG@10 = 0.029817\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Summarize ablations (delta vs FULL)\n",
    "# ============================\n",
    "\n",
    "res_big = pd.DataFrame(all_results).copy()\n",
    "if res_big.empty:\n",
    "    import json\n",
    "    rows = []\n",
    "    for p in sorted(RESULTS_DIR.glob(\"summary_*.json\")):\n",
    "        with open(p, \"r\", encoding=\"utf-8\") as f:\n",
    "            rows.append(json.load(f))\n",
    "    res_big = pd.DataFrame(rows)\n",
    "\n",
    "# FULL as baseline\n",
    "full_row = res_big[res_big[\"variant\"] == \"FULL\"]\n",
    "if len(full_row) == 0:\n",
    "    raise ValueError(\"FULL variant not found in results. Run FULL at least once.\")\n",
    "\n",
    "full = full_row.iloc[0]\n",
    "\n",
    "for k in [\"test_NDCG@10\", \"test_Hit@10\", \"test_NDCG@20\", \"test_Hit@20\", \"test_NDCG@50\", \"test_Hit@50\"]:\n",
    "    res_big[f\"delta_{k}\"] = res_big[k] - float(full[k])\n",
    "\n",
    "# Sort by main metric\n",
    "res_big = res_big.sort_values(\"test_NDCG@10\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "cols = [\n",
    "    \"variant\", \"n_rel_ids\", \"best_epoch\", \"E\", \"nnz\",\n",
    "    \"test_Hit@10\", \"test_NDCG@10\", \"delta_test_NDCG@10\",\n",
    "    \"test_Hit@20\", \"test_NDCG@20\", \"delta_test_NDCG@20\",\n",
    "    \"test_Hit@50\", \"test_NDCG@50\", \"delta_test_NDCG@50\",\n",
    "]\n",
    "display(res_big[cols])\n",
    "\n",
    "print(\"Baseline FULL:\")\n",
    "print(f\"  FULL test_NDCG@10 = {float(full['test_NDCG@10']):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c9cd806-0044-4ba3-8b2c-94d55273eeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved: D:\\ML\\GNN\\graph_recsys\\artifacts\\v2_proper\\ablation_runs\\ablation_summary_BIG.csv\n",
      "[OK] saved: D:\\ML\\GNN\\graph_recsys\\artifacts\\v2_proper\\ablation_runs\\ablation_summary_BIG_compact.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Save final results table\n",
    "# ============================\n",
    "out_csv = RESULTS_DIR / \"ablation_summary_BIG.csv\"\n",
    "res_big.to_csv(out_csv, index=False)\n",
    "print(\"[OK] saved:\", out_csv)\n",
    "\n",
    "# Дополнительно — компактная \"витринная\" таблица\n",
    "out_csv_small = RESULTS_DIR / \"ablation_summary_BIG_compact.csv\"\n",
    "compact_cols = [\n",
    "    \"variant\",\n",
    "    \"test_Hit@10\", \"test_NDCG@10\",\n",
    "    \"test_Hit@20\", \"test_NDCG@20\",\n",
    "    \"test_Hit@50\", \"test_NDCG@50\",\n",
    "    \"delta_test_NDCG@10\",\n",
    "    \"E\", \"nnz\", \"best_epoch\"\n",
    "]\n",
    "res_big[compact_cols].to_csv(out_csv_small, index=False)\n",
    "print(\"[OK] saved:\", out_csv_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bc50b7-891a-480f-bada-909ae2f7acea",
   "metadata": {},
   "source": [
    "## Ablation Study Summary (Graph3 + LightGCN)\n",
    "\n",
    "In this notebook, we conducted a systematic **ablation study** on the enriched **Graph3** constructed from the **Goodbooks-10k** dataset in order to quantify the contribution of different relation types to recommendation quality.\n",
    "\n",
    "### Experimental Setup\n",
    "- **Model:** LightGCN  \n",
    "- **Graph:** Unified node space (users, books, tags, authors, language, year_bin)  \n",
    "- **Task:** Link prediction / recommendation  \n",
    "- **Evaluation:** Leave-One-Out (LOO)  \n",
    "- **Metrics:** Hit@K, NDCG@K  \n",
    "- **Baseline:** FULL graph with all relation types enabled  \n",
    "\n",
    "### Ablation Variants\n",
    "We evaluated the impact of removing or isolating specific relation groups:\n",
    "- Removal of individual relations (`-book_tag`, `-book_author`, `-book_lang`, `-book_year`, `-book_sim`);\n",
    "- Simplified graph structures (`ONLY_user_book`, `user_book+tag`);\n",
    "- All variants were compared against the FULL graph baseline.\n",
    "\n",
    "### Key Results (TEST NDCG@10)\n",
    "\n",
    "| Variant | TEST NDCG@10 | Δ vs FULL |\n",
    "|------|-------------|-----------|\n",
    "| **FULL** | **0.0298** | baseline |\n",
    "| ONLY_user_book | 0.0297 | −0.0001 |\n",
    "| user_book+tag | 0.0295 | −0.0003 |\n",
    "| −book_sim | 0.0290 | −0.0008 |\n",
    "| **−book_tag** | 0.0275 | −0.0023 |\n",
    "| **−book_lang** | 0.0265 | −0.0033 |\n",
    "| **−book_author** | 0.0264 | −0.0034 |\n",
    "| **−book_year** | 0.0263 | −0.0035 |\n",
    "\n",
    "### Main Observations\n",
    "\n",
    "1. **User–Book interactions carry the dominant signal**  \n",
    "   A graph containing only user–book edges achieves almost the same performance as the full graph.\n",
    "\n",
    "2. **Book–Book similarity provides a small but consistent benefit**  \n",
    "   Removing TF-IDF–based similarity edges leads to a measurable degradation in ranking quality.\n",
    "\n",
    "3. **Content-based meta-relations are critical when used together**  \n",
    "   Removing relations related to:\n",
    "   - publication year,\n",
    "   - authors,\n",
    "   - language,\n",
    "   - tags  \n",
    "   results in a substantial performance drop (up to −0.0035 NDCG@10).\n",
    "\n",
    "4. **Individual content signals do not work well in isolation**  \n",
    "   The `user_book+tag` variant underperforms the full graph, indicating that tags alone introduce noise unless supported by additional contextual relations.\n",
    "\n",
    "5. **LightGCN does not explicitly model heterogeneity**  \n",
    "   All neighbors are aggregated uniformly, without:\n",
    "   - relation-specific parameters,\n",
    "   - attention mechanisms,\n",
    "   - explicit node or edge typing.  \n",
    "\n",
    "   As a result, the model fails to fully exploit the rich heterogeneous structure of Graph3.\n",
    "\n",
    "### Final Conclusion\n",
    "\n",
    "This ablation study demonstrates that:\n",
    "- the enriched Graph3 contains meaningful and complementary signals;\n",
    "- **LightGCN acts as the main bottleneck** when applied to heterogeneous graphs;\n",
    "- further improvements are unlikely to come from adding more edges or features, but rather from **more expressive, relation-aware architectures**.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "The natural continuation of this work is to transition to models that explicitly account for relation types, such as:\n",
    "- **Relational GCN (R-GCN) / HeteroConv**\n",
    "- **Heterogeneous Graph Transformer (HGT)**\n",
    "\n",
    "These models are better suited to leverage the full potential of Graph3 and to assess whether its rich structure can translate into meaningful gains in recommendation quality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - GNN (clean)",
   "language": "python",
   "name": "gnn_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
