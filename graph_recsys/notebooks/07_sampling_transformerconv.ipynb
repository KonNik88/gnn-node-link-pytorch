{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dc04f9d-2f6e-4740-8d50-afda5345283a",
   "metadata": {},
   "source": [
    "TransformerConv (Neighbor Sampling) for Ranking on Graph3 (Goodbooks-10k)\n",
    "\n",
    "In this notebook we train a Transformer-like GNN for recommendations using PyG TransformerConv with mini-batch neighbor sampling on the Goodbooks-10k interaction graph.\n",
    "\n",
    "Motivation\n",
    "\n",
    "R-GCN (BCE) failed due to an objective–metric mismatch.\n",
    "\n",
    "Sampling-based models with BPR restored ranking performance.\n",
    "\n",
    "GAT + BPR outperformed GraphSAGE, suggesting attention helps.\n",
    "\n",
    "Here we test TransformerConv, which is an attention-style message passing layer inspired by Transformers.\n",
    "\n",
    "Setup\n",
    "\n",
    "Graph: start with user–book bipartite graph (train interactions only) to keep comparisons fair.\n",
    "\n",
    "Training: NeighborLoader + BPR loss.\n",
    "\n",
    "Evaluation: LOO candidate-based ranking:\n",
    "\n",
    "Hit@10/20/50, NDCG@10/20/50\n",
    "\n",
    "C=1000 (main) and optionally C=2000 (stricter)\n",
    "\n",
    "Artifacts\n",
    "\n",
    "We load splits from the frozen Graph3 bundle:\n",
    "D:/ML/GNN/graph_recsys/artifacts/v2_proper/graph3_bundle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4efbc355-9d9f-4c53-866c-f537b400caf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n",
      "BUNDLE_DIR: D:\\ML\\GNN\\graph_recsys\\artifacts\\v2_proper\\graph3_bundle\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 1: Imports + device + paths\n",
    "# ============================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "PROJECT_ROOT = Path(r\"D:/ML/GNN/graph_recsys\")\n",
    "ARTIFACTS = PROJECT_ROOT / \"artifacts\" / \"v2_proper\"\n",
    "BUNDLE_DIR = ARTIFACTS / \"graph3_bundle\"\n",
    "\n",
    "print(\"BUNDLE_DIR:\", BUNDLE_DIR)\n",
    "assert BUNDLE_DIR.exists(), f\"Missing bundle: {BUNDLE_DIR}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c3a61d6-9037-4a81-9341-fb12f1cdbebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/val/test: (4926384, 2) (53398, 2) (53398, 2)\n",
      "U, B: 53398 9999\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 2: Load LOO splits\n",
    "# Purpose:\n",
    "# - Load train interactions and LOO validation/test ground truth\n",
    "# ============================\n",
    "\n",
    "z = np.load(BUNDLE_DIR / \"splits_ui.npz\", allow_pickle=True)\n",
    "\n",
    "train_ui = z[\"train_ui\"].astype(np.int64)\n",
    "val_ui   = z[\"val_ui\"].astype(np.int64)\n",
    "test_ui  = z[\"test_ui\"].astype(np.int64)\n",
    "\n",
    "U = int(z[\"U\"])\n",
    "B = int(z[\"B\"])\n",
    "\n",
    "print(\"train/val/test:\", train_ui.shape, val_ui.shape, test_ui.shape)\n",
    "print(\"U, B:\", U, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50c0d7c8-bccd-4802-ae43-d07eaf28921e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_pos users: 53398\n",
      "val_gt: 53398 test_gt: 53398\n",
      "[val] leaks: 0 / 53398\n",
      "[test] leaks: 0 / 53398\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 3: Build train positives + LOO ground truth\n",
    "# Purpose:\n",
    "# - train_pos: what items each user interacted with in train\n",
    "# - val_gt/test_gt: leave-one-out item per user\n",
    "# - leak check: gt must NOT be in train_pos\n",
    "# ============================\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "train_pos = defaultdict(set)\n",
    "for u, i in train_ui:\n",
    "    train_pos[int(u)].add(int(i))\n",
    "\n",
    "val_gt  = {int(u): int(i) for u, i in val_ui}\n",
    "test_gt = {int(u): int(i) for u, i in test_ui}\n",
    "\n",
    "leaks_val = sum(1 for u, i in val_gt.items() if i in train_pos[u])\n",
    "leaks_test = sum(1 for u, i in test_gt.items() if i in train_pos[u])\n",
    "\n",
    "print(\"train_pos users:\", len(train_pos))\n",
    "print(\"val_gt:\", len(val_gt), \"test_gt:\", len(test_gt))\n",
    "print(\"[val] leaks:\", leaks_val, \"/\", len(val_gt))\n",
    "print(\"[test] leaks:\", leaks_test, \"/\", len(test_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "015a2e94-0141-4446-b2da-1095fda58794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_index_ui: (2, 9852768) num_nodes_ui: 63397\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 4: Build user-book edge_index\n",
    "# Notes:\n",
    "# - user nodes: [0..U-1]\n",
    "# - item nodes: [U..U+B-1]\n",
    "# - undirected edges (u<->i) as required by message passing\n",
    "# ============================\n",
    "\n",
    "u = torch.from_numpy(train_ui[:, 0]).long()\n",
    "i = torch.from_numpy(train_ui[:, 1]).long() + U\n",
    "\n",
    "row = torch.cat([u, i], dim=0)\n",
    "col = torch.cat([i, u], dim=0)\n",
    "\n",
    "edge_index_ui = torch.stack([row, col], dim=0)\n",
    "num_nodes_ui = U + B\n",
    "\n",
    "print(\"edge_index_ui:\", tuple(edge_index_ui.shape), \"num_nodes_ui:\", num_nodes_ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2751f8b9-c4ec-4716-ad7f-50aad99d5a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding_dim': 64,\n",
       " 'num_layers': 2,\n",
       " 'heads': 2,\n",
       " 'dropout': 0.1,\n",
       " 'batch_size_users': 512,\n",
       " 'neighbors': [15, 10],\n",
       " 'lr': 0.001,\n",
       " 'weight_decay': 1e-06,\n",
       " 'epochs': 30,\n",
       " 'bpr_reg': 1e-06,\n",
       " 'seed': 42,\n",
       " 'patience': 5,\n",
       " 'min_delta': 0.0001}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 5: PyG Data + NeighborLoader config\n",
    "# Notes:\n",
    "# - TransformerConv can be heavier than GAT depending on heads/dropout\n",
    "# - Start with moderate batch size and small number of heads\n",
    "# ============================\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "CFG = {\n",
    "    \"embedding_dim\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"heads\": 2,                 # multi-head attention\n",
    "    \"dropout\": 0.1,\n",
    "    \"batch_size_users\": 512,    # safer default (TransformerConv can be heavy)\n",
    "    \"neighbors\": [15, 10],\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"epochs\": 30,\n",
    "    \"bpr_reg\": 1e-6,\n",
    "    \"seed\": 42,\n",
    "    \"patience\": 5,\n",
    "    \"min_delta\": 1e-4,\n",
    "}\n",
    "CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "999ded20-9ef1-43e8-9c66-76e11a2a6240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 45090], num_nodes=30042, n_id=[30042], e_id=[45090], num_sampled_nodes=[3], num_sampled_edges=[2], input_id=[512], batch_size=512)\n",
      "batch.num_nodes: 30042 batch.edge_index: torch.Size([2, 45090])\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 5b: Instantiate NeighborLoader + smoke batch\n",
    "# ============================\n",
    "\n",
    "SEED = CFG[\"seed\"]\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "data_ui = Data(edge_index=edge_index_ui, num_nodes=num_nodes_ui)\n",
    "\n",
    "train_user_nodes = torch.arange(U, dtype=torch.long)\n",
    "\n",
    "train_loader = NeighborLoader(\n",
    "    data_ui,\n",
    "    input_nodes=train_user_nodes,\n",
    "    num_neighbors=CFG[\"neighbors\"],\n",
    "    batch_size=CFG[\"batch_size_users\"],\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    persistent_workers=False\n",
    ")\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "print(batch)\n",
    "print(\"batch.num_nodes:\", batch.num_nodes, \"batch.edge_index:\", batch.edge_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c46e7991-08f4-4517-bd80-d06bf5d8af9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min/mean/max train_pos size: 3 92.25783737218623 197\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 6: Random positive sampling + negative sampling + BPR loss\n",
    "# ============================\n",
    "\n",
    "train_pos_arr = {}\n",
    "train_pos_size = np.zeros(U, dtype=np.int32)\n",
    "\n",
    "for uu in range(U):\n",
    "    arr = np.fromiter(train_pos[uu], dtype=np.int64)\n",
    "    train_pos_arr[uu] = arr\n",
    "    train_pos_size[uu] = arr.size\n",
    "\n",
    "print(\"min/mean/max train_pos size:\", train_pos_size.min(), train_pos_size.mean(), train_pos_size.max())\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "def sample_positives(users_np: np.ndarray):\n",
    "    pos = np.empty_like(users_np, dtype=np.int64)\n",
    "    for idx, uu in enumerate(users_np):\n",
    "        arr = train_pos_arr[int(uu)]\n",
    "        pos[idx] = int(arr[rng.integers(0, arr.size)])\n",
    "    return pos\n",
    "\n",
    "def sample_negatives(users_np: np.ndarray):\n",
    "    neg = np.empty_like(users_np, dtype=np.int64)\n",
    "    for idx, uu in enumerate(users_np):\n",
    "        seen = train_pos[int(uu)]\n",
    "        while True:\n",
    "            j = int(rng.integers(0, B))\n",
    "            if j not in seen:\n",
    "                neg[idx] = j\n",
    "                break\n",
    "    return neg\n",
    "\n",
    "def bpr_loss(u_emb, p_emb, n_emb, reg=0.0):\n",
    "    pos_scores = (u_emb * p_emb).sum(dim=-1)\n",
    "    neg_scores = (u_emb * n_emb).sum(dim=-1)\n",
    "    loss = -torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-8).mean()\n",
    "    if reg > 0:\n",
    "        loss = loss + reg * (u_emb.pow(2).mean() + p_emb.pow(2).mean() + n_emb.pow(2).mean())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a132cbba-709c-4c5c-82ac-961ea1625a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerRec(\n",
      "  (emb): Embedding(63397, 64)\n",
      "  (convs): ModuleList(\n",
      "    (0-1): 2 x TransformerConv(64, 64, heads=2)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 7: TransformerConv recommender model\n",
    "# Notes:\n",
    "# - concat=False keeps output dim == embedding_dim (no heads*dim explosion)\n",
    "# - We use ELU + dropout similar to GAT experiments\n",
    "# ============================\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import TransformerConv\n",
    "\n",
    "class TransformerRec(nn.Module):\n",
    "    def __init__(self, num_nodes: int, dim: int, num_layers: int, heads: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.dim = dim\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.emb = nn.Embedding(num_nodes, dim)\n",
    "        nn.init.normal_(self.emb.weight, std=0.1)\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.convs.append(\n",
    "                TransformerConv(\n",
    "                    in_channels=dim,\n",
    "                    out_channels=dim,\n",
    "                    heads=heads,\n",
    "                    concat=False,\n",
    "                    dropout=dropout,\n",
    "                    beta=True  # allows residual weighting (often helps)\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, n_id, edge_index):\n",
    "        h = self.emb(n_id)\n",
    "        for conv in self.convs:\n",
    "            h = conv(h, edge_index)\n",
    "            h = F.elu(h)\n",
    "            h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        return h\n",
    "\n",
    "model = TransformerRec(\n",
    "    num_nodes=num_nodes_ui,\n",
    "    dim=CFG[\"embedding_dim\"],\n",
    "    num_layers=CFG[\"num_layers\"],\n",
    "    heads=CFG[\"heads\"],\n",
    "    dropout=CFG[\"dropout\"],\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "576beb60-775f-40ab-8fec-235f45098946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Cell 8: Train one epoch (NeighborLoader + BPR)\n",
    "# Notes:\n",
    "# - Same approach as GraphSAGE/GAT notebooks for fair comparison.\n",
    "# - Fallback to raw embeddings if pos/neg nodes are not in the sampled subgraph.\n",
    "# ============================\n",
    "\n",
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    steps = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=\"train\"):\n",
    "        batch = batch.to(DEVICE)\n",
    "        n_id = batch.n_id\n",
    "        seed_users = batch.input_id\n",
    "        users_np = seed_users.detach().cpu().numpy()\n",
    "\n",
    "        pos_items = sample_positives(users_np)\n",
    "        neg_items = sample_negatives(users_np)\n",
    "\n",
    "        pos_nodes = torch.from_numpy(pos_items).long().to(DEVICE) + U\n",
    "        neg_nodes = torch.from_numpy(neg_items).long().to(DEVICE) + U\n",
    "\n",
    "        h = model(n_id, batch.edge_index)\n",
    "\n",
    "        idx_map = torch.full((num_nodes_ui,), -1, device=DEVICE, dtype=torch.long)\n",
    "        idx_map[n_id] = torch.arange(n_id.size(0), device=DEVICE)\n",
    "\n",
    "        u_loc = idx_map[seed_users]\n",
    "        p_loc = idx_map[pos_nodes]\n",
    "        n_loc = idx_map[neg_nodes]\n",
    "\n",
    "        u_emb = h[u_loc]\n",
    "\n",
    "        def get_item_emb(loc_idx, global_nodes):\n",
    "            mask = loc_idx >= 0\n",
    "            out = torch.empty((global_nodes.size(0), CFG[\"embedding_dim\"]), device=DEVICE)\n",
    "            out[mask] = h[loc_idx[mask]]\n",
    "            out[~mask] = model.emb(global_nodes[~mask])  # fallback\n",
    "            return out\n",
    "\n",
    "        p_emb = get_item_emb(p_loc, pos_nodes)\n",
    "        n_emb = get_item_emb(n_loc, neg_nodes)\n",
    "\n",
    "        loss = bpr_loss(u_emb, p_emb, n_emb, reg=CFG[\"bpr_reg\"])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss.detach().cpu())\n",
    "        steps += 1\n",
    "\n",
    "    return total_loss / max(1, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a986d6d-0205-42bc-8c48-2213ba1c2bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d6cf9413a34893b65a1f7eb52aaf37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke eval (C=200): {'Hit@10': 0.055, 'Hit@20': 0.1035, 'Hit@50': 0.2595, 'NDCG@10': 0.025147360479841042, 'NDCG@20': 0.03740782827916556, 'NDCG@50': 0.06784492906237218}\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 9: Candidate-based LOO evaluation (fast)\n",
    "# Notes:\n",
    "# - Uses raw embedding table for speed (as in previous notebooks)\n",
    "# - Main comparison signal: NDCG@10 with C=1000\n",
    "# ============================\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_loo_sampled(model, gt_dict, users_subset, C=1000, Ks=(10, 20, 50), seed=42):\n",
    "    model.eval()\n",
    "    rng_local = np.random.default_rng(seed)\n",
    "\n",
    "    hits = {k: 0 for k in Ks}\n",
    "    ndcgs = {k: 0.0 for k in Ks}\n",
    "\n",
    "    emb = model.emb.weight.detach()\n",
    "\n",
    "    for u in tqdm(users_subset, desc=f\"eval(C={C})\"):\n",
    "        gt = int(gt_dict[int(u)])\n",
    "\n",
    "        negs = []\n",
    "        seen = train_pos[int(u)]\n",
    "        while len(negs) < C - 1:\n",
    "            j = int(rng_local.integers(0, B))\n",
    "            if (j not in seen) and (j != gt):\n",
    "                negs.append(j)\n",
    "\n",
    "        cand_items = np.array([gt] + negs, dtype=np.int64)\n",
    "        cand_nodes = torch.from_numpy(cand_items).long().to(DEVICE) + U\n",
    "\n",
    "        u_node = torch.tensor([int(u)], device=DEVICE, dtype=torch.long)\n",
    "        u_vec = emb[u_node]\n",
    "        i_vec = emb[cand_nodes]\n",
    "        scores = (u_vec * i_vec).sum(dim=-1)\n",
    "\n",
    "        rank = torch.argsort(scores, descending=True)\n",
    "        gt_pos = (rank == 0).nonzero(as_tuple=False).item()\n",
    "\n",
    "        for k in Ks:\n",
    "            if gt_pos < k:\n",
    "                hits[k] += 1\n",
    "                ndcgs[k] += 1.0 / math.log2(gt_pos + 2)\n",
    "\n",
    "    n = len(users_subset)\n",
    "    out = {f\"Hit@{k}\": hits[k] / n for k in Ks}\n",
    "    out.update({f\"NDCG@{k}\": ndcgs[k] / n for k in Ks})\n",
    "    return out\n",
    "\n",
    "subset_2k = np.random.default_rng(SEED).choice(np.arange(U), size=2000, replace=False)\n",
    "subset_10k = np.random.default_rng(SEED).choice(np.arange(U), size=10000, replace=False)\n",
    "\n",
    "print(\"Smoke eval (C=200):\", eval_loo_sampled(model, val_gt, subset_2k, C=200, Ks=(10,20,50), seed=SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b8ceeeb-73f9-4be2-a58c-8646eb7696d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ef90b414b5476f8c92401b134564a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fba1ed2a037471983c30deecce00c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1b70391c9849118e1d94dc9e3bf0dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=01 loss=0.5326 | val(C=200) NDCG@10=0.04031 | val(C=1000) NDCG@10=0.011215\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d4b374d6bc4dbcac6e1e89256039ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afae65f4cbd349328578e9ef6cd22ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e83283a87ac46b2b6722095b9b8b3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=02 loss=0.4658 | val(C=200) NDCG@10=0.05711 | val(C=1000) NDCG@10=0.017288\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7bc7559b4904a5ea1f3de4fe596ed25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afdb78f8b174419daa7799368b6b6540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2929c6928344108a1acb698c96cc800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=03 loss=0.4554 | val(C=200) NDCG@10=0.06539 | val(C=1000) NDCG@10=0.020264\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f11bc73a6134695994f22b753126707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "affa2282f0c84a809b798d1a430df40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bbfbd44d3934765a5196cdc956f741c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=04 loss=0.4426 | val(C=200) NDCG@10=0.07072 | val(C=1000) NDCG@10=0.022463\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673a6104f9e94d0cb5dbf7bb214970bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8acd31669b54657b3cd5ffeaf285360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4d5a4808784771b0ce9a9d58b87d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=05 loss=0.4434 | val(C=200) NDCG@10=0.07174 | val(C=1000) NDCG@10=0.023806\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d43c5565554a4cb4ce9f71afd682b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a066cfb8f7248ae8aa6b2724f602441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac3b662461241eb910985d45a4619d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=06 loss=0.4283 | val(C=200) NDCG@10=0.07460 | val(C=1000) NDCG@10=0.026128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a8182de97a488296d0185be001c250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def1f6931c9c4849abad7c331c1eaee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f32808155e85447abf8bc8d5caedcccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=07 loss=0.4287 | val(C=200) NDCG@10=0.07900 | val(C=1000) NDCG@10=0.027205\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e94fbbe444c4dc4bb532ce72a589ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67681f02735c40239e072ecfaded75ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d169d8b906497787672338c9ec8caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=08 loss=0.4210 | val(C=200) NDCG@10=0.08175 | val(C=1000) NDCG@10=0.027982\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e3a5e2168b403ab6aa21e67dd1a0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c2475b15574ac59e526a219334631a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7050bc39149b4ca4852c5ec5689bad2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=09 loss=0.4129 | val(C=200) NDCG@10=0.08701 | val(C=1000) NDCG@10=0.030402\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6479c1c61a4b798fca7f002c85c660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0513511374c48a0975b10820846971c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41888fbc85634123987703a6d44034c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=10 loss=0.3971 | val(C=200) NDCG@10=0.08883 | val(C=1000) NDCG@10=0.030716\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ab290e7e5247138c3c57609299e16e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52172586ea1b4a08ab43bb53c701a9ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6d9d95c7fe4049942d109a5d08aaf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=11 loss=0.3862 | val(C=200) NDCG@10=0.09338 | val(C=1000) NDCG@10=0.033329\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288cec1f35f041f7ad4ff93e013858e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50bf0021704f4b1c82e2703d92f440c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f857b5b1176431da4ce65b0ecd0709b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=12 loss=0.3751 | val(C=200) NDCG@10=0.09626 | val(C=1000) NDCG@10=0.033771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156a13ea3c9e4d4789cd04254e6dee2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "565ca570a45b44aaad40906f467f4a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d90cba022348aab40d0da5b3c98738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=13 loss=0.3708 | val(C=200) NDCG@10=0.09726 | val(C=1000) NDCG@10=0.033391\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7d13c96dba4478b44893c1f1631bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1373cf17971405d9e317b89567705a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da49a5ae1e441268118d91f238ab7ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=14 loss=0.3615 | val(C=200) NDCG@10=0.09587 | val(C=1000) NDCG@10=0.033835\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae9ed4a0a9e41439005ba98303e92f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667749141b7a46d190aa955fac7f2b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b10ca4aa9c34e4ba9dc3ce01eb46780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=15 loss=0.3544 | val(C=200) NDCG@10=0.09532 | val(C=1000) NDCG@10=0.032505\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b337f7c7e813403199d311f612f74626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e05def1ded6455dbf734e46afe89e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d397e7175bd94e34b827457a233ee1dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=16 loss=0.3449 | val(C=200) NDCG@10=0.09625 | val(C=1000) NDCG@10=0.032885\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863d09da248443c6989f8e91e862b3ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d0db8937b043fe8aa052a3dc89372c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ce710f36fe4fb39dfaa61f25b28192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=17 loss=0.3492 | val(C=200) NDCG@10=0.09470 | val(C=1000) NDCG@10=0.033470\n",
      "Early stopping at epoch 17. Best epoch=12 best NDCG@10=0.033771\n",
      "Loaded best checkpoint: 12 best val NDCG@10: 0.03377127617123508\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 10: Train up to 30 epochs + early stopping on val NDCG@10 (C=1000)\n",
    "# ============================\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class EarlyStopper:\n",
    "    patience: int = 5\n",
    "    min_delta: float = 1e-4\n",
    "    best: float = -1e9\n",
    "    best_epoch: int = -1\n",
    "    bad_count: int = 0\n",
    "    best_state: dict = None\n",
    "\n",
    "    def step(self, metric_value: float, model: torch.nn.Module, epoch: int) -> bool:\n",
    "        improved = metric_value > (self.best + self.min_delta)\n",
    "        if improved:\n",
    "            self.best = metric_value\n",
    "            self.best_epoch = epoch\n",
    "            self.bad_count = 0\n",
    "            self.best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            self.bad_count += 1\n",
    "        return self.bad_count >= self.patience\n",
    "\n",
    "    def load_best(self, model: torch.nn.Module, device=DEVICE):\n",
    "        model.load_state_dict({k: v.to(device) for k, v in self.best_state.items()})\n",
    "\n",
    "EARLY = EarlyStopper(patience=CFG[\"patience\"], min_delta=CFG[\"min_delta\"])\n",
    "\n",
    "history = []\n",
    "for ep in range(1, CFG[\"epochs\"] + 1):\n",
    "    loss = train_one_epoch()\n",
    "\n",
    "    m200 = eval_loo_sampled(model, val_gt, subset_2k, C=200, Ks=(10,20,50), seed=SEED)\n",
    "    m1000 = eval_loo_sampled(model, val_gt, subset_10k, C=1000, Ks=(10,20,50), seed=SEED)\n",
    "    val_ndcg10 = float(m1000[\"NDCG@10\"])\n",
    "\n",
    "    history.append({\"epoch\": ep, \"loss\": loss,\n",
    "                    **{f\"val200_{k}\": v for k, v in m200.items()},\n",
    "                    **{f\"val1000_{k}\": v for k, v in m1000.items()}})\n",
    "\n",
    "    print(\n",
    "        f\"epoch={ep:02d} loss={loss:.4f} | \"\n",
    "        f\"val(C=200) NDCG@10={m200['NDCG@10']:.5f} | \"\n",
    "        f\"val(C=1000) NDCG@10={val_ndcg10:.6f}\"\n",
    "    )\n",
    "\n",
    "    if EARLY.step(val_ndcg10, model, ep):\n",
    "        print(f\"Early stopping at epoch {ep}. Best epoch={EARLY.best_epoch} best NDCG@10={EARLY.best:.6f}\")\n",
    "        break\n",
    "\n",
    "EARLY.load_best(model, device=DEVICE)\n",
    "print(\"Loaded best checkpoint:\", EARLY.best_epoch, \"best val NDCG@10:\", EARLY.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab56e4ff-f6c4-4b63-8e8c-afcd8e6f13d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4da6345c94347ea9d5265a25cd7cb19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST (C=1000, 10k users): {'Hit@10': 0.0672, 'Hit@20': 0.1064, 'Hit@50': 0.1794, 'NDCG@10': 0.033345572142068285, 'NDCG@20': 0.04318613558125753, 'NDCG@50': 0.057575686738235994}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7896795d7f4439aaeb1acacf1b559a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=2000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST (C=2000, 10k users): {'Hit@10': 0.0412, 'Hit@20': 0.0659, 'Hit@50': 0.1213, 'NDCG@10': 0.020895186405055798, 'NDCG@20': 0.027123912058835215, 'NDCG@50': 0.03805636473930741}\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 11: Final TEST evaluation\n",
    "# ============================\n",
    "\n",
    "test_subset_10k = np.random.default_rng(SEED + 123).choice(np.arange(U), size=10000, replace=False)\n",
    "\n",
    "test_m1000 = eval_loo_sampled(model, test_gt, test_subset_10k, C=1000, Ks=(10,20,50), seed=SEED + 123)\n",
    "print(\"TEST (C=1000, 10k users):\", test_m1000)\n",
    "\n",
    "test_m2000 = eval_loo_sampled(model, test_gt, test_subset_10k, C=2000, Ks=(10,20,50), seed=SEED + 123)\n",
    "print(\"TEST (C=2000, 10k users):\", test_m2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c46c56db-ed09-42df-8095-54b1070e14ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\ML\\GNN\\graph_recsys\\artifacts\\v2_proper\\ablation_runs\\transformerconv_sampling\\history_transformerconv_bpr_sampled_eval.csv\n",
      "Saved: D:\\ML\\GNN\\graph_recsys\\artifacts\\v2_proper\\ablation_runs\\transformerconv_sampling\\transformerconv_bpr_best.pt\n",
      "Saved: D:\\ML\\GNN\\graph_recsys\\artifacts\\v2_proper\\ablation_runs\\transformerconv_sampling\\run_meta.json\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 12: Save run artifacts\n",
    "# ============================\n",
    "\n",
    "hist_df = pd.DataFrame(history)\n",
    "out_dir = ARTIFACTS / \"ablation_runs\" / \"transformerconv_sampling\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "hist_path = out_dir / \"history_transformerconv_bpr_sampled_eval.csv\"\n",
    "hist_df.to_csv(hist_path, index=False)\n",
    "\n",
    "meta = {\n",
    "    \"best_epoch\": EARLY.best_epoch,\n",
    "    \"best_val_ndcg10_C1000_10k\": float(EARLY.best),\n",
    "    \"config\": CFG,\n",
    "    \"bundle_dir\": str(BUNDLE_DIR),\n",
    "}\n",
    "with open(out_dir / \"run_meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "ckpt_path = out_dir / \"transformerconv_bpr_best.pt\"\n",
    "torch.save({\"state_dict\": EARLY.best_state, \"meta\": meta}, ckpt_path)\n",
    "\n",
    "print(\"Saved:\", hist_path)\n",
    "print(\"Saved:\", ckpt_path)\n",
    "print(\"Saved:\", out_dir / \"run_meta.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fccf70-5ddc-4fd9-94e3-69460725da91",
   "metadata": {},
   "source": [
    "## Results & Conclusions\n",
    "### What we did\n",
    "\n",
    "Trained a TransformerConv-based recommender on the user–book bipartite graph using:\n",
    "\n",
    "Neighbor sampling (mini-batch training with NeighborLoader)\n",
    "\n",
    "BPR loss (pairwise ranking objective aligned with recommendation metrics)\n",
    "\n",
    "Evaluated with leave-one-out (LOO) candidate-based ranking:\n",
    "\n",
    "Hit@10/20/50 and NDCG@10/20/50\n",
    "\n",
    "candidates: C=1000 (main) and C=2000 (stricter)\n",
    "\n",
    "### Key results\n",
    "\n",
    "Validation improved quickly and peaked early.\n",
    "\n",
    "Early stopping selected the best checkpoint at epoch 12:\n",
    "\n",
    "Val NDCG@10 (C=1000, 10k users): 0.03377\n",
    "\n",
    "Final test performance (10k users):\n",
    "\n",
    "TEST (C=1000): Hit@10 = 0.0672, NDCG@10 = 0.03335\n",
    "\n",
    "TEST (C=2000): Hit@10 = 0.0412, NDCG@10 = 0.02090\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "TransformerConv provides a clear ranking signal and outperforms simpler sampling baselines (e.g., GraphSAGE) in this setup.\n",
    "\n",
    "However, it underperforms the GAT + BPR model trained under the same protocol, suggesting that attention in GAT is more effective here (or that TransformerConv needs different tuning / training fidelity).\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Candidate-based evaluation (not full-ranking over all items).\n",
    "\n",
    "Training uses a scalability workaround: some sampled positives/negatives may fall outside sampled subgraphs and fall back to raw embeddings.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "TransformerConv + BPR + neighbor sampling is a viable ranking model, but GAT remains the strongest architecture among the tested sampling-based GNNs under this evaluation protocol."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - GNN (clean)",
   "language": "python",
   "name": "gnn_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
