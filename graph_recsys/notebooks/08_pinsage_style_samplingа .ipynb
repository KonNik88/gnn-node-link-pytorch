{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb9d88de-1fba-45bb-9276-014399c84296",
   "metadata": {},
   "source": [
    "# PinSAGE-style Sampling for Ranking (Goodbooks-10k, Graph3)\n",
    "\n",
    "In this notebook we implement a PinSAGE-style recommendation training loop:\n",
    "\n",
    "random-walk based neighbor sampling on the bipartite user–item graph,\n",
    "\n",
    "mini-batch training with subgraphs built from sampled neighborhoods,\n",
    "\n",
    "BPR loss aligned with ranking metrics.\n",
    "\n",
    "## Why PinSAGE-style?\n",
    "\n",
    "Previous models used uniform k-hop neighbor sampling (NeighborLoader). PinSAGE introduces a more recommender-centric sampling strategy:\n",
    "\n",
    "sample neighborhoods using random walks (captures co-visitation / collaborative signals),\n",
    "\n",
    "optionally apply importance weighting (in full PinSAGE),\n",
    "\n",
    "train a GNN with a ranking loss.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Graph: user–book bipartite (train interactions only).\n",
    "\n",
    "Sampling: random walks from seed users/items to generate a “relevant neighborhood pool”.\n",
    "\n",
    "Model: GraphSAGE (PinSAGE typically uses SAGE-like aggregators) trained with BPR.\n",
    "\n",
    "Evaluation: LOO candidate-based ranking (C=1000 / C=2000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af41db6b-c6f1-428b-ac3c-c29bca6fb8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n",
      "BUNDLE_DIR: D:\\ML\\GNN\\graph_recsys\\artifacts\\v2_proper\\graph3_bundle\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 1: Imports + device + paths\n",
    "# ============================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "PROJECT_ROOT = Path(r\"D:/ML/GNN/graph_recsys\")\n",
    "ARTIFACTS = PROJECT_ROOT / \"artifacts\" / \"v2_proper\"\n",
    "BUNDLE_DIR = ARTIFACTS / \"graph3_bundle\"\n",
    "\n",
    "print(\"BUNDLE_DIR:\", BUNDLE_DIR)\n",
    "assert BUNDLE_DIR.exists(), f\"Missing bundle: {BUNDLE_DIR}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b17d490f-8f26-4767-ab3a-342ad25d039d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/val/test: (4926384, 2) (53398, 2) (53398, 2)\n",
      "U, B: 53398 9999\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 2: Load LOO splits\n",
    "# ============================\n",
    "\n",
    "z = np.load(BUNDLE_DIR / \"splits_ui.npz\", allow_pickle=True)\n",
    "\n",
    "train_ui = z[\"train_ui\"].astype(np.int64)\n",
    "val_ui   = z[\"val_ui\"].astype(np.int64)\n",
    "test_ui  = z[\"test_ui\"].astype(np.int64)\n",
    "\n",
    "U = int(z[\"U\"])\n",
    "B = int(z[\"B\"])\n",
    "\n",
    "print(\"train/val/test:\", train_ui.shape, val_ui.shape, test_ui.shape)\n",
    "print(\"U, B:\", U, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "556b3274-266b-4c6b-b0b0-dc2b5df0421d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_pos users: 53398\n",
      "[val] leaks: 0 / 53398\n",
      "[test] leaks: 0 / 53398\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 3: train_pos + gt + leak check\n",
    "# ============================\n",
    "\n",
    "train_pos = defaultdict(set)\n",
    "for u, i in train_ui:\n",
    "    train_pos[int(u)].add(int(i))\n",
    "\n",
    "val_gt  = {int(u): int(i) for u, i in val_ui}\n",
    "test_gt = {int(u): int(i) for u, i in test_ui}\n",
    "\n",
    "leaks_val = sum(1 for u, i in val_gt.items() if i in train_pos[u])\n",
    "leaks_test = sum(1 for u, i in test_gt.items() if i in train_pos[u])\n",
    "\n",
    "print(\"train_pos users:\", len(train_pos))\n",
    "print(\"[val] leaks:\", leaks_val, \"/\", len(val_gt))\n",
    "print(\"[test] leaks:\", leaks_test, \"/\", len(test_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42136bba-e26b-4ee3-b260-d943ea1ecc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user deg min/mean/max: 3 92.25783737218623 197\n",
      "item deg min/mean/max: 4 492.6876687668767 19452\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 4: Build adjacency lists for fast random walks\n",
    "# Notes:\n",
    "# - We store user->items and item->users as numpy arrays for fast sampling.\n",
    "# ============================\n",
    "\n",
    "user2items = [None] * U\n",
    "item2users = [None] * B\n",
    "\n",
    "tmp_u = [[] for _ in range(U)]\n",
    "tmp_i = [[] for _ in range(B)]\n",
    "\n",
    "for u, i in train_ui:\n",
    "    tmp_u[int(u)].append(int(i))\n",
    "    tmp_i[int(i)].append(int(u))\n",
    "\n",
    "for u in range(U):\n",
    "    user2items[u] = np.asarray(tmp_u[u], dtype=np.int64)\n",
    "for i in range(B):\n",
    "    item2users[i] = np.asarray(tmp_i[i], dtype=np.int64)\n",
    "\n",
    "deg_u = np.array([len(x) for x in user2items], dtype=np.int32)\n",
    "deg_i = np.array([len(x) for x in item2users], dtype=np.int32)\n",
    "\n",
    "print(\"user deg min/mean/max:\", deg_u.min(), deg_u.mean(), deg_u.max())\n",
    "print(\"item deg min/mean/max:\", deg_i.min(), deg_i.mean(), deg_i.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da4eb6c7-a2e7-4131-ad7b-0e020e67477e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding_dim': 64,\n",
       " 'num_layers': 2,\n",
       " 'dropout': 0.1,\n",
       " 'lr': 0.001,\n",
       " 'weight_decay': 1e-06,\n",
       " 'epochs': 30,\n",
       " 'batch_size_users': 1024,\n",
       " 'num_walks': 10,\n",
       " 'walk_len': 4,\n",
       " 'items_per_user': 80,\n",
       " 'bpr_reg': 1e-06,\n",
       " 'seed': 42,\n",
       " 'patience': 7,\n",
       " 'min_delta': 0.0001}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 5: PinSAGE-style sampler via random walks\n",
    "# Goal:\n",
    "# - For each seed user, run multiple short random walks on the bipartite graph\n",
    "# - Collect visited items as a relevance-biased neighborhood pool\n",
    "# ============================\n",
    "\n",
    "CFG = {\n",
    "    \"embedding_dim\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.1,\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"epochs\": 30,\n",
    "    \"batch_size_users\": 1024,\n",
    "    # PinSAGE-style sampling params:\n",
    "    \"num_walks\": 10,\n",
    "    \"walk_len\": 4,          # even length: user->item->user->item...\n",
    "    \"items_per_user\": 80,   # cap visited item pool per seed user\n",
    "    # BPR:\n",
    "    \"bpr_reg\": 1e-6,\n",
    "    # Eval:\n",
    "    \"seed\": 42,\n",
    "    \"patience\": 7,\n",
    "    \"min_delta\": 1e-4,\n",
    "}\n",
    "CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98c2e5d0-9872-4abe-9672-b399fe0582ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Cell 5b: Random-walk based item pool for a batch of users\n",
    "# ============================\n",
    "\n",
    "SEED = CFG[\"seed\"]\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "def sample_item_pool_for_users(users_np: np.ndarray,\n",
    "                               num_walks: int,\n",
    "                               walk_len: int,\n",
    "                               items_cap: int):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      pools: list of np.array item_ids per user (unique, capped)\n",
    "    \"\"\"\n",
    "    pools = []\n",
    "    for u in users_np:\n",
    "        u = int(u)\n",
    "        visited = []\n",
    "\n",
    "        for _ in range(num_walks):\n",
    "            cur_u = u\n",
    "            for step in range(walk_len):\n",
    "                # user -> item\n",
    "                items = user2items[cur_u]\n",
    "                if items.size == 0:\n",
    "                    break\n",
    "                it = int(items[rng.integers(0, items.size)])\n",
    "                visited.append(it)\n",
    "\n",
    "                # item -> user\n",
    "                users = item2users[it]\n",
    "                if users.size == 0:\n",
    "                    break\n",
    "                cur_u = int(users[rng.integers(0, users.size)])\n",
    "\n",
    "        if len(visited) == 0:\n",
    "            pools.append(np.empty((0,), dtype=np.int64))\n",
    "            continue\n",
    "\n",
    "        uniq = np.unique(np.asarray(visited, dtype=np.int64))\n",
    "        if uniq.size > items_cap:\n",
    "            uniq = rng.choice(uniq, size=items_cap, replace=False)\n",
    "        pools.append(uniq)\n",
    "\n",
    "    return pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70a9182d-dab3-4a15-8d99-dab194d03592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Cell 6: Build an induced subgraph for a batch\n",
    "# Nodes in batch-graph:\n",
    "# - seed users\n",
    "# - pooled items from random walks\n",
    "# Edges:\n",
    "# - all train edges between these users and these items (undirected)\n",
    "# ============================\n",
    "\n",
    "def build_batch_subgraph(seed_users: np.ndarray, item_pools):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      n_id_global: torch.LongTensor of global node ids (users 0..U-1, items U..U+B-1)\n",
    "      edge_index_local: torch.LongTensor [2, E] with local indices\n",
    "      local_index: dict-like mapping global_id -> local_id (implemented via tensor map)\n",
    "      seed_users_local: torch.LongTensor local ids of seed users\n",
    "    \"\"\"\n",
    "    # collect global ids\n",
    "    seed_users = seed_users.astype(np.int64)\n",
    "    items = np.concatenate(item_pools) if len(item_pools) else np.empty((0,), dtype=np.int64)\n",
    "    items = np.unique(items)\n",
    "\n",
    "    # global node ids: users + items(offset by U)\n",
    "    global_users = seed_users\n",
    "    global_items = items + U\n",
    "\n",
    "    n_id = np.concatenate([global_users, global_items]).astype(np.int64)\n",
    "    n_id_t = torch.from_numpy(n_id).long()\n",
    "\n",
    "    # build mapping global->local via tensor map (size = num_nodes_ui)\n",
    "    # (note: num_nodes_ui = U+B)\n",
    "    idx_map = torch.full((U + B,), -1, dtype=torch.long)\n",
    "    idx_map[n_id_t] = torch.arange(n_id_t.numel(), dtype=torch.long)\n",
    "\n",
    "    # build edges: for each seed user, connect to its train items that are in selected item set\n",
    "    item_set = set(items.tolist())\n",
    "\n",
    "    rows = []\n",
    "    cols = []\n",
    "    for uu in global_users:\n",
    "        uu = int(uu)\n",
    "        ui = user2items[uu]\n",
    "        if ui.size == 0:\n",
    "            continue\n",
    "        mask = np.isin(ui, items)  # keep only pooled items\n",
    "        kept = ui[mask]\n",
    "        if kept.size == 0:\n",
    "            continue\n",
    "\n",
    "        u_loc = int(idx_map[uu])\n",
    "        for it in kept:\n",
    "            it_glob = int(it + U)\n",
    "            it_loc = int(idx_map[it_glob])\n",
    "            if it_loc >= 0:\n",
    "                rows.append(u_loc); cols.append(it_loc)\n",
    "                rows.append(it_loc); cols.append(u_loc)\n",
    "\n",
    "    if len(rows) == 0:\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "    else:\n",
    "        edge_index = torch.tensor([rows, cols], dtype=torch.long)\n",
    "\n",
    "    seed_users_local = idx_map[torch.from_numpy(global_users)].long()\n",
    "\n",
    "    return n_id_t, edge_index, idx_map, seed_users_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afd40f62-67b1-40fd-b4a7-86244cc6c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Cell 7: Pos/neg sampling (PinSAGE-style tweak)\n",
    "# Notes:\n",
    "# - positives: sample from train_pos\n",
    "# - negatives: sample from items NOT in train_pos\n",
    "# - optionally bias negatives to be \"harder\" by sampling from pool first\n",
    "# ============================\n",
    "\n",
    "train_pos_arr = {}\n",
    "for uu in range(U):\n",
    "    train_pos_arr[uu] = np.fromiter(train_pos[uu], dtype=np.int64)\n",
    "\n",
    "def sample_positives(users_np: np.ndarray):\n",
    "    pos = np.empty_like(users_np, dtype=np.int64)\n",
    "    for idx, uu in enumerate(users_np):\n",
    "        arr = train_pos_arr[int(uu)]\n",
    "        pos[idx] = int(arr[rng.integers(0, arr.size)])\n",
    "    return pos\n",
    "\n",
    "def sample_negatives(users_np: np.ndarray, item_pools=None, hard_pool_prob=0.5):\n",
    "    neg = np.empty_like(users_np, dtype=np.int64)\n",
    "    for idx, uu in enumerate(users_np):\n",
    "        seen = train_pos[int(uu)]\n",
    "\n",
    "        # with some prob, try sample from pool (harder negatives)\n",
    "        if item_pools is not None and item_pools[idx].size > 0 and rng.random() < hard_pool_prob:\n",
    "            pool = item_pools[idx]\n",
    "            for _ in range(10):\n",
    "                j = int(pool[rng.integers(0, pool.size)])\n",
    "                if j not in seen:\n",
    "                    neg[idx] = j\n",
    "                    break\n",
    "            else:\n",
    "                # fallback\n",
    "                while True:\n",
    "                    j = int(rng.integers(0, B))\n",
    "                    if j not in seen:\n",
    "                        neg[idx] = j\n",
    "                        break\n",
    "        else:\n",
    "            while True:\n",
    "                j = int(rng.integers(0, B))\n",
    "                if j not in seen:\n",
    "                    neg[idx] = j\n",
    "                    break\n",
    "\n",
    "    return neg\n",
    "\n",
    "def bpr_loss(u_emb, p_emb, n_emb, reg=0.0):\n",
    "    pos_scores = (u_emb * p_emb).sum(dim=-1)\n",
    "    neg_scores = (u_emb * n_emb).sum(dim=-1)\n",
    "    loss = -torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-8).mean()\n",
    "    if reg > 0:\n",
    "        loss = loss + reg * (u_emb.pow(2).mean() + p_emb.pow(2).mean() + n_emb.pow(2).mean())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "283c7847-91c0-4fd8-af3c-69b7986dcd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PinSAGERec(\n",
      "  (emb): Embedding(63397, 64)\n",
      "  (convs): ModuleList(\n",
      "    (0-1): 2 x SAGEConv(64, 64, aggr=mean)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 8: PinSAGE-style model (GraphSAGE)\n",
    "# Notes:\n",
    "# - PinSAGE typically uses SAGE-like aggregator; key is sampling strategy.\n",
    "# ============================\n",
    "\n",
    "class PinSAGERec(nn.Module):\n",
    "    def __init__(self, num_nodes: int, dim: int, num_layers: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_nodes, dim)\n",
    "        nn.init.normal_(self.emb.weight, std=0.1)\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.convs.append(SAGEConv(dim, dim, aggr=\"mean\"))\n",
    "\n",
    "        self.dropout = dropout\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, n_id, edge_index):\n",
    "        h = self.emb(n_id.to(DEVICE))\n",
    "        edge_index = edge_index.to(DEVICE)\n",
    "\n",
    "        for conv in self.convs:\n",
    "            h = conv(h, edge_index)\n",
    "            h = F.relu(h)\n",
    "            h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        return h\n",
    "\n",
    "model = PinSAGERec(num_nodes=U+B, dim=CFG[\"embedding_dim\"], num_layers=CFG[\"num_layers\"], dropout=CFG[\"dropout\"]).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e16da25-792a-4edd-9096-9f4529ef8694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Cell 9 (fully fixed): Train one epoch (PinSAGE-style) + skipped tracking + device-safe indexing\n",
    "# Returns:\n",
    "# - avg_loss: average BPR loss over processed batches\n",
    "# - steps: number of processed batches (with edges)\n",
    "# - skipped: number of skipped batches (no edges)\n",
    "# ============================\n",
    "\n",
    "train_users_all = np.arange(U, dtype=np.int64)\n",
    "\n",
    "def train_one_epoch():\n",
    "    model.train()\n",
    "\n",
    "    rng.shuffle(train_users_all)\n",
    "    bs = CFG[\"batch_size_users\"]\n",
    "\n",
    "    total_loss = 0.0\n",
    "    steps = 0\n",
    "    skipped = 0\n",
    "\n",
    "    for start in tqdm(range(0, U, bs), desc=\"train\"):\n",
    "        users_np = train_users_all[start:start + bs]\n",
    "        if users_np.size == 0:\n",
    "            continue\n",
    "\n",
    "        # 1) sample random-walk item pools\n",
    "        pools = sample_item_pool_for_users(\n",
    "            users_np,\n",
    "            num_walks=CFG[\"num_walks\"],\n",
    "            walk_len=CFG[\"walk_len\"],\n",
    "            items_cap=CFG[\"items_per_user\"]\n",
    "        )\n",
    "\n",
    "        # 2) build induced subgraph (users + pooled items)\n",
    "        n_id, edge_index, idx_map, seed_users_local = build_batch_subgraph(users_np, pools)\n",
    "\n",
    "        # If no edges, skip\n",
    "        if edge_index.numel() == 0:\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        # 3) sample positives / negatives (hard negatives from pool with prob=0.7)\n",
    "        pos_items = sample_positives(users_np)\n",
    "        neg_items = sample_negatives(users_np, item_pools=pools, hard_pool_prob=0.7)\n",
    "\n",
    "        # global node ids for items (shift by U)\n",
    "        pos_nodes = torch.from_numpy(pos_items).long() + U\n",
    "        neg_nodes = torch.from_numpy(neg_items).long() + U\n",
    "\n",
    "        # 4) forward on batch subgraph\n",
    "        # model moves n_id/edge_index to DEVICE internally\n",
    "        h = model(n_id, edge_index)\n",
    "\n",
    "        # 5) local indices:\n",
    "        # idx_map is created on CPU (in build_batch_subgraph), so index it with CPU tensors, then move to DEVICE\n",
    "        u_loc = seed_users_local.to(DEVICE)\n",
    "\n",
    "        p_loc = idx_map[pos_nodes.cpu()].to(DEVICE)\n",
    "        n_loc = idx_map[neg_nodes.cpu()].to(DEVICE)\n",
    "\n",
    "        u_emb = h[u_loc]\n",
    "\n",
    "        # 6) helper: fetch item embeddings from subgraph or fallback to raw embedding table\n",
    "        def get_item_emb(loc_idx, global_nodes):\n",
    "            \"\"\"\n",
    "            loc_idx: LongTensor on DEVICE (local indices in h, -1 means missing from subgraph)\n",
    "            global_nodes: LongTensor (global node ids), can be CPU\n",
    "            Returns: [N, dim] tensor on DEVICE\n",
    "            \"\"\"\n",
    "            global_nodes = global_nodes.to(DEVICE)   # move FIRST to avoid device-mismatch\n",
    "            loc_idx = loc_idx.to(DEVICE)\n",
    "\n",
    "            mask = loc_idx >= 0\n",
    "            out = torch.empty((global_nodes.size(0), CFG[\"embedding_dim\"]), device=DEVICE)\n",
    "\n",
    "            if mask.any():\n",
    "                out[mask] = h[loc_idx[mask]]\n",
    "            if (~mask).any():\n",
    "                out[~mask] = model.emb(global_nodes[~mask])\n",
    "\n",
    "            return out\n",
    "\n",
    "        p_emb = get_item_emb(p_loc, pos_nodes)\n",
    "        n_emb = get_item_emb(n_loc, neg_nodes)\n",
    "\n",
    "        # 7) BPR loss + step\n",
    "        loss = bpr_loss(u_emb, p_emb, n_emb, reg=CFG[\"bpr_reg\"])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss.detach().cpu())\n",
    "        steps += 1\n",
    "\n",
    "    avg_loss = total_loss / max(1, steps)\n",
    "    return avg_loss, steps, skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e5cb922-46d4-420c-9081-f804ee0c0e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f58c9ed60ba2420ab24db85ac2442d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke eval (C=200): {'Hit@10': 0.046, 'Hit@20': 0.096, 'Hit@50': 0.239, 'NDCG@10': 0.020917185507600185, 'NDCG@20': 0.033487712151199264, 'NDCG@50': 0.061197168968758715}\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 10: Candidate-based LOO evaluation (fast)\n",
    "# ============================\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_loo_sampled(model, gt_dict, users_subset, C=1000, Ks=(10, 20, 50), seed=42):\n",
    "    model.eval()\n",
    "    rng_local = np.random.default_rng(seed)\n",
    "\n",
    "    hits = {k: 0 for k in Ks}\n",
    "    ndcgs = {k: 0.0 for k in Ks}\n",
    "\n",
    "    emb = model.emb.weight.detach()\n",
    "\n",
    "    for u in tqdm(users_subset, desc=f\"eval(C={C})\"):\n",
    "        gt = int(gt_dict[int(u)])\n",
    "        seen = train_pos[int(u)]\n",
    "\n",
    "        negs = []\n",
    "        while len(negs) < C - 1:\n",
    "            j = int(rng_local.integers(0, B))\n",
    "            if (j not in seen) and (j != gt):\n",
    "                negs.append(j)\n",
    "\n",
    "        cand_items = np.array([gt] + negs, dtype=np.int64)\n",
    "        cand_nodes = torch.from_numpy(cand_items).long().to(DEVICE) + U\n",
    "\n",
    "        u_node = torch.tensor([int(u)], device=DEVICE, dtype=torch.long)\n",
    "        u_vec = emb[u_node]\n",
    "        i_vec = emb[cand_nodes]\n",
    "        scores = (u_vec * i_vec).sum(dim=-1)\n",
    "\n",
    "        rank = torch.argsort(scores, descending=True)\n",
    "        gt_pos = (rank == 0).nonzero(as_tuple=False).item()\n",
    "\n",
    "        for k in Ks:\n",
    "            if gt_pos < k:\n",
    "                hits[k] += 1\n",
    "                ndcgs[k] += 1.0 / math.log2(gt_pos + 2)\n",
    "\n",
    "    n = len(users_subset)\n",
    "    out = {f\"Hit@{k}\": hits[k] / n for k in Ks}\n",
    "    out.update({f\"NDCG@{k}\": ndcgs[k] / n for k in Ks})\n",
    "    return out\n",
    "\n",
    "subset_2k = np.random.default_rng(SEED).choice(np.arange(U), size=2000, replace=False)\n",
    "subset_10k = np.random.default_rng(SEED).choice(np.arange(U), size=10000, replace=False)\n",
    "\n",
    "print(\"Smoke eval (C=200):\", eval_loo_sampled(model, val_gt, subset_2k, C=200, Ks=(10,20,50), seed=SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65502879-572d-4b29-899c-2cfbcba78b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38717ef8694746d5a921075585cff653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25925d408a64346bf6bcc37f94814dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4accb557714baeb9eb3910027c3766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=01 loss=0.6826 | steps=53 skipped=0 | val(C=200) NDCG@10=0.02897 | val(C=1000) NDCG@10=0.006591\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e7468ac91844a8999f74439efc2775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7332d91564ad4474bfabcc7b83545acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02330ab49ddd418882e1057c7515b4b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=02 loss=0.6556 | steps=53 skipped=0 | val(C=200) NDCG@10=0.03807 | val(C=1000) NDCG@10=0.009969\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1411a35719e1436980599f76e9f61fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b547f2a1e44346b6840668079bf47edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98748b049db4676a9d8f69b2c96ba5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=03 loss=0.6289 | steps=53 skipped=0 | val(C=200) NDCG@10=0.04159 | val(C=1000) NDCG@10=0.013061\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88e5c5d00044e71bb2f26fea3e5e6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951e2f9e86e04f4e9b58dd2280049a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700b8fcd07214b93b0c0491dd978943d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=04 loss=0.6210 | steps=53 skipped=0 | val(C=200) NDCG@10=0.04511 | val(C=1000) NDCG@10=0.014836\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844b9ebedba848bca07c4216250b5139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eedccf3c9be4211a0e452e0d9fea0e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c8d59eb44d04f9b84c6edd5bf387bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=05 loss=0.6173 | steps=53 skipped=0 | val(C=200) NDCG@10=0.04933 | val(C=1000) NDCG@10=0.017421\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb84d6de7a87489c8db036e40bc72d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239415bc7f3a4060a22ccbae1858f881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5834100a0a634217b55bfe7bdf0d134d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=06 loss=0.6048 | steps=53 skipped=0 | val(C=200) NDCG@10=0.05647 | val(C=1000) NDCG@10=0.018977\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48fe92842f34052b3fa980b981b1547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b31874dba4440794145d783c7a1621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329a747ff3e742b1acfcefc191ab5c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=07 loss=0.5928 | steps=53 skipped=0 | val(C=200) NDCG@10=0.06266 | val(C=1000) NDCG@10=0.020172\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5312eef729cc424eacbc9689eccb4cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984cc2bb10004bec803eee90efb2c980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f5610222c84fd7b857589654ff71d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=08 loss=0.5866 | steps=53 skipped=0 | val(C=200) NDCG@10=0.06608 | val(C=1000) NDCG@10=0.022087\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18bb42fed7794783a2f42ce1c4a7b2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b91e873bd0f4479b43e92c904f7904b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe7f6df09464ab7a081a3fba661f815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=09 loss=0.5798 | steps=53 skipped=0 | val(C=200) NDCG@10=0.06768 | val(C=1000) NDCG@10=0.024593\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2dd9b2784d46eb9e615be3f374d74f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e190248220cc42369d4282d8424d7315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9745b825fc6d4450aa5fb6ad6417cd87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=10 loss=0.5739 | steps=53 skipped=0 | val(C=200) NDCG@10=0.07325 | val(C=1000) NDCG@10=0.025597\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb84aac4e59e47bf8fc8056a0ab184de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ea3abbbfeb4e56b414c75d5161d917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856ee75d4280477c8ad4bd5f67b3fcca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=11 loss=0.5690 | steps=53 skipped=0 | val(C=200) NDCG@10=0.07745 | val(C=1000) NDCG@10=0.027720\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f8ec9cb9a44fb7b274d94d27558b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f89868b27ea40f99e7847516576cf48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1dae61958884a1cbef826110d76bc9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=12 loss=0.5699 | steps=53 skipped=0 | val(C=200) NDCG@10=0.08102 | val(C=1000) NDCG@10=0.027904\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb244f51f4a54a219a27b946878eb979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c3c75d24984d00b7f41c0337b84987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05904785c9f47eea452b24fb647f94a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=13 loss=0.5695 | steps=53 skipped=0 | val(C=200) NDCG@10=0.08467 | val(C=1000) NDCG@10=0.029590\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65115c0314b84441929f0099b09a7c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb1d46038934a6ba62ae963ab6ce4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4810abe069a74870a4c20aafcb72a759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=14 loss=0.5639 | steps=53 skipped=0 | val(C=200) NDCG@10=0.08369 | val(C=1000) NDCG@10=0.030299\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00673321575f4f57bf623ba5cfc08800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c787f1bcc13f43a883c2e1eaa6931e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ddbd73107b64505be66747119aeeda1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=15 loss=0.5644 | steps=53 skipped=0 | val(C=200) NDCG@10=0.08568 | val(C=1000) NDCG@10=0.031389\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14cc974701f04c228e58894e595cdbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c48ccaf58546f48616f71e29805001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99abfaec87d4f9299d2eee575d2425b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=16 loss=0.5584 | steps=53 skipped=0 | val(C=200) NDCG@10=0.08674 | val(C=1000) NDCG@10=0.032316\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677760235d07409fa32c8cce6107ac00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b76e158c7f4ece9d81db57828be5c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3ccbb0f2734a29af834f4764fa1a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=17 loss=0.5580 | steps=53 skipped=0 | val(C=200) NDCG@10=0.08878 | val(C=1000) NDCG@10=0.032489\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1b6e2cbeea4d2e8a7cb74f367a20e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910f0ae9e4354cb592dd90549d374b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6a6ad29f8e4e4ebe1ab467319c8b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=18 loss=0.5564 | steps=53 skipped=0 | val(C=200) NDCG@10=0.09314 | val(C=1000) NDCG@10=0.033094\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e68ff9f741c4459a28dbeb5d741286b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d877f566d5c436187225948cce99fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a4f8febdbb4e41949d66192dec0d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=19 loss=0.5472 | steps=53 skipped=0 | val(C=200) NDCG@10=0.09930 | val(C=1000) NDCG@10=0.034617\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49bae0aa7c1949499312f9c277a77961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c76f4da236492783fa29ebd5b4ea92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0265638f24d54fe6a6998592ed4dee5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=20 loss=0.5488 | steps=53 skipped=0 | val(C=200) NDCG@10=0.09938 | val(C=1000) NDCG@10=0.035726\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe65700e0914925812984431d3a746c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd92fce527354807a70ff224e1310e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded99ead49884584b4dcd4a660822153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=21 loss=0.5402 | steps=53 skipped=0 | val(C=200) NDCG@10=0.09999 | val(C=1000) NDCG@10=0.036455\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6110c7bce40f4e76841e1419a1a34d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a351cc71ec4596aabb02edcafdd0af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4046e9d61d4612ace6afdb80c1a5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=22 loss=0.5387 | steps=53 skipped=0 | val(C=200) NDCG@10=0.10026 | val(C=1000) NDCG@10=0.036221\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7268d35894224d658091e82ad72bd610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8430992730c941d686dc954eb747c70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aaff2b5c94045188edf468a33031dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=23 loss=0.5363 | steps=53 skipped=0 | val(C=200) NDCG@10=0.09938 | val(C=1000) NDCG@10=0.036905\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82212fdf423040e4846b5f53952c8148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03e5318935943ae87d554d63d3413cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae3827de96845bd9550eb500c1a9672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=24 loss=0.5294 | steps=53 skipped=0 | val(C=200) NDCG@10=0.10212 | val(C=1000) NDCG@10=0.036219\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2447e6cfe741dc9165058de257af69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a28996b06d94f23999ea7770bd70d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4510893c37934e4e8ec76bb40c3f074d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=25 loss=0.5189 | steps=53 skipped=0 | val(C=200) NDCG@10=0.10406 | val(C=1000) NDCG@10=0.036457\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc34de3524b248ed8c06b97be8c2b2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05c458f218b4248bc3d3ea5aad1ec4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f447220e45c4ccba8bbb41ace583e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=26 loss=0.5171 | steps=53 skipped=0 | val(C=200) NDCG@10=0.10892 | val(C=1000) NDCG@10=0.036697\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8fe70db56e942779cb9a1dfd10a7c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13177e0d70e6408da074a8c721d701ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7b18de31fd42b099d269323925ff70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=27 loss=0.5038 | steps=53 skipped=0 | val(C=200) NDCG@10=0.10929 | val(C=1000) NDCG@10=0.037098\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6f6c3746d14dce984e8e0b26519146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac869f8b8ba5488a8a55c010c7e2204c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64fad1f9bdef41bb857512c0cba8d008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=28 loss=0.5057 | steps=53 skipped=0 | val(C=200) NDCG@10=0.11308 | val(C=1000) NDCG@10=0.037405\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd65b917cdf144e293043b32ff498694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b884927cebbf4d41a229396dbc120aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a0cc7f7f1e94a7c985f2fde96ddae90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=29 loss=0.5001 | steps=53 skipped=0 | val(C=200) NDCG@10=0.11476 | val(C=1000) NDCG@10=0.037505\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65105d9602e945db9230dc1c5cfeb17b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e873771f3441e380765602565302d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=200):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f0916f9058426895fdd0445cb45657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=30 loss=0.4980 | steps=53 skipped=0 | val(C=200) NDCG@10=0.11508 | val(C=1000) NDCG@10=0.038234\n",
      "Loaded best checkpoint: 30 best val NDCG@10: 0.03823351739798701\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 11 (fixed): Train loop + early stopping + steps/skipped logging\n",
    "# Metric for early stopping: val NDCG@10 @ (C=1000, 10k users)\n",
    "# ============================\n",
    "\n",
    "@dataclass\n",
    "class EarlyStopper:\n",
    "    patience: int = 7\n",
    "    min_delta: float = 1e-4\n",
    "    best: float = -1e9\n",
    "    best_epoch: int = -1\n",
    "    bad_count: int = 0\n",
    "    best_state: dict = None\n",
    "\n",
    "    def step(self, metric_value: float, model: torch.nn.Module, epoch: int) -> bool:\n",
    "        improved = metric_value > (self.best + self.min_delta)\n",
    "        if improved:\n",
    "            self.best = metric_value\n",
    "            self.best_epoch = epoch\n",
    "            self.bad_count = 0\n",
    "            self.best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            self.bad_count += 1\n",
    "        return self.bad_count >= self.patience\n",
    "\n",
    "    def load_best(self, model: torch.nn.Module, device=DEVICE):\n",
    "        model.load_state_dict({k: v.to(device) for k, v in self.best_state.items()})\n",
    "\n",
    "\n",
    "EARLY = EarlyStopper(patience=CFG[\"patience\"], min_delta=CFG[\"min_delta\"])\n",
    "\n",
    "history = []\n",
    "for ep in range(1, CFG[\"epochs\"] + 1):\n",
    "    # train_one_epoch now returns (avg_loss, steps, skipped)\n",
    "    avg_loss, steps, skipped = train_one_epoch()\n",
    "\n",
    "    m200 = eval_loo_sampled(model, val_gt, subset_2k, C=200, Ks=(10,20,50), seed=SEED)\n",
    "    m1000 = eval_loo_sampled(model, val_gt, subset_10k, C=1000, Ks=(10,20,50), seed=SEED)\n",
    "    val_ndcg10 = float(m1000[\"NDCG@10\"])\n",
    "\n",
    "    history.append({\n",
    "        \"epoch\": ep,\n",
    "        \"loss\": avg_loss,\n",
    "        \"steps\": steps,\n",
    "        \"skipped\": skipped,\n",
    "        **{f\"val200_{k}\": float(v) for k, v in m200.items()},\n",
    "        **{f\"val1000_{k}\": float(v) for k, v in m1000.items()},\n",
    "    })\n",
    "\n",
    "    print(\n",
    "        f\"epoch={ep:02d} loss={avg_loss:.4f} | steps={steps} skipped={skipped} | \"\n",
    "        f\"val(C=200) NDCG@10={m200['NDCG@10']:.5f} | \"\n",
    "        f\"val(C=1000) NDCG@10={val_ndcg10:.6f}\"\n",
    "    )\n",
    "\n",
    "    if EARLY.step(val_ndcg10, model, ep):\n",
    "        print(f\"Early stopping at epoch {ep}. Best epoch={EARLY.best_epoch} best NDCG@10={EARLY.best:.6f}\")\n",
    "        break\n",
    "\n",
    "EARLY.load_best(model, device=DEVICE)\n",
    "print(\"Loaded best checkpoint:\", EARLY.best_epoch, \"best val NDCG@10:\", EARLY.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6026aab6-f41a-4151-955e-edac87e83c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2726bf9e87f24efeacea470cc8b817da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=1000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST (C=1000, 10k users): {'Hit@10': 0.0761, 'Hit@20': 0.1164, 'Hit@50': 0.2019, 'NDCG@10': 0.041187646994723576, 'NDCG@20': 0.051263158758467424, 'NDCG@50': 0.06817057082797173}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e34104856f41ccb02a4fd166d4deda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(C=2000):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST (C=2000, 10k users): {'Hit@10': 0.0493, 'Hit@20': 0.0754, 'Hit@50': 0.1341, 'NDCG@10': 0.026857281486186428, 'NDCG@20': 0.033402968913480185, 'NDCG@50': 0.04495259872554541}\n",
      "Saved: D:\\ML\\GNN\\graph_recsys\\artifacts\\v2_proper\\ablation_runs\\pinsage_style_sampling\\history_pinsage_style_bpr.csv\n",
      "Saved: D:\\ML\\GNN\\graph_recsys\\artifacts\\v2_proper\\ablation_runs\\pinsage_style_sampling\\pinsage_style_best.pt\n",
      "Saved: D:\\ML\\GNN\\graph_recsys\\artifacts\\v2_proper\\ablation_runs\\pinsage_style_sampling\\run_meta.json\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 12: Final TEST eval + save artifacts\n",
    "# ============================\n",
    "\n",
    "test_subset_10k = np.random.default_rng(SEED + 123).choice(np.arange(U), size=10000, replace=False)\n",
    "\n",
    "test_m1000 = eval_loo_sampled(model, test_gt, test_subset_10k, C=1000, Ks=(10,20,50), seed=SEED + 123)\n",
    "print(\"TEST (C=1000, 10k users):\", test_m1000)\n",
    "\n",
    "test_m2000 = eval_loo_sampled(model, test_gt, test_subset_10k, C=2000, Ks=(10,20,50), seed=SEED + 123)\n",
    "print(\"TEST (C=2000, 10k users):\", test_m2000)\n",
    "\n",
    "hist_df = pd.DataFrame(history)\n",
    "out_dir = ARTIFACTS / \"ablation_runs\" / \"pinsage_style_sampling\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "hist_path = out_dir / \"history_pinsage_style_bpr.csv\"\n",
    "hist_df.to_csv(hist_path, index=False)\n",
    "\n",
    "meta = {\n",
    "    \"best_epoch\": EARLY.best_epoch,\n",
    "    \"best_val_ndcg10_C1000_10k\": float(EARLY.best),\n",
    "    \"config\": CFG,\n",
    "    \"bundle_dir\": str(BUNDLE_DIR),\n",
    "    \"test_C1000\": test_m1000,\n",
    "    \"test_C2000\": test_m2000,\n",
    "}\n",
    "with open(out_dir / \"run_meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "ckpt_path = out_dir / \"pinsage_style_best.pt\"\n",
    "torch.save({\"state_dict\": EARLY.best_state, \"meta\": meta}, ckpt_path)\n",
    "\n",
    "print(\"Saved:\", hist_path)\n",
    "print(\"Saved:\", ckpt_path)\n",
    "print(\"Saved:\", out_dir / \"run_meta.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3af756-953d-4e0b-ab81-81f64246b7ca",
   "metadata": {},
   "source": [
    "# Results & Conclusions (PinSAGE-style Sampling)\n",
    "\n",
    "## What we built\n",
    "In this notebook we implemented a **PinSAGE-style** training loop for recommendation on the Goodbooks-10k **Graph3** setup:\n",
    "- We use the **train-only user–item bipartite graph**.\n",
    "- For each mini-batch of seed users we generate **neighborhoods via random walks** (PinSAGE idea).\n",
    "- We build an **induced subgraph** from the visited items and train a **GraphSAGE** model on that subgraph.\n",
    "- Objective: **BPR loss** (ranking-aligned, consistent with Hit@K / NDCG@K evaluation).\n",
    "\n",
    "This differs from standard neighbor sampling because the neighborhood is **biased by random walks**, which tends to capture collaborative/co-visitation structure.\n",
    "\n",
    "## Training sanity checks\n",
    "- Induced subgraphs were valid: `skipped=0` across all epochs (no empty subgraphs).\n",
    "- Loss decreased steadily and validation ranking improved consistently.\n",
    "\n",
    "## Best checkpoint\n",
    "- Best epoch: **30**\n",
    "- Best validation (C=1000, 10k users): **NDCG@10 = 0.03823**\n",
    "\n",
    "## Final test metrics (10k users)\n",
    "**Candidate evaluation C=1000**\n",
    "- Hit@10 = **0.0761**\n",
    "- Hit@20 = **0.1164**\n",
    "- Hit@50 = **0.2019**\n",
    "- NDCG@10 = **0.04119**\n",
    "- NDCG@20 = **0.05126**\n",
    "- NDCG@50 = **0.06817**\n",
    "\n",
    "**Candidate evaluation C=2000**\n",
    "- Hit@10 = **0.0493**\n",
    "- Hit@20 = **0.0754**\n",
    "- Hit@50 = **0.1341**\n",
    "- NDCG@10 = **0.02686**\n",
    "- NDCG@20 = **0.03340**\n",
    "- NDCG@50 = **0.04495**\n",
    "\n",
    "## Key takeaway\n",
    "PinSAGE-style random-walk neighborhoods provide a strong training signal for ranking and produce **competitive results** compared to other sampling-based GNN recommenders.\n",
    "\n",
    "## Saved artifacts\n",
    "All artifacts are saved under:\n",
    "`artifacts/v2_proper/ablation_runs/pinsage_style_sampling/`\n",
    "- `history_pinsage_style_bpr.csv`\n",
    "- `pinsage_style_best.pt`\n",
    "- `run_meta.json`\n",
    "\n",
    "## Next step\n",
    "Proceed to **09_final_eval_and_report.ipynb**:\n",
    "- load all `run_meta.json` from `ablation_runs/`,\n",
    "- build a single comparison table for all models,\n",
    "- highlight the best model(s) and produce the final report."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - GNN (clean)",
   "language": "python",
   "name": "gnn_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
