{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fac9127a-0e26-4e35-bdaa-c48d9f42e4b5",
   "metadata": {},
   "source": [
    "## GraphSAGE (Neighbor Sampling) for Ranking on Graph3 (Goodbooks-10k)\n",
    "\n",
    "In this notebook we train a scalable GNN recommender on the Graph3 augmented graph for Goodbooks-10k.\n",
    "\n",
    "Graph3 contains multiple node/edge types:\n",
    "\n",
    "Nodes: users, books, tags, authors, language, year_bin\n",
    "\n",
    "### Edges:\n",
    "\n",
    "user–book (train only)\n",
    "\n",
    "book–tag (weighted: log1p(count))\n",
    "\n",
    "book–book similarity (TF-IDF cosine)\n",
    "\n",
    "book–author\n",
    "\n",
    "book–language\n",
    "\n",
    "book–year_bin\n",
    "\n",
    "### Why GraphSAGE here?\n",
    "\n",
    "Our previous R-GCN run showed a strong objective ↔ metric mismatch:\n",
    "\n",
    "trained with BCE + negative sampling (binary link prediction),\n",
    "\n",
    "evaluated with global ranking (Leave-One-Out Hit@K / NDCG@K),\n",
    "\n",
    "resulting metrics were near zero despite decreasing loss.\n",
    "\n",
    "### GraphSAGE is a better fit because:\n",
    "\n",
    "it supports mini-batch neighbor sampling (practical training on large graphs),\n",
    "\n",
    "we can optimize a ranking loss (BPR), aligned with the LOO ranking metrics.\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "We keep the same evaluation protocol as the LightGCN baseline:\n",
    "\n",
    "Hit@10/20/50\n",
    "\n",
    "NDCG@10/20/50\n",
    "using Leave-One-Out ground truth pairs.\n",
    "\n",
    "Artifacts / Inputs\n",
    "\n",
    "We load the frozen Graph3 bundle from:\n",
    "D:/ML/GNN/graph_recsys/artifacts/v2_proper/graph3_bundle/\n",
    "\n",
    "Bundle files:\n",
    "\n",
    "graph3_state.pt — graph tensors (edges / edge types / A_norm / offsets / vocab)\n",
    "\n",
    "splits_ui.npz — train / val / test LOO splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85436766-d439-43c5-9b35-96019b5327bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n",
      "BUNDLE_DIR: D:\\ML\\GNN\\graph_recsys\\artifacts\\v2_proper\\graph3_bundle\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 1: Imports + device + paths\n",
    "# Purpose:\n",
    "# - Define project paths\n",
    "# - Setup torch device\n",
    "# - Basic imports used throughout the notebook\n",
    "# ============================\n",
    "\n",
    "import copy\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "PROJECT_ROOT = Path(r\"D:/ML/GNN/graph_recsys\")\n",
    "ARTIFACTS = PROJECT_ROOT / \"artifacts\" / \"v2_proper\"\n",
    "BUNDLE_DIR = ARTIFACTS / \"graph3_bundle\"\n",
    "\n",
    "print(\"BUNDLE_DIR:\", BUNDLE_DIR)\n",
    "assert BUNDLE_DIR.exists(), f\"Missing bundle: {BUNDLE_DIR}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e49aec11-583a-45c7-b73f-fa35540727c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\555\\AppData\\Local\\Temp\\ipykernel_17260\\2351652110.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  g = torch.load(BUNDLE_DIR / \"graph3_state.pt\", map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: num_nodes=74285, U=53398, B=9999\n",
      "train/val/test: (4926384, 2) (53398, 2) (53398, 2)\n",
      "A_norm nnz: 11260518\n",
      "offsets: {'user_offset': 0, 'book_offset': 53398, 'tag_offset': 63397, 'author_offset': 68411, 'lang_offset': 74252, 'year_offset': 74278}\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 2: Load Graph3 bundle (graph tensors + LOO splits)\n",
    "# Purpose:\n",
    "# - Load saved graph state (sparse adjacency, edge types, offsets, etc.)\n",
    "# - Load train/val/test user-item splits (LOO protocol)\n",
    "# Notes:\n",
    "# - We keep everything on CPU for now; sampling will move mini-batches to GPU later.\n",
    "# ============================\n",
    "\n",
    "g = torch.load(BUNDLE_DIR / \"graph3_state.pt\", map_location=\"cpu\")\n",
    "z = np.load(BUNDLE_DIR / \"splits_ui.npz\", allow_pickle=True)\n",
    "\n",
    "train_ui = z[\"train_ui\"].astype(np.int64)\n",
    "val_ui   = z[\"val_ui\"].astype(np.int64)\n",
    "test_ui  = z[\"test_ui\"].astype(np.int64)\n",
    "\n",
    "# naming: U = n_users, B = n_books/items\n",
    "U = int(z[\"U\"])\n",
    "B = int(z[\"B\"])\n",
    "\n",
    "# Main sparse graph representation (COO)\n",
    "A_norm = g[\"A_norm\"].coalesce()   # sparse COO on CPU\n",
    "num_nodes = int(g[\"num_nodes\"])\n",
    "offsets = g[\"offsets\"]            # dict with node-type offsets in the global ID space\n",
    "\n",
    "print(f\"Loaded: num_nodes={num_nodes}, U={U}, B={B}\")\n",
    "print(\"train/val/test:\", train_ui.shape, val_ui.shape, test_ui.shape)\n",
    "print(\"A_norm nnz:\", int(A_norm._nnz()))\n",
    "print(\"offsets:\", offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7be5db8-4d6c-4e79-af66-fe336c2c7944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_pos users: 53398\n",
      "val_gt: 53398 test_gt: 53398\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 3: Build train positives + LOO ground truth (val/test)\n",
    "# Purpose:\n",
    "# - train_pos[u] = set(items) used to:\n",
    "#   1) filter already-seen items during ranking\n",
    "#   2) avoid sampling positives as negatives\n",
    "# - val_gt/test_gt: dict user -> held-out item (LOO)\n",
    "# ============================\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "train_pos = defaultdict(set)\n",
    "for u, i in train_ui:\n",
    "    train_pos[int(u)].add(int(i))\n",
    "\n",
    "val_gt  = {int(u): int(i) for u, i in val_ui}\n",
    "test_gt = {int(u): int(i) for u, i in test_ui}\n",
    "\n",
    "print(\"train_pos users:\", len(train_pos))\n",
    "print(\"val_gt:\", len(val_gt), \"test_gt:\", len(test_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21f8d175-55b2-49d7-b290-f5fe91e3118e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_index_ui: (2, 9852768) num_nodes_ui: 63397\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 4: Build bipartite user-book edge_index for training\n",
    "# Purpose:\n",
    "# - GraphSAGE with BPR is typically trained on the user-item interaction graph\n",
    "# - We build an undirected edge_index (u<->(i+U)) in global node ID space\n",
    "# Notes:\n",
    "# - items are shifted by +U so that users: [0..U-1], items: [U..U+B-1]\n",
    "# - This matches the convention used in LightGCN baseline\n",
    "# ============================\n",
    "\n",
    "u = torch.from_numpy(train_ui[:, 0]).long()\n",
    "i = torch.from_numpy(train_ui[:, 1]).long() + U\n",
    "\n",
    "row = torch.cat([u, i], dim=0)\n",
    "col = torch.cat([i, u], dim=0)\n",
    "\n",
    "edge_index_ui = torch.stack([row, col], dim=0)  # [2, 2*E]\n",
    "num_nodes_ui = U + B\n",
    "\n",
    "print(\"edge_index_ui:\", tuple(edge_index_ui.shape), \"num_nodes_ui:\", num_nodes_ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b530a384-abed-40a4-823c-e3f9dc9d05df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] leaks (gt in train_pos): 0 / 53398\n",
      "[test] leaks (gt in train_pos): 0 / 53398\n",
      "train interactions: 4926384\n",
      "avg train interactions per user: 92.25783737218623\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 5: Sanity checks\n",
    "# Purpose:\n",
    "# - Verify that val/test items are not present in train for the same user (LOO assumption)\n",
    "# - Basic stats for debugging\n",
    "# ============================\n",
    "\n",
    "def check_loo_splits(train_pos, gt_dict, name=\"val\"):\n",
    "    bad = 0\n",
    "    for u, gt_i in gt_dict.items():\n",
    "        if gt_i in train_pos.get(u, set()):\n",
    "            bad += 1\n",
    "    print(f\"[{name}] leaks (gt in train_pos): {bad} / {len(gt_dict)}\")\n",
    "\n",
    "check_loo_splits(train_pos, val_gt, \"val\")\n",
    "check_loo_splits(train_pos, test_gt, \"test\")\n",
    "\n",
    "# interaction density quick look\n",
    "num_interactions = train_ui.shape[0]\n",
    "print(\"train interactions:\", num_interactions)\n",
    "print(\"avg train interactions per user:\", num_interactions / max(1, U))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "483e6732-fd06-4203-a97d-9cab5f827288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding_dim': 64,\n",
       " 'num_layers': 2,\n",
       " 'dropout': 0.1,\n",
       " 'batch_size_users': 2048,\n",
       " 'neighbors': [15, 10],\n",
       " 'lr': 0.001,\n",
       " 'weight_decay': 1e-06,\n",
       " 'epochs': 10,\n",
       " 'bpr_reg': 1e-06,\n",
       " 'eval_every': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 6: Config + reproducibility\n",
    "# Purpose:\n",
    "# - Central place for hyperparameters for GraphSAGE+BPR\n",
    "# - Fix seeds for stable comparisons\n",
    "# ============================\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "CFG = {\n",
    "    \"embedding_dim\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.1,\n",
    "    \"batch_size_users\": 2048,      \n",
    "    \"neighbors\": [15, 10],         # neighbor sampling fanout per layer\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"epochs\": 10,\n",
    "    \"bpr_reg\": 1e-6,\n",
    "    \"eval_every\": 1,\n",
    "}\n",
    "CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cddad996-7576-4174-9dc4-c7813f3c9391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 104485], num_nodes=46092, n_id=[46092], e_id=[104485], num_sampled_nodes=[3], num_sampled_edges=[2], input_id=[2048], batch_size=2048)\n",
      "batch.num_nodes: 46092 batch.edge_index: torch.Size([2, 104485])\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 7: Build PyG Data + NeighborLoader\n",
    "# Purpose:\n",
    "# - Wrap edge_index in torch_geometric.data.Data\n",
    "# - Prepare a NeighborLoader that samples neighbors for a mini-batch of *seed nodes*\n",
    "# Notes:\n",
    "# - We'll train only on the bipartite user-item graph first.\n",
    "# - Seed nodes will be USERS; positives/negatives are sampled as ITEMS.\n",
    "# ============================\n",
    "\n",
    "data_ui = Data(edge_index=edge_index_ui, num_nodes=num_nodes_ui)\n",
    "\n",
    "# Train loader samples neighborhoods for a set of seed nodes.\n",
    "# We'll pass user node ids (0..U-1) as input_nodes.\n",
    "train_user_nodes = torch.arange(U, dtype=torch.long)\n",
    "\n",
    "train_loader = NeighborLoader(\n",
    "    data_ui,\n",
    "    input_nodes=train_user_nodes,\n",
    "    num_neighbors=CFG[\"neighbors\"],   # e.g. [15, 10]\n",
    "    batch_size=CFG[\"batch_size_users\"],\n",
    "    shuffle=True,\n",
    "    num_workers=0,                    # set >0 later if you want\n",
    "    persistent_workers=False\n",
    ")\n",
    "\n",
    "# quick smoke: one batch\n",
    "batch = next(iter(train_loader))\n",
    "print(batch)\n",
    "print(\"batch.num_nodes:\", batch.num_nodes, \"batch.edge_index:\", batch.edge_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "778e5b86-bd03-4d3a-b4db-3d6020b7e8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphSAGERec(\n",
      "  (emb): Embedding(63397, 64)\n",
      "  (convs): ModuleList(\n",
      "    (0-1): 2 x SAGEConv(64, 64, aggr=mean)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 8: GraphSAGE model\n",
    "# Purpose:\n",
    "# - Node embeddings table for all nodes (users + items)\n",
    "# - GraphSAGE layers produce context-aware embeddings\n",
    "# ============================\n",
    "\n",
    "class GraphSAGERec(nn.Module):\n",
    "    def __init__(self, num_nodes: int, dim: int = 64, num_layers: int = 2, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.dim = dim\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.emb = nn.Embedding(num_nodes, dim)\n",
    "        nn.init.normal_(self.emb.weight, std=0.1)\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.convs.append(SAGEConv(dim, dim))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x is node ids (LongTensor)\n",
    "        h = self.emb(x)\n",
    "        for conv in self.convs:\n",
    "            h = conv(h, edge_index)\n",
    "            h = F.relu(h)\n",
    "            h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        return h\n",
    "\n",
    "model = GraphSAGERec(\n",
    "    num_nodes=num_nodes_ui,\n",
    "    dim=CFG[\"embedding_dim\"],\n",
    "    num_layers=CFG[\"num_layers\"],\n",
    "    dropout=CFG[\"dropout\"],\n",
    ").to(DEVICE)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "419bbb10-ffa0-49f9-b17e-f905c0858df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Cell 9: BPR helpers\n",
    "# Purpose:\n",
    "# - Sample negatives for (user, positive_item) pairs\n",
    "# - Compute BPR loss from user/item embeddings\n",
    "# Notes:\n",
    "# - We must avoid sampling already-seen train positives as negatives.\n",
    "# ============================\n",
    "\n",
    "def sample_negatives(users_np: np.ndarray, num_items: int, train_pos, rng: np.random.Generator):\n",
    "    \"\"\"\n",
    "    For each user, sample one negative item not in train_pos[user].\n",
    "    Returns: neg_items (np.int64)\n",
    "    \"\"\"\n",
    "    neg = np.empty_like(users_np, dtype=np.int64)\n",
    "    for idx, u in enumerate(users_np):\n",
    "        seen = train_pos[int(u)]\n",
    "        while True:\n",
    "            j = int(rng.integers(0, num_items))\n",
    "            if j not in seen:\n",
    "                neg[idx] = j\n",
    "                break\n",
    "    return neg\n",
    "\n",
    "def bpr_loss(u_emb, p_emb, n_emb, reg=0.0):\n",
    "    \"\"\"\n",
    "    BPR loss: -log sigma(u·p - u·n)\n",
    "    \"\"\"\n",
    "    pos_scores = (u_emb * p_emb).sum(dim=-1)\n",
    "    neg_scores = (u_emb * n_emb).sum(dim=-1)\n",
    "    loss = -torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-8).mean()\n",
    "    if reg > 0:\n",
    "        loss = loss + reg * (u_emb.pow(2).mean() + p_emb.pow(2).mean() + n_emb.pow(2).mean())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a57a5b1-2a2b-4b20-a5fc-832a291be303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49e7cf8cb1045e0b4dfcd74c3250fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg train loss: 0.5631215947645681\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 10: Training loop (smoke run)\n",
    "# Purpose:\n",
    "# - One epoch training with NeighborLoader + BPR\n",
    "# Strategy:\n",
    "# - For each batch of seed users, we sample ONE positive per user from train_pos\n",
    "# - Then sample one negative item per user\n",
    "# - Run GraphSAGE on the sampled subgraph and compute BPR on user/item embeddings\n",
    "# ============================\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    steps = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=\"train\"):\n",
    "        # batch contains a subgraph. batch.n_id maps local nodes -> global node ids.\n",
    "        batch = batch.to(DEVICE)\n",
    "        n_id = batch.n_id  # global node ids for nodes in this batch-subgraph\n",
    "\n",
    "        # Seed users are the first batch.batch_size nodes in input_nodes order\n",
    "        # In NeighborLoader, batch.input_id gives the seed node ids (global) of this batch.\n",
    "        seed_users = batch.input_id  # global user node ids\n",
    "        seed_users_np = seed_users.detach().cpu().numpy()\n",
    "\n",
    "        # sample 1 positive per user\n",
    "        pos_items = np.array([next(iter(train_pos[int(u)])) for u in seed_users_np], dtype=np.int64)\n",
    "\n",
    "        # sample 1 negative per user\n",
    "        neg_items = sample_negatives(seed_users_np, B, train_pos, rng)\n",
    "\n",
    "        # convert to global item node ids\n",
    "        pos_nodes = torch.from_numpy(pos_items).long().to(DEVICE) + U\n",
    "        neg_nodes = torch.from_numpy(neg_items).long().to(DEVICE) + U\n",
    "\n",
    "        # IMPORTANT: ensure sampled items exist in this batch subgraph\n",
    "        # If an item is not included by sampling, its embedding won't be computed in forward.\n",
    "        # Quick workaround (for now): compute embeddings directly from nn.Embedding for items not in batch.\n",
    "        # We'll do a robust fix later (force include nodes or use embedding table fallback).\n",
    "        # For now, we compute full node embeddings for the batch subgraph:\n",
    "        h = model(n_id, batch.edge_index)  # embeddings for nodes in n_id order\n",
    "\n",
    "        # map global ids -> local positions in n_id\n",
    "        # build dict on CPU? no, do vectorized mapping using an index array:\n",
    "        # create a tensor of size num_nodes_ui with -1; fill local indices for n_id\n",
    "        idx_map = torch.full((num_nodes_ui,), -1, device=DEVICE, dtype=torch.long)\n",
    "        idx_map[n_id] = torch.arange(n_id.size(0), device=DEVICE)\n",
    "\n",
    "        u_loc = idx_map[seed_users]\n",
    "        p_loc = idx_map[pos_nodes]\n",
    "        n_loc = idx_map[neg_nodes]\n",
    "\n",
    "        # fallback: if p_loc or n_loc == -1, take direct embedding (no message passing)\n",
    "        u_emb = h[u_loc]\n",
    "\n",
    "        def get_item_emb(loc_idx, global_nodes):\n",
    "            mask = loc_idx >= 0\n",
    "            out = torch.empty((global_nodes.size(0), CFG[\"embedding_dim\"]), device=DEVICE)\n",
    "            out[mask] = h[loc_idx[mask]]\n",
    "            out[~mask] = model.emb(global_nodes[~mask])  # fallback\n",
    "            return out\n",
    "\n",
    "        p_emb = get_item_emb(p_loc, pos_nodes)\n",
    "        n_emb = get_item_emb(n_loc, neg_nodes)\n",
    "\n",
    "        loss = bpr_loss(u_emb, p_emb, n_emb, reg=CFG[\"bpr_reg\"])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss.detach().cpu())\n",
    "        steps += 1\n",
    "\n",
    "    return total_loss / max(1, steps)\n",
    "\n",
    "avg_loss = train_one_epoch()\n",
    "print(\"avg train loss:\", avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b55218e6-9489-4252-976a-4994781c6907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min/mean/max train_pos size: 3 92.25783737218623 197\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 11: Prepare fast random positive sampling\n",
    "# Purpose:\n",
    "# - Convert train_pos sets -> arrays to sample positives uniformly\n",
    "# ============================\n",
    "\n",
    "train_pos_arr = {}\n",
    "train_pos_size = np.zeros(U, dtype=np.int32)\n",
    "\n",
    "for u in range(U):\n",
    "    items = np.fromiter(train_pos[u], dtype=np.int64)\n",
    "    train_pos_arr[u] = items\n",
    "    train_pos_size[u] = items.size\n",
    "\n",
    "print(\"min/mean/max train_pos size:\", train_pos_size.min(), train_pos_size.mean(), train_pos_size.max())\n",
    "\n",
    "def sample_positives(users_np: np.ndarray, rng: np.random.Generator):\n",
    "    pos = np.empty_like(users_np, dtype=np.int64)\n",
    "    for idx, u in enumerate(users_np):\n",
    "        arr = train_pos_arr[int(u)]\n",
    "        pos[idx] = int(arr[rng.integers(0, arr.size)])\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58414388-34f5-45aa-8c89-afbd8303705c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0db87611ca343eeb50269156dc07041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Hit@10': 0.062,\n",
       " 'Hit@20': 0.109,\n",
       " 'Hit@50': 0.2575,\n",
       " 'NDCG@10': 0.029169205182808054,\n",
       " 'NDCG@20': 0.04087964021528664,\n",
       " 'NDCG@50': 0.0698140560566304}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 12: Fast LOO evaluation on sampled candidates (subset users)\n",
    "# Purpose:\n",
    "# - Quick check that BPR training improves ranking-like metrics\n",
    "# - Evaluate on candidate set: [1 gt + (C-1) negatives]\n",
    "# ============================\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_loo_sampled(model, gt_dict, users_subset, C=200, Ks=(10, 20, 50), seed=42):\n",
    "    \"\"\"\n",
    "    Candidate-based LOO eval:\n",
    "    For each user:\n",
    "      candidates = [gt_item] + sampled negatives (not in train_pos)\n",
    "    Score by dot(user_emb, item_emb) using raw embedding table (fast).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    hits = {k: 0 for k in Ks}\n",
    "    ndcgs = {k: 0.0 for k in Ks}\n",
    "\n",
    "    # We'll use base embeddings (no message passing) for speed in this quick eval.\n",
    "    # Later we can do a more faithful eval if needed.\n",
    "    emb = model.emb.weight.detach()  # [num_nodes_ui, dim], on DEVICE? model on DEVICE, so yes\n",
    "\n",
    "    for u in tqdm(users_subset, desc=\"eval(sampled)\"):\n",
    "        gt = int(gt_dict[int(u)])\n",
    "\n",
    "        # build candidates\n",
    "        negs = []\n",
    "        seen = train_pos[int(u)]\n",
    "        while len(negs) < C - 1:\n",
    "            j = int(rng.integers(0, B))\n",
    "            if (j not in seen) and (j != gt):\n",
    "                negs.append(j)\n",
    "\n",
    "        cand_items = np.array([gt] + negs, dtype=np.int64)\n",
    "        cand_nodes = torch.from_numpy(cand_items).long().to(DEVICE) + U\n",
    "\n",
    "        u_node = torch.tensor([int(u)], device=DEVICE, dtype=torch.long)\n",
    "        u_vec = emb[u_node]                         # [1, dim]\n",
    "        i_vec = emb[cand_nodes]                     # [C, dim]\n",
    "        scores = (u_vec * i_vec).sum(dim=-1)        # [C]\n",
    "\n",
    "        # rank descending\n",
    "        rank = torch.argsort(scores, descending=True)\n",
    "        # position of gt is where rank == 0 (since gt is at index 0 in cand_items)\n",
    "        gt_pos = (rank == 0).nonzero(as_tuple=False).item()  # 0-based\n",
    "\n",
    "        for k in Ks:\n",
    "            if gt_pos < k:\n",
    "                hits[k] += 1\n",
    "                ndcgs[k] += 1.0 / math.log2(gt_pos + 2)  # +2 because positions start at 1 in DCG formula\n",
    "\n",
    "    n = len(users_subset)\n",
    "    out = {f\"Hit@{k}\": hits[k] / n for k in Ks}\n",
    "    out.update({f\"NDCG@{k}\": ndcgs[k] / n for k in Ks})\n",
    "    return out\n",
    "\n",
    "# subset users for fast check\n",
    "subset = np.random.default_rng(SEED).choice(np.arange(U), size=2000, replace=False)\n",
    "metrics = eval_loo_sampled(model, val_gt, subset, C=200, Ks=(10,20,50), seed=SEED)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bef32054-1309-492d-b5d3-dfd28f530720",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0641d331273449f5bea76d31cc0f6775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5352083dbb443f5b99e12c6db78b1c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1 loss=0.5884 metrics={'Hit@10': 0.0625, 'Hit@20': 0.117, 'Hit@50': 0.2535, 'NDCG@10': 0.02991845318821254, 'NDCG@20': 0.04348749062164587, 'NDCG@50': 0.07003587265525034}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06753eeaf8174fd092f39b196b5dcc51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ff801c6377487481e57e1b6e21eb44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=2 loss=0.5073 metrics={'Hit@10': 0.07, 'Hit@20': 0.1245, 'Hit@50': 0.268, 'NDCG@10': 0.03478295679550602, 'NDCG@20': 0.04849160576371658, 'NDCG@50': 0.07627352996153926}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1c1efa763c4fc5901ca22d0eb17e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e61f96b7a0c4205b38232383556960e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=3 loss=0.4674 metrics={'Hit@10': 0.0815, 'Hit@20': 0.1325, 'Hit@50': 0.2705, 'NDCG@10': 0.0392722566159134, 'NDCG@20': 0.05202523012743539, 'NDCG@50': 0.07878876052453557}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8f17077f1b4bc29aa4230588f74411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64e0321f4fc42ff9f52889bff5eb56f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=4 loss=0.4606 metrics={'Hit@10': 0.084, 'Hit@20': 0.1335, 'Hit@50': 0.285, 'NDCG@10': 0.042342207566231846, 'NDCG@20': 0.05470456798833096, 'NDCG@50': 0.08413747918220779}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d85ab0673f4775bb48e16bca58a7ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16401779d80c4148b4cd895e8cd967fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=5 loss=0.4531 metrics={'Hit@10': 0.0865, 'Hit@20': 0.1415, 'Hit@50': 0.295, 'NDCG@10': 0.04413208817029047, 'NDCG@20': 0.057961201592542574, 'NDCG@50': 0.08777030653335029}\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 13: Train for a few epochs + fast eval\n",
    "# Purpose:\n",
    "# - See if metrics move in the right direction\n",
    "# ============================\n",
    "\n",
    "def train_one_epoch_v2():\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    steps = 0\n",
    "    for batch in tqdm(train_loader, desc=\"train\"):\n",
    "        batch = batch.to(DEVICE)\n",
    "        n_id = batch.n_id\n",
    "        seed_users = batch.input_id\n",
    "        seed_users_np = seed_users.detach().cpu().numpy()\n",
    "\n",
    "        pos_items = sample_positives(seed_users_np, rng)\n",
    "        neg_items = sample_negatives(seed_users_np, B, train_pos, rng)\n",
    "\n",
    "        pos_nodes = torch.from_numpy(pos_items).long().to(DEVICE) + U\n",
    "        neg_nodes = torch.from_numpy(neg_items).long().to(DEVICE) + U\n",
    "\n",
    "        h = model(n_id, batch.edge_index)\n",
    "\n",
    "        idx_map = torch.full((num_nodes_ui,), -1, device=DEVICE, dtype=torch.long)\n",
    "        idx_map[n_id] = torch.arange(n_id.size(0), device=DEVICE)\n",
    "\n",
    "        u_loc = idx_map[seed_users]\n",
    "        p_loc = idx_map[pos_nodes]\n",
    "        n_loc = idx_map[neg_nodes]\n",
    "\n",
    "        u_emb = h[u_loc]\n",
    "\n",
    "        def get_item_emb(loc_idx, global_nodes):\n",
    "            mask = loc_idx >= 0\n",
    "            out = torch.empty((global_nodes.size(0), CFG[\"embedding_dim\"]), device=DEVICE)\n",
    "            out[mask] = h[loc_idx[mask]]\n",
    "            out[~mask] = model.emb(global_nodes[~mask])\n",
    "            return out\n",
    "\n",
    "        p_emb = get_item_emb(p_loc, pos_nodes)\n",
    "        n_emb = get_item_emb(n_loc, neg_nodes)\n",
    "\n",
    "        loss = bpr_loss(u_emb, p_emb, n_emb, reg=CFG[\"bpr_reg\"])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss.detach().cpu())\n",
    "        steps += 1\n",
    "\n",
    "    return total_loss / max(1, steps)\n",
    "\n",
    "EPOCHS = 5\n",
    "for ep in range(1, EPOCHS + 1):\n",
    "    avg_loss = train_one_epoch_v2()\n",
    "    m = eval_loo_sampled(model, val_gt, subset, C=200, Ks=(10,20,50), seed=SEED)\n",
    "    print(f\"epoch={ep} loss={avg_loss:.4f} metrics={m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79d7dc48-65ad-4977-86e0-a455828f9bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e758e3fcb67e476f827146e27541188a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823ccdd999644bd1b29401a6a6019333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4f0f88a7404cf8bad64b17523fcaa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1 loss=0.4459\n",
      "  eval C=200  (2k users):  {'Hit@10': 0.09, 'Hit@20': 0.145, 'Hit@50': 0.308, 'NDCG@10': 0.04630391165631217, 'NDCG@20': 0.06012681450828042, 'NDCG@50': 0.09173653350296644}\n",
      "  eval C=1000 (10k users): {'Hit@10': 0.0264, 'Hit@20': 0.0456, 'Hit@50': 0.0892, 'NDCG@10': 0.013610082739373195, 'NDCG@20': 0.01842730767125949, 'NDCG@50': 0.026915586022710103}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eea737f3e464138ba0cde3d7fb723ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a724f6bc7dd4773b8963cf0dcf6306d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257d9ca9909244669792761c260dfc0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=2 loss=0.4398\n",
      "  eval C=200  (2k users):  {'Hit@10': 0.095, 'Hit@20': 0.1515, 'Hit@50': 0.3105, 'NDCG@10': 0.049146213333516243, 'NDCG@20': 0.06331539809195257, 'NDCG@50': 0.09437044772852086}\n",
      "  eval C=1000 (10k users): {'Hit@10': 0.0276, 'Hit@20': 0.0477, 'Hit@50': 0.0915, 'NDCG@10': 0.014129746711627, 'NDCG@20': 0.019154261606535945, 'NDCG@50': 0.027713866980726243}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3d176b1ad34fb38a6d93234d5aa2fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6799b6a3f42b42259aa7d6ec6b839703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb52710ab363495aa4a7a80518166389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=3 loss=0.4374\n",
      "  eval C=200  (2k users):  {'Hit@10': 0.0995, 'Hit@20': 0.1605, 'Hit@50': 0.324, 'NDCG@10': 0.05029672998679614, 'NDCG@20': 0.06557543170751791, 'NDCG@50': 0.09749333114187213}\n",
      "  eval C=1000 (10k users): {'Hit@10': 0.0286, 'Hit@20': 0.0494, 'Hit@50': 0.0947, 'NDCG@10': 0.014593363020934964, 'NDCG@20': 0.01978401294028719, 'NDCG@50': 0.028645318968704443}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca5bbba23c60492fa7d9b042cfc5c792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1ebf670a094871925b9a89c8ad16ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de518cf84be945c1a06a66ac45be0c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=4 loss=0.4398\n",
      "  eval C=200  (2k users):  {'Hit@10': 0.108, 'Hit@20': 0.16, 'Hit@50': 0.326, 'NDCG@10': 0.05389124179687326, 'NDCG@20': 0.06690024800750159, 'NDCG@50': 0.09938436311400906}\n",
      "  eval C=1000 (10k users): {'Hit@10': 0.0306, 'Hit@20': 0.0498, 'Hit@50': 0.1002, 'NDCG@10': 0.015388048796209912, 'NDCG@20': 0.020197617784262753, 'NDCG@50': 0.030085525428997954}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c991d4c06c5f491a9d1da0bcc49d4b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4eebee828f451190da6dfabac39a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1f9d0a347a45e58cf5985c269a706a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=5 loss=0.4277\n",
      "  eval C=200  (2k users):  {'Hit@10': 0.1075, 'Hit@20': 0.1665, 'Hit@50': 0.33, 'NDCG@10': 0.055178454182531644, 'NDCG@20': 0.07008618294428924, 'NDCG@50': 0.1019793030013096}\n",
      "  eval C=1000 (10k users): {'Hit@10': 0.0311, 'Hit@20': 0.0525, 'Hit@50': 0.1041, 'NDCG@10': 0.015959581089605195, 'NDCG@20': 0.021329786600736856, 'NDCG@50': 0.03141121857691474}\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 14: Train for a few epochs + tougher sampled eval\n",
    "# ============================\n",
    "\n",
    "EPOCHS = 5\n",
    "subset_10k = np.random.default_rng(SEED).choice(np.arange(U), size=10000, replace=False)\n",
    "\n",
    "for ep in range(1, EPOCHS + 1):\n",
    "    avg_loss = train_one_epoch_v2()\n",
    "\n",
    "    m200  = eval_loo_sampled(model, val_gt, subset,      C=200,  Ks=(10,20,50), seed=SEED)\n",
    "    m1000 = eval_loo_sampled(model, val_gt, subset_10k,  C=1000, Ks=(10,20,50), seed=SEED)\n",
    "\n",
    "    print(f\"epoch={ep} loss={avg_loss:.4f}\")\n",
    "    print(\"  eval C=200  (2k users): \", m200)\n",
    "    print(\"  eval C=1000 (10k users):\", m1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f373bfc-507d-4076-badc-9f491ad87234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Cell 15: Early stopping + checkpoint helpers\n",
    "# ============================\n",
    "\n",
    "@dataclass\n",
    "class EarlyStopper:\n",
    "    patience: int = 5\n",
    "    min_delta: float = 1e-4\n",
    "    best: float = -1e9\n",
    "    best_epoch: int = -1\n",
    "    bad_count: int = 0\n",
    "    best_state: dict = None\n",
    "\n",
    "    def step(self, metric_value: float, model: torch.nn.Module, epoch: int) -> bool:\n",
    "        \"\"\"\n",
    "        Returns True if should stop.\n",
    "        \"\"\"\n",
    "        improved = metric_value > (self.best + self.min_delta)\n",
    "        if improved:\n",
    "            self.best = metric_value\n",
    "            self.best_epoch = epoch\n",
    "            self.bad_count = 0\n",
    "            # store best weights (GPU-safe)\n",
    "            self.best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            self.bad_count += 1\n",
    "        return self.bad_count >= self.patience\n",
    "\n",
    "    def load_best(self, model: torch.nn.Module, device=DEVICE):\n",
    "        assert self.best_state is not None, \"No best_state saved\"\n",
    "        model.load_state_dict({k: v.to(device) for k, v in self.best_state.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82bdad27-a131-41f9-b826-1659796cbe9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01030109ac564c33b86a9233579f4fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986900fa6aa54c659eb27a8e044c015f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bfe1ab5683e43d1a98af0bf6faf6b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=01 loss=0.4339 | val NDCG@10 (C=1000, 10k users) = 0.016822\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e57827a850c4306b0bc46fe0df3a59d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43848f2ed40047c6b617df81b0e90882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba5642eeb4784ad6b2e7fca3d21f1d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=02 loss=0.4268 | val NDCG@10 (C=1000, 10k users) = 0.017561\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4305f9818494afe9b3dab429814737d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b9400b2a7346dcaf46bb1acddb50b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9631487c61474630851b9365990ae39a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=03 loss=0.4281 | val NDCG@10 (C=1000, 10k users) = 0.018519\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc68cbafe2c404baaee0fa08215e1c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958d2e03bbdd45eab5401521449a43be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04abd26354da43e6a608eca994a49946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=04 loss=0.4271 | val NDCG@10 (C=1000, 10k users) = 0.019001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18bb10b09502424bb7342c1c116dd95c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e98d4ba4f8436c92b39409c820f3b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4fa9e58b214a24b6ce03bf140b2232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=05 loss=0.4226 | val NDCG@10 (C=1000, 10k users) = 0.019171\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1809af6d94bb43bea619108aa2d8d190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31750ff266641bbb1788b15ed7d27e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b10da5f51ec4ef687c4f58af181c33d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=06 loss=0.4145 | val NDCG@10 (C=1000, 10k users) = 0.019954\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a14776dd637d451ab453886865262e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f6fec8b3934a07853d4fe1e44ee99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93056ca6edac4021b78436131c4425db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=07 loss=0.4132 | val NDCG@10 (C=1000, 10k users) = 0.020055\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae07ac8f9f34d8ea609fb0ebdaa3c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "723388dfaafa46d19bfcb1fa670ffaf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2479e95fda3748d1a1d9047b6f1910bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=08 loss=0.4059 | val NDCG@10 (C=1000, 10k users) = 0.020539\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060bc5973cb94e6ca11958c0cdf1eb38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af70fbd73f964be0890f387a661e0b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61e8b1c76ae42d9bdca0f626cbb7e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=09 loss=0.4030 | val NDCG@10 (C=1000, 10k users) = 0.021259\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f28d14bc4b422e998d9647aa92976f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e818cf11ad4f8a93dcb59670cb2bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ef443289384d34b5e6ef7d5cca6c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=10 loss=0.4008 | val NDCG@10 (C=1000, 10k users) = 0.021671\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f71eff6fe124ee79877c7379a93ddd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319a9e04e62042c9be138aa74bc69312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd4e82892b9419bb63fefe9ebc0a313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=11 loss=0.3926 | val NDCG@10 (C=1000, 10k users) = 0.021925\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202f0cabeb8e4b7eba2484b3d717e4c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bdc54adcd734d82940fbee7fdba92b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9973621cff54d44bd2ff37db2490708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=12 loss=0.3909 | val NDCG@10 (C=1000, 10k users) = 0.021864\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93308f86065d433dbf4cff16338fa4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120b89b10dc8400190b4acd18a6ecbe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4625632227648deaaebc4dd5a8a0f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=13 loss=0.3920 | val NDCG@10 (C=1000, 10k users) = 0.022408\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca54ef6083854552a7893860d7338e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ddabf4ecc04af7b953889eeebe2fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce216c9b65834c9aa416dc5b0a086859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=14 loss=0.3913 | val NDCG@10 (C=1000, 10k users) = 0.022953\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b717542430041d081c5945e7d40fc8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96c0b41c0b44e7bb90daaba0ae1b062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d00d019a41d42e6910922b1c64f054e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=15 loss=0.3847 | val NDCG@10 (C=1000, 10k users) = 0.023623\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2fe1d88f20547a1b3285a0c44d9e67b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a1bf08ffdd409380c1bae210c182d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688e4ef423534cbb80b9dd5359139631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=16 loss=0.3820 | val NDCG@10 (C=1000, 10k users) = 0.023593\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89806af8a5f74a8db66c3e89c2a6ba90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2f30b6763f4d7f94c51e703597119f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b2de3c21f4427390a85c58d2d3b2c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=17 loss=0.3804 | val NDCG@10 (C=1000, 10k users) = 0.024029\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc2dac6f87d4ed1bf710c4c9054e65b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c677ff310c0492287f1f1622a58a005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e8528a4a154fe684613d254eb36376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=18 loss=0.3772 | val NDCG@10 (C=1000, 10k users) = 0.024243\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d60c081e3da2460d932496c2259d38f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86519b61118149b690fe07f6ed241b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4f334c8b424f95a89d86f699b205a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=19 loss=0.3701 | val NDCG@10 (C=1000, 10k users) = 0.024632\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33164f5ef794442b2c369fa17ef5a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47811200109f4e0dba486a7834c651ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ece1dce6e84b6c96825068f49fdeb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=20 loss=0.3730 | val NDCG@10 (C=1000, 10k users) = 0.024948\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33bf4d2535ea44eeace3c43478fba6e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e03aa59a424a7d9b539db4a1e5c915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a44df999f824f2a900745439bc638d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=21 loss=0.3746 | val NDCG@10 (C=1000, 10k users) = 0.025256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e075bb39eb034b55ba308baff91172d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed257ac0c4847659ad4c283b18a695d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6455a5c9bbda4b5885be9f90c900076e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=22 loss=0.3674 | val NDCG@10 (C=1000, 10k users) = 0.026053\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b42bcde1264b40a295b5ce7a1a71a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc740fd389e14bcf88a55f036dc2756a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9695b1aad5f94ec08228410c6dd92379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=23 loss=0.3602 | val NDCG@10 (C=1000, 10k users) = 0.026580\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee946af8ba684c86bee5d8f3c9546e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7081ab1c5aba402895a3f3857199852a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61bde6e813be479fb8e986d1cf28f2f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=24 loss=0.3615 | val NDCG@10 (C=1000, 10k users) = 0.026863\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6a8974548e47d1a133a4fee4547484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15bfff24f39f42a8b39c41329bc71d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da47d269a0d4fcdb9a3773893a924bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=25 loss=0.3594 | val NDCG@10 (C=1000, 10k users) = 0.026483\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e79dd500c9e4742844c42777b8a1701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32cf9b37ffbf4e8585edd2611d6ed457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e81ae3201d469eacdf617c18a7e6f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=26 loss=0.3688 | val NDCG@10 (C=1000, 10k users) = 0.026936\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d8c7ef929364b56865dfec2dfc6f08f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c5aea9052b40e5bbb519258bd2380b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bde0b01d18c4e8d8ba752f0d4dbdd78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=27 loss=0.3576 | val NDCG@10 (C=1000, 10k users) = 0.027151\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9d8810e9a3410ea2fe967b6b4b00a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274839fd939640c0af113e762abed312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0626ee6415d4405889cd797105d3dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=28 loss=0.3610 | val NDCG@10 (C=1000, 10k users) = 0.027448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f593a475f950480da2725e775a9a8cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d200a6837b48e19eb3bdb6c3edf663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099d9707bb0e4b4bb890277081822c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=29 loss=0.3589 | val NDCG@10 (C=1000, 10k users) = 0.027557\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f7b49d518a441bfb68cec9b403918c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b6d5b4a6364ef28b9c9c5fe945e760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6a8a4119d04daa9ba79b4494145e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=30 loss=0.3541 | val NDCG@10 (C=1000, 10k users) = 0.027834\n",
      "Loaded best checkpoint: 30 best val NDCG@10: 0.027834138642069708\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 16: Train up to 30 epochs with early stopping on val NDCG@10 (C=1000)\n",
    "# ============================\n",
    "\n",
    "CFG[\"epochs\"] = 30\n",
    "EARLY = EarlyStopper(patience=5, min_delta=1e-4)\n",
    "\n",
    "# фиксируем user subsets, чтобы сравнение по эпохам было честным\n",
    "subset_2k = subset  \n",
    "subset_10k = subset_10k  \n",
    "\n",
    "history = []\n",
    "\n",
    "for ep in range(1, CFG[\"epochs\"] + 1):\n",
    "    avg_loss = train_one_epoch_v2()\n",
    "\n",
    "    # быстрый контроль (2k, C=200)\n",
    "    m200 = eval_loo_sampled(model, val_gt, subset_2k, C=200, Ks=(10,20,50), seed=SEED)\n",
    "\n",
    "    # основной сигнал для ES (10k, C=1000)\n",
    "    m1000 = eval_loo_sampled(model, val_gt, subset_10k, C=1000, Ks=(10,20,50), seed=SEED)\n",
    "    val_ndcg10 = float(m1000[\"NDCG@10\"])\n",
    "\n",
    "    row = {\n",
    "        \"epoch\": ep,\n",
    "        \"loss\": avg_loss,\n",
    "        **{f\"val200_{k}\": v for k, v in m200.items()},\n",
    "        **{f\"val1000_{k}\": v for k, v in m1000.items()},\n",
    "    }\n",
    "    history.append(row)\n",
    "\n",
    "    print(f\"epoch={ep:02d} loss={avg_loss:.4f} | val NDCG@10 (C=1000, 10k users) = {val_ndcg10:.6f}\")\n",
    "\n",
    "    if EARLY.step(val_ndcg10, model, ep):\n",
    "        print(f\"Early stopping at epoch {ep}. Best epoch={EARLY.best_epoch} best NDCG@10={EARLY.best:.6f}\")\n",
    "        break\n",
    "\n",
    "# load best model weights\n",
    "EARLY.load_best(model, device=DEVICE)\n",
    "print(\"Loaded best checkpoint:\", EARLY.best_epoch, \"best val NDCG@10:\", EARLY.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4178755-15de-4ea2-a8f3-4e963e0b8069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4efa426d4e63410bbc05e4c8a3caa978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST metrics (C=1000, 10k users): {'Hit@10': 0.0577, 'Hit@20': 0.0922, 'Hit@50': 0.1715, 'NDCG@10': 0.02978591198187386, 'NDCG@20': 0.03842829609518776, 'NDCG@50': 0.0540368908993595}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac9174b6beca4761ba9be48ced3824a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval(sampled):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST metrics (C=2000, 10k users): {'Hit@10': 0.0356, 'Hit@20': 0.0572, 'Hit@50': 0.1067, 'NDCG@10': 0.01825064652190281, 'NDCG@20': 0.023635743952412133, 'NDCG@50': 0.033412209287885984}\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 17: Final TEST evaluation (sampled candidates)\n",
    "# ============================\n",
    "\n",
    "# фиксируем test subset (10k users) для скорости и стабильности\n",
    "test_subset_10k = np.random.default_rng(SEED + 123).choice(np.arange(U), size=10000, replace=False)\n",
    "\n",
    "test_m1000 = eval_loo_sampled(model, test_gt, test_subset_10k, C=1000, Ks=(10,20,50), seed=SEED + 123)\n",
    "print(\"TEST metrics (C=1000, 10k users):\", test_m1000)\n",
    "\n",
    "# если терпимо по времени — можно чуть честнее:\n",
    "test_m2000 = eval_loo_sampled(model, test_gt, test_subset_10k, C=2000, Ks=(10,20,50), seed=SEED + 123)\n",
    "print(\"TEST metrics (C=2000, 10k users):\", test_m2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba0be5c2-1f9f-42ea-8e01-25204a368ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\ML\\GNN\\graph_recsys\\artifacts\\v2_proper\\ablation_runs\\graphsage_sampling\\history_graphsage_bpr_sampled_eval.csv\n",
      "Saved: D:\\ML\\GNN\\graph_recsys\\artifacts\\v2_proper\\ablation_runs\\graphsage_sampling\\graphsage_bpr_best.pt\n",
      "Saved: D:\\ML\\GNN\\graph_recsys\\artifacts\\v2_proper\\ablation_runs\\graphsage_sampling\\run_meta.json\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 18: Save history + best checkpoint info\n",
    "# ============================\n",
    "\n",
    "hist_df = pd.DataFrame(history)\n",
    "out_dir = ARTIFACTS / \"ablation_runs\" / \"graphsage_sampling\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "hist_path = out_dir / \"history_graphsage_bpr_sampled_eval.csv\"\n",
    "hist_df.to_csv(hist_path, index=False)\n",
    "\n",
    "meta = {\n",
    "    \"best_epoch\": EARLY.best_epoch,\n",
    "    \"best_val_ndcg10_C1000_10k\": float(EARLY.best),\n",
    "    \"config\": CFG,\n",
    "    \"bundle_dir\": str(BUNDLE_DIR),\n",
    "}\n",
    "with open(out_dir / \"run_meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# сохраняем веса (лучшие)\n",
    "ckpt_path = out_dir / \"graphsage_bpr_best.pt\"\n",
    "torch.save({\"state_dict\": EARLY.best_state, \"meta\": meta}, ckpt_path)\n",
    "\n",
    "print(\"Saved:\", hist_path)\n",
    "print(\"Saved:\", ckpt_path)\n",
    "print(\"Saved:\", out_dir / \"run_meta.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d355d018-e395-4ebd-933d-57b767cb0eed",
   "metadata": {},
   "source": [
    "## Results & Conclusions\n",
    "### What we did\n",
    "\n",
    "Loaded the frozen Graph3 bundle (Goodbooks-10k) and kept the original leave-one-out (LOO) splits.\n",
    "\n",
    "Switched from binary link prediction (BCE) to a ranking-aligned objective:\n",
    "\n",
    "GraphSAGE with neighbor sampling\n",
    "\n",
    "BPR loss (pairwise ranking)\n",
    "\n",
    "Trained the model in mini-batches of users with sampled neighborhoods.\n",
    "\n",
    "Evaluated with candidate-based LOO ranking to approximate global ranking:\n",
    "\n",
    "C=200, C=1000, C=2000 candidates per user (1 GT + negatives)\n",
    "\n",
    "Metrics: Hit@K / NDCG@K\n",
    "\n",
    "### Key findings\n",
    "\n",
    "Training is stable and convergent (loss decreases smoothly).\n",
    "\n",
    "Ranking quality improves steadily with more epochs.\n",
    "\n",
    "Best checkpoint (epoch 30) achieved on validation:\n",
    "\n",
    "Val NDCG@10 (C=1000, 10k users) ≈ 0.02783\n",
    "\n",
    "Final test metrics (10k users):\n",
    "\n",
    "TEST (C=1000): Hit@10 = 0.0577, NDCG@10 = 0.02979\n",
    "\n",
    "TEST (C=2000): Hit@10 = 0.0356, NDCG@10 = 0.01825\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "Unlike the R-GCN experiment (BCE + negative sampling), GraphSAGE trained with BPR demonstrates meaningful ranking performance.\n",
    "\n",
    "This supports the diagnosis that R-GCN underperformed mainly due to an objective–metric mismatch (binary classification vs global ranking evaluation).\n",
    "\n",
    "Candidate-based evaluation becomes stricter as C increases, reducing metrics as expected, while preserving consistent ranking signal.\n",
    "\n",
    "### Limitations (important)\n",
    "\n",
    "Current evaluation is candidate-based, not full-ranking over all items.\n",
    "\n",
    "During training, some sampled positives/negatives may fall outside the sampled subgraph and fall back to raw embeddings (a practical workaround for a scalable smoke-to-full pipeline).\n",
    "\n",
    "### Next steps\n",
    "\n",
    "Move to the next model notebook to compare architectures under the same ranking objective.\n",
    "\n",
    "In a later iteration, improve training/evaluation fidelity by:\n",
    "\n",
    "forcing inclusion of positive/negative items in sampled subgraphs,\n",
    "\n",
    "running a batched inference step to compute embeddings for all nodes and performing full-ranking LOO evaluation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - GNN (clean)",
   "language": "python",
   "name": "gnn_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
